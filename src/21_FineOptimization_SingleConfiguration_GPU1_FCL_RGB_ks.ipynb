{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Training on GPU 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick Links <a name = \"Top\"></a>\n",
    "\n",
    "<ol>\n",
    "<li><a href = #setup>Begin Training</a></li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Conda Environment: tf_ks\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]='0'\n",
    "\n",
    "print('Current Conda Environment: {}'.format(os.environ['CONDA_DEFAULT_ENV']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The installed version of TensorFlow 2.1.0 includes GPU support.\n",
      "\n",
      "Num GPUs Available:  2 \n",
      "\n",
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 2449116742638489735\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 9105744200\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 12926999585616728617\n",
      "physical_device_desc: \"device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:17:00.0, compute capability: 7.5\"\n",
      ", name: \"/device:GPU:1\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 9104897474\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 4503630800758909043\n",
      "physical_device_desc: \"device: 1, name: GeForce RTX 2080 Ti, pci bus id: 0000:65:00.0, compute capability: 7.5\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import talos as ta\n",
    "from talos.model import lr_normalizer, early_stopper, hidden_layers\n",
    "\n",
    "import tensorflow as tf\n",
    "  \n",
    "available_gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "built_with_cuda = tf.test.is_built_with_cuda()\n",
    "\n",
    "if not (not available_gpus) & built_with_cuda:\n",
    "    print(\"The installed version of TensorFlow {} includes GPU support.\\n\".format(tf.__version__))\n",
    "    print(\"Num GPUs Available: \", len(available_gpus), \"\\n\")\n",
    "else:\n",
    "    print(\"The installed version of TensorFlow {} does not include GPU support.\\n\".format(tf.__version__))\n",
    "    \n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "from tensorflow.compat.v1.keras import callbacks, backend as K\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.utils import multi_gpu_model\n",
    "from tensorflow.keras.initializers import glorot_uniform\n",
    "from tensorflow.keras.optimizers import Adam, Nadam, RMSprop, SGD, Adagrad\n",
    "from tensorflow.keras.layers import ReLU, LeakyReLU\n",
    "\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "import time\n",
    "\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "tf.random.set_seed(1)\n",
    "\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.99\n",
    "sess = tf.compat.v1.Session(config = config)\n",
    "\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hilfsfunktionen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enum für Training-Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class TrainingSet(Enum):\n",
    "    SYNTHETIC = 1\n",
    "    REAL = 2\n",
    "    MIXED = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Directory\n",
    "\n",
    "* <i>SSD</i>, falls genug Speicher auf SSD im SymLink <i>fast_output</i> verfügbar ist\n",
    "* <i>HDD</i>, falls möglicherweise zu wenig SSD-Speicher verfügbar ist $\\rightarrow$ <i>output</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import IntEnum\n",
    "\n",
    "class OutputDirectory(IntEnum):\n",
    "    HDD = 0\n",
    "    SSD = 1\n",
    "    \n",
    "output_path = ['output', 'fast_output']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benutzerdefinierte Kostenfunktion & Metrik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def circular_mse(y_true, y_pred):\n",
    "    max_error = tf.constant(360, dtype='float32')\n",
    "    return K.mean(K.square(K.minimum(K.abs(y_pred - y_true), max_error - K.abs(y_pred - y_true))), axis = -1)\n",
    "\n",
    "def circular_mae(y_true, y_pred):\n",
    "    max_error = tf.constant(360, dtype='float32')\n",
    "    return K.mean(K.minimum(K.abs(y_pred - y_true), K.abs(max_error - K.abs(y_pred - y_true))), axis = -1)\n",
    "\n",
    "def custom_mae(y_true, y_pred):\n",
    "    return K.mean(K.abs(y_pred - y_true), axis = -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Label_Type into suitable label names.\n",
    "$\\Rightarrow$ Angular / Normalized $\\rightarrow$ ['Elevation', 'Azimuth']\n",
    "\n",
    "$\\Rightarrow$ Stereographic $\\rightarrow$ ['S_x', 'S_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Label_Names(label_type):\n",
    "    if label_type == 'Angular' or label_type == 'Normalized':\n",
    "        return ['Elevation', 'Azimuth']\n",
    "    elif label_type == 'Stereographic':\n",
    "        return ['S_x', 'S_y']\n",
    "    else:\n",
    "        assert(True, 'LabelType Invalid')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert String into Reduction Metric Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Reduction_Metric(metric):\n",
    "    \n",
    "    if metric == 'custom_mae':\n",
    "        return [custom_mae]\n",
    "    elif metric == 'tf.keras.metrics.MeanAbsoluteError()':\n",
    "        return [tf.keras.metrics.MeanAbsoluteError()]\n",
    "    elif metric == 'circular_mae':\n",
    "        return [circular_mae]\n",
    "    elif metric == 'mean_squared_error':\n",
    "        return ['mean_squared_error']\n",
    "    else:\n",
    "        assert(False, 'Metric yet unknown - Please modify get_Reduction_Metric to meet your requirements')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatische Optimizer Generierung aus String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_optimizer(optimizer):\n",
    "    # [Adam, Nadam, Adagrad, RMSprop]\n",
    "    if optimizer == \"<class 'keras.optimizers.Adam'>\":\n",
    "        return Adam\n",
    "    elif optimizer == \"<class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>\":\n",
    "        return Adam\n",
    "    elif optimizer == \"<class 'keras.optimizers.Nadam'>\":\n",
    "        return Nadam\n",
    "    elif optimizer == \"<class 'keras.optimizers.Adagard'>\":\n",
    "        return Adagard\n",
    "    elif optimizer == \"<class 'keras.optimizers.RMSprop'>\":\n",
    "        return RMSprop\n",
    "    else:\n",
    "        print('ERROR::: Unspecified Optimizer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainingsset-Typ nach String Converter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainingset_to_string(ts):\n",
    "    if ts == TrainingSet.SYNTHETIC:\n",
    "        return 'Synth'\n",
    "    elif ts == TrainingSet.REAL:\n",
    "        return 'Real'\n",
    "    elif ts == TrainingSet.MIXED:\n",
    "        return 'Mixed'\n",
    "    else:\n",
    "        print('Unknown TrainingSet')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generierung Datenpipeline (Angepasst für Talos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data(batch_size, num_samples, label_type):\n",
    "    # if Block für synthetische Daten, um nur auf realen Daten zu trainieren _USE_SYNTHETIC_TRAIN_DATA\n",
    "    # 1. lege df_train und df_valid als leere Liste an\n",
    "    # 2. If-block um Zeile df = ... bis df_valid\n",
    "    \n",
    "    if trainingset == TrainingSet.SYNTHETIC:\n",
    "        df = pd.read_csv(_CSV_FILE)\n",
    "        df_shuffled = df.sample(frac = 1, random_state = 1)\n",
    "        df_train = df_shuffled[0 : int(num_samples * 0.8 // batch_size * batch_size)]\n",
    "        df_valid = df_shuffled.drop(df_shuffled.index[0 : df_train.shape[0]])[0 : int(num_samples * 0.2 // batch_size * batch_size)]\n",
    "        \n",
    "    elif trainingset == TrainingSet.MIXED:\n",
    "        df = pd.read_csv(_CSV_FILE)\n",
    "        df_shuffled = df.sample(frac = 1, random_state = 1)\n",
    "        df_train = df_shuffled[0 : int(num_samples * 0.8 // batch_size * batch_size)]\n",
    "        df_valid = df_shuffled.drop(df_shuffled.index[0 : df_train.shape[0]])[0 : int(num_samples * 0.2 // batch_size * batch_size)]\n",
    "        \n",
    "        df_real = pd.read_csv(_CSV_FILE_REAL)\n",
    "        df_shuffled_real = df_real.sample(frac = 1, random_state = 1)\n",
    "        df_shuffled_real = df_shuffled_real.drop(df_shuffled_real.index[(df_shuffled_real.shape[0] - 61) : df_shuffled_real.shape[0]])\n",
    "        df_train_real = df_shuffled_real[0: int(df_shuffled_real.shape[0] * 0.8 // batch_size * batch_size)]   \n",
    "        df_valid_real = df_shuffled_real.drop(df_shuffled_real.index[0 : df_train_real.shape[0]])\n",
    "        df_train = df_train.drop(df_train.index[df_train.shape[0] - df_train_real.shape[0] : df_train.shape[0]])\n",
    "        df_valid = df_valid.drop(df_valid.index[df_valid.shape[0] - df_valid_real.shape[0] : df_valid.shape[0]])\n",
    "        df_train = df_train.append(df_train_real)\n",
    "        df_valid= df_valid.append(df_valid_real)\n",
    "    \n",
    "    elif trainingset == TrainingSet.REAL: # Add check for num_samples, once the real dataset increases\n",
    "        df_real = pd.read_csv(_CSV_FILE_REAL)\n",
    "        df_shuffled_real = df_real.sample(frac = 1, random_state = 1)\n",
    "        df_shuffled_real = df_shuffled_real.drop(df_shuffled_real.index[(df_shuffled_real.shape[0] - 61) : df_shuffled_real.shape[0]])\n",
    "        df_train = df_shuffled_real[0 : int(df_shuffled_real.shape[0] * 0.8 // batch_size * batch_size)]   \n",
    "        df_valid = df_shuffled_real.drop(df_shuffled_real.index[0 : df_train.shape[0]])\n",
    "        \n",
    "    else:\n",
    "        print('Create_Data :: should not have reached here')\n",
    "        \n",
    "\n",
    "        \n",
    "    if _USE_DATA_AUGMENTATION:\n",
    "        train_data_generator = ImageDataGenerator(\n",
    "            rescale = 1./255,\n",
    "            width_shift_range = 0.1,\n",
    "            height_shift_range = 0.1,\n",
    "            zoom_range = 0.1,\n",
    "            brightness_range = (0.25, 0.75),\n",
    "            fill_mode = 'nearest'\n",
    "        )\n",
    "    else:\n",
    "        train_data_generator = ImageDataGenerator(\n",
    "            rescale = 1./255\n",
    "        )\n",
    "        \n",
    "    print('Y-Col: {}'.format(get_Label_Names(label_type)))\n",
    "    print('Train Data Generator: ', end = '')\n",
    "    \n",
    "    train_generator = train_data_generator.flow_from_dataframe(\n",
    "        dataframe = df_train,\n",
    "        directory = _IMAGE_DIR,\n",
    "        x_col = 'Filename RGB',\n",
    "        y_col = get_Label_Names(label_type),\n",
    "        class_mode = 'raw',\n",
    "        target_size = (224, 224),\n",
    "        color_mode = 'rgb',\n",
    "        shuffle = True,\n",
    "        seed = 77,\n",
    "        batch_size = batch_size\n",
    "    )\n",
    "    \n",
    "    valid_data_generator = ImageDataGenerator(\n",
    "        rescale = 1./255\n",
    "    )\n",
    "    \n",
    "    print('Validation Data Generator: ', end = '')\n",
    "    \n",
    "    valid_generator = valid_data_generator.flow_from_dataframe(\n",
    "        dataframe = df_valid,\n",
    "        directory = _IMAGE_DIR,\n",
    "        x_col = 'Filename RGB',\n",
    "        y_col = get_Label_Names(label_type),\n",
    "        class_mode = 'raw',\n",
    "        target_size = (224, 224),\n",
    "        color_mode = 'rgb',\n",
    "        shuffle = False,\n",
    "        seed = 77,\n",
    "        batch_size = batch_size\n",
    "    )\n",
    "    \n",
    "    return train_generator, valid_generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generierung Modell (Angepasst für Talos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_model_fine(x, y, x_val, y_val, params):\n",
    "    print('==========================Params:')\n",
    "    print(params)\n",
    "    print('==========================')\n",
    "    \n",
    "    K.clear_session()\n",
    "    \n",
    "    train_generator, valid_generator = create_data(params['batch_size'], params['samples'], params['label_type'])\n",
    "    tg_steps_per_epoch = train_generator.n // train_generator.batch_size\n",
    "    vg_validation_steps = valid_generator.n // valid_generator.batch_size\n",
    "    print('Steps per Epoch: {}, Validation Steps: {}'.format(tg_steps_per_epoch, vg_validation_steps))\n",
    "    \n",
    "    dropout_rate = params['dropout']\n",
    "    first_neuron = params['first_neuron']\n",
    "    \n",
    "    if params['activation'] == 'leakyrelu':\n",
    "        activation_layer = LeakyReLU(alpha = params['leaky_alpha'])\n",
    "    elif params['activation'] == 'relu':\n",
    "        activation_layer = ReLU()\n",
    "    \n",
    "    model = Sequential()\n",
    "    cnn = VGG16(weights = 'imagenet', include_top = False, input_shape = (224, 224, 3))\n",
    "    \n",
    "    for layer in cnn.layers[:15]:\n",
    "        layer.trainable = False\n",
    "        #print(layer.name, layer.trainable)\n",
    "        \n",
    "    print('_________________________________________________________________')\n",
    "    print('{:>16} {:>16}'.format('Network Layer', 'Trainable'))\n",
    "    print('=================================================================')\n",
    "    for layer in cnn.layers:\n",
    "        print('{:>16} {:>16}'.format(layer.name, layer.trainable))\n",
    "    print('_________________________________________________________________\\n')\n",
    "    \n",
    "    model.add(cnn)\n",
    "    \n",
    "    fc = Sequential()\n",
    "    fc.add(Flatten(input_shape = model.output_shape[1:])) # (7, 7, 512)\n",
    "    \n",
    "    fc.add(Dense(units = first_neuron, kernel_initializer = glorot_uniform(seed = 1)))\n",
    "    fc.add(activation_layer)\n",
    "    if dropout_rate > 0.0:\n",
    "        fc.add(Dropout(rate = dropout_rate))\n",
    "    \n",
    "    print('Number Hidden Layers {}'.format(params['hidden_layers']))\n",
    "    hidden_neuron_fraction = first_neuron\n",
    "    for i in range(params['hidden_layers']):\n",
    "        hidden_neuron_fraction = hidden_neuron_fraction // 2\n",
    "        fc.add(Dense(units = hidden_neuron_fraction, kernel_initializer = glorot_uniform(seed = 1)))\n",
    "        fc.add(activation_layer)\n",
    "        if dropout_rate > 0.0:\n",
    "            fc.add(Dropout(rate = dropout_rate))\n",
    "    \n",
    "    fc.add(Dense(units = 2, kernel_initializer = glorot_uniform(seed = 1)))\n",
    "    fc.load_weights(_MODEL_DIR + _MODEL_TO_LOAD)\n",
    "    model.add(fc)\n",
    "    print('Fully Connected Layers added to Base Network')\n",
    "    \n",
    "    print('Using Loss: {} \\nand Reduction Metric: {}'.format(\n",
    "        params['loss_function'], \n",
    "        get_Reduction_Metric(params['reduction_metric'])))\n",
    "    \n",
    "    model.compile(\n",
    "        #optimizer=params['optimizer'](lr=lr_normalizer(params['lr'], params['optimizer'])*1e-2),\n",
    "        optimizer = params['optimizer'](lr = lr_normalizer(params['lr'], params['optimizer']) * 1e-3),\n",
    "        loss = params['loss_function'],\n",
    "        metrics = get_Reduction_Metric(params['reduction_metric'])\n",
    "    )\n",
    "    print('Model was compiled')\n",
    "    print(model.summary())\n",
    "    print('_________________________________________________________________')\n",
    "    \n",
    "    checkpointer = callbacks.ModelCheckpoint(\n",
    "        filepath = _LOG_DIR + 'CNN_Base_{}_Model_and_Weights_{}.hdf5'.format(_MODEL_TO_LOAD_INDEX, train_generator.n),\n",
    "        monitor =  params['monitor_value'],\n",
    "        verbose = 1,\n",
    "        save_weights_only = False,\n",
    "        save_best_only = True,\n",
    "        mode = 'min'\n",
    "    )\n",
    "    print('Checkpointer was created')\n",
    "    \n",
    "    csv_logger = callbacks.CSVLogger(\n",
    "        filename = _LOG_DIR + 'CNN_Base_{}_Logger_{}.csv'.format(_MODEL_TO_LOAD_INDEX, train_generator.n),\n",
    "        separator = ',',\n",
    "        append = False\n",
    "    )\n",
    "    print('CSV Logger was created')\n",
    "\n",
    "    lr_reducer = callbacks.ReduceLROnPlateau(\n",
    "        monitor = 'val_loss',\n",
    "        factor = 0.1,\n",
    "        patience = 13,\n",
    "        verbose = 1,\n",
    "        mode = 'min',\n",
    "        min_delta = 0.0001\n",
    "    )\n",
    "    print('Learning Rate Reducer was created')\n",
    "    \n",
    "    early_stopper = callbacks.EarlyStopping(\n",
    "        monitor = 'val_loss',\n",
    "        min_delta = 0,\n",
    "        #patience = 15,\n",
    "        patience = 20,\n",
    "        verbose = 1,\n",
    "        mode = 'min',\n",
    "        restore_best_weights = True\n",
    "    )\n",
    "    print('Early Stopper was created')\n",
    "    \n",
    "    out = model.fit(\n",
    "        x = train_generator,\n",
    "        steps_per_epoch = tg_steps_per_epoch,\n",
    "        validation_data = valid_generator,\n",
    "        validation_steps = vg_validation_steps,\n",
    "        callbacks = [checkpointer, csv_logger, lr_reducer, early_stopper],\n",
    "        epochs = params['epochs'],\n",
    "        workers = 8\n",
    "    )\n",
    "    \n",
    "    return out, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feinoptimierung <a name = \"setup\"></a><a href = #Top>Up</a></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyper Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     Adam = RMSprop + Momentum (lr=0.001)\n",
    "#     Nadam = Adam RMSprop + Nesterov-Momentum (lr=0.002)\n",
    "#     RMSprop = (lr=0.001)\n",
    "#     SGD = (lr=0.01)\n",
    "#     Adagrad\n",
    "\n",
    "global_hyper_parameter = {\n",
    "    'samples': None,\n",
    "    'epochs': None,\n",
    "    'batch_size': None,\n",
    "    'optimizer': None,\n",
    "    'lr': None,\n",
    "    'first_neuron': None,\n",
    "    'dropout': None,\n",
    "    'activation': None,\n",
    "    'leaky_alpha': None,\n",
    "    'hidden_layers': None,\n",
    "    # beginning from here, Values should only contain one single entry:\n",
    "    # ===============================================================\n",
    "    'label_type': ['Angular'], # Stereographic, Angular, Normalized\n",
    "    'loss_function': None,\n",
    "    'reduction_metric': None,\n",
    "    'monitor_value': None\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "_RUN = 'SYNTH'\n",
    "_LOSS = 'MSE'\n",
    "_DATASET_NAME = '201019_2253_final'#'2020-05-28'\n",
    "_DEVICE = 'GeForce_RTX_2080_Ti'#'TITAN_GPU1'\n",
    "\n",
    "storage = OutputDirectory.SSD # 'fast_output' if ssd storage may suffice, 'output' otherwise\n",
    "\n",
    "if global_hyper_parameter['label_type'][0] == 'Stereographic':\n",
    "    _CSV_SYNTH_FILE_NAME = 'images_synthetisch_stereographic.csv'\n",
    "    _CSV_REAL_FILE_NAME = 'images_real_stereographic.csv'\n",
    "    \n",
    "elif global_hyper_parameter['label_type'][0] == 'Angular':\n",
    "    _CSV_SYNTH_FILE_NAME = 'labels_ks_RGB.csv'\n",
    "    _CSV_REAL_FILE_NAME = 'images_real.csv'\n",
    "    \n",
    "elif global_hyper_parameter['label_type'][0] == 'Normalized':\n",
    "    _CSV_SYNTH_FILE_NAME = 'images_synthetisch_normalized.csv'\n",
    "    _CSV_REAL_FILE_NAME = 'images_real_normalized.csv'\n",
    "    \n",
    "else:\n",
    "    assert(True, 'Label Type Invalid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingset = TrainingSet.SYNTHETIC\n",
    "_USE_DATA_AUGMENTATION = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory >>| ..\\fast_output\\SYNTH_Regression_MSE\\201019_2253_final_Angular_Top_1_Custom-MAE\\Synth_TD\\ |<< existiert bereits. Fortsetzen auf eigene Gefahr! (Weiter mit Enter)\n"
     ]
    }
   ],
   "source": [
    "_IMAGE_DIR = '..\\\\..\\\\data_generation\\\\dataset\\\\{}\\\\'.format(_DATASET_NAME)\n",
    "_CSV_FILE = _IMAGE_DIR + _CSV_SYNTH_FILE_NAME\n",
    "_CSV_FILE_REAL = _IMAGE_DIR + _CSV_REAL_FILE_NAME\n",
    "\n",
    "_note = '_Custom-MAE'\n",
    "\n",
    "_MODEL_DIR = '..\\\\output\\\\{}_Regression_{}\\\\{}_{}_Base{}\\\\'.format(_RUN, _LOSS, _DATASET_NAME, global_hyper_parameter['label_type'][0], _note)\n",
    "_NET_DIR = '{}_Regression_{}\\\\{}_{}_Top_1{}\\\\{}_TD\\\\'.format(_RUN, _LOSS, _DATASET_NAME, global_hyper_parameter['label_type'][0], _note, trainingset_to_string(trainingset))\n",
    "_LOG_DIR = '..\\\\{}\\\\{}'.format(output_path[storage], _NET_DIR)\n",
    "\n",
    "if(not os.path.exists(_LOG_DIR)):\n",
    "    os.makedirs(_LOG_DIR)\n",
    "else:\n",
    "    input('Directory >>| {} |<< existiert bereits. Fortsetzen auf eigene Gefahr! (Weiter mit Enter)'.format(_LOG_DIR))\n",
    "\n",
    "device_file = open(_LOG_DIR + '{}.txt'.format(_DEVICE), \"a+\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 3 FC-Gewichte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying: ..\\output\\SYNTH_Regression_MSE\\201019_2253_final_Angular_Base_Custom-MAE\\..\\201019_2253_final_Angular_Base_Custom-MAE_Results.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>duration</th>\n",
       "      <th>loss</th>\n",
       "      <th>custom_mae</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_custom_mae</th>\n",
       "      <th>activation</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>dropout</th>\n",
       "      <th>first_neuron</th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th>label_type</th>\n",
       "      <th>loss_function</th>\n",
       "      <th>lr</th>\n",
       "      <th>monitor_value</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>reduction_metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>11/04/20-133756</td>\n",
       "      <td>11/04/20-133811</td>\n",
       "      <td>15.101719</td>\n",
       "      <td>4383.826411</td>\n",
       "      <td>40.741211</td>\n",
       "      <td>2547.475186</td>\n",
       "      <td>28.446991</td>\n",
       "      <td>leakyrelu</td>\n",
       "      <td>32</td>\n",
       "      <td>0.25</td>\n",
       "      <td>4096</td>\n",
       "      <td>0</td>\n",
       "      <td>Angular</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>5</td>\n",
       "      <td>val_custom_mae</td>\n",
       "      <td>&lt;class 'tensorflow.python.keras.optimizer_v2.a...</td>\n",
       "      <td>custom_mae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>123</td>\n",
       "      <td>11/04/20-135632</td>\n",
       "      <td>11/04/20-135645</td>\n",
       "      <td>12.903348</td>\n",
       "      <td>4370.115269</td>\n",
       "      <td>41.885189</td>\n",
       "      <td>2500.798960</td>\n",
       "      <td>28.509195</td>\n",
       "      <td>leakyrelu</td>\n",
       "      <td>64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>4096</td>\n",
       "      <td>1</td>\n",
       "      <td>Angular</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>1</td>\n",
       "      <td>val_custom_mae</td>\n",
       "      <td>&lt;class 'tensorflow.python.keras.optimizer_v2.a...</td>\n",
       "      <td>custom_mae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>11/04/20-133503</td>\n",
       "      <td>11/04/20-133513</td>\n",
       "      <td>10.042880</td>\n",
       "      <td>4001.966997</td>\n",
       "      <td>39.212330</td>\n",
       "      <td>2567.742597</td>\n",
       "      <td>28.672417</td>\n",
       "      <td>leakyrelu</td>\n",
       "      <td>32</td>\n",
       "      <td>0.25</td>\n",
       "      <td>2048</td>\n",
       "      <td>0</td>\n",
       "      <td>Angular</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>5</td>\n",
       "      <td>val_custom_mae</td>\n",
       "      <td>&lt;class 'tensorflow.python.keras.optimizer_v2.a...</td>\n",
       "      <td>custom_mae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>11/04/20-133916</td>\n",
       "      <td>11/04/20-133932</td>\n",
       "      <td>16.196169</td>\n",
       "      <td>5342.255862</td>\n",
       "      <td>44.598431</td>\n",
       "      <td>2508.385596</td>\n",
       "      <td>29.009453</td>\n",
       "      <td>leakyrelu</td>\n",
       "      <td>32</td>\n",
       "      <td>0.25</td>\n",
       "      <td>4096</td>\n",
       "      <td>2</td>\n",
       "      <td>Angular</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>2</td>\n",
       "      <td>val_custom_mae</td>\n",
       "      <td>&lt;class 'tensorflow.python.keras.optimizer_v2.a...</td>\n",
       "      <td>custom_mae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>126</td>\n",
       "      <td>11/04/20-135712</td>\n",
       "      <td>11/04/20-135725</td>\n",
       "      <td>13.103501</td>\n",
       "      <td>4892.983958</td>\n",
       "      <td>44.019562</td>\n",
       "      <td>2545.006084</td>\n",
       "      <td>29.102833</td>\n",
       "      <td>leakyrelu</td>\n",
       "      <td>64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>4096</td>\n",
       "      <td>2</td>\n",
       "      <td>Angular</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>1</td>\n",
       "      <td>val_custom_mae</td>\n",
       "      <td>&lt;class 'tensorflow.python.keras.optimizer_v2.a...</td>\n",
       "      <td>custom_mae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>109</td>\n",
       "      <td>11/04/20-135414</td>\n",
       "      <td>11/04/20-135423</td>\n",
       "      <td>8.591999</td>\n",
       "      <td>4502.218566</td>\n",
       "      <td>42.888409</td>\n",
       "      <td>2549.238323</td>\n",
       "      <td>29.138407</td>\n",
       "      <td>leakyrelu</td>\n",
       "      <td>64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>2048</td>\n",
       "      <td>1</td>\n",
       "      <td>Angular</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>2</td>\n",
       "      <td>val_custom_mae</td>\n",
       "      <td>&lt;class 'tensorflow.python.keras.optimizer_v2.a...</td>\n",
       "      <td>custom_mae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>11/04/20-133619</td>\n",
       "      <td>11/04/20-133629</td>\n",
       "      <td>10.735754</td>\n",
       "      <td>4304.691335</td>\n",
       "      <td>43.828423</td>\n",
       "      <td>2479.888127</td>\n",
       "      <td>29.194164</td>\n",
       "      <td>leakyrelu</td>\n",
       "      <td>32</td>\n",
       "      <td>0.25</td>\n",
       "      <td>2048</td>\n",
       "      <td>3</td>\n",
       "      <td>Angular</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>1</td>\n",
       "      <td>val_custom_mae</td>\n",
       "      <td>&lt;class 'tensorflow.python.keras.optimizer_v2.a...</td>\n",
       "      <td>custom_mae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>11/04/20-133900</td>\n",
       "      <td>11/04/20-133916</td>\n",
       "      <td>16.164278</td>\n",
       "      <td>4115.395587</td>\n",
       "      <td>41.639866</td>\n",
       "      <td>2575.603947</td>\n",
       "      <td>29.298376</td>\n",
       "      <td>leakyrelu</td>\n",
       "      <td>32</td>\n",
       "      <td>0.25</td>\n",
       "      <td>4096</td>\n",
       "      <td>2</td>\n",
       "      <td>Angular</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>1</td>\n",
       "      <td>val_custom_mae</td>\n",
       "      <td>&lt;class 'tensorflow.python.keras.optimizer_v2.a...</td>\n",
       "      <td>custom_mae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>108</td>\n",
       "      <td>11/04/20-135405</td>\n",
       "      <td>11/04/20-135414</td>\n",
       "      <td>8.623027</td>\n",
       "      <td>3881.180195</td>\n",
       "      <td>40.146988</td>\n",
       "      <td>2558.554630</td>\n",
       "      <td>29.299927</td>\n",
       "      <td>leakyrelu</td>\n",
       "      <td>64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>2048</td>\n",
       "      <td>1</td>\n",
       "      <td>Angular</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>1</td>\n",
       "      <td>val_custom_mae</td>\n",
       "      <td>&lt;class 'tensorflow.python.keras.optimizer_v2.a...</td>\n",
       "      <td>custom_mae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>11/04/20-133514</td>\n",
       "      <td>11/04/20-133524</td>\n",
       "      <td>10.283503</td>\n",
       "      <td>3871.796719</td>\n",
       "      <td>39.797153</td>\n",
       "      <td>2617.595140</td>\n",
       "      <td>29.322357</td>\n",
       "      <td>leakyrelu</td>\n",
       "      <td>32</td>\n",
       "      <td>0.25</td>\n",
       "      <td>2048</td>\n",
       "      <td>1</td>\n",
       "      <td>Angular</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>1</td>\n",
       "      <td>val_custom_mae</td>\n",
       "      <td>&lt;class 'tensorflow.python.keras.optimizer_v2.a...</td>\n",
       "      <td>custom_mae</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0            start              end   duration         loss  \\\n",
       "32           32  11/04/20-133756  11/04/20-133811  15.101719  4383.826411   \n",
       "123         123  11/04/20-135632  11/04/20-135645  12.903348  4370.115269   \n",
       "17           17  11/04/20-133503  11/04/20-133513  10.042880  4001.966997   \n",
       "37           37  11/04/20-133916  11/04/20-133932  16.196169  5342.255862   \n",
       "126         126  11/04/20-135712  11/04/20-135725  13.103501  4892.983958   \n",
       "109         109  11/04/20-135414  11/04/20-135423   8.591999  4502.218566   \n",
       "24           24  11/04/20-133619  11/04/20-133629  10.735754  4304.691335   \n",
       "36           36  11/04/20-133900  11/04/20-133916  16.164278  4115.395587   \n",
       "108         108  11/04/20-135405  11/04/20-135414   8.623027  3881.180195   \n",
       "18           18  11/04/20-133514  11/04/20-133524  10.283503  3871.796719   \n",
       "\n",
       "     custom_mae     val_loss  val_custom_mae activation  batch_size  dropout  \\\n",
       "32    40.741211  2547.475186       28.446991  leakyrelu          32     0.25   \n",
       "123   41.885189  2500.798960       28.509195  leakyrelu          64     0.25   \n",
       "17    39.212330  2567.742597       28.672417  leakyrelu          32     0.25   \n",
       "37    44.598431  2508.385596       29.009453  leakyrelu          32     0.25   \n",
       "126   44.019562  2545.006084       29.102833  leakyrelu          64     0.25   \n",
       "109   42.888409  2549.238323       29.138407  leakyrelu          64     0.25   \n",
       "24    43.828423  2479.888127       29.194164  leakyrelu          32     0.25   \n",
       "36    41.639866  2575.603947       29.298376  leakyrelu          32     0.25   \n",
       "108   40.146988  2558.554630       29.299927  leakyrelu          64     0.25   \n",
       "18    39.797153  2617.595140       29.322357  leakyrelu          32     0.25   \n",
       "\n",
       "     first_neuron  hidden_layers label_type       loss_function  lr  \\\n",
       "32           4096              0    Angular  mean_squared_error   5   \n",
       "123          4096              1    Angular  mean_squared_error   1   \n",
       "17           2048              0    Angular  mean_squared_error   5   \n",
       "37           4096              2    Angular  mean_squared_error   2   \n",
       "126          4096              2    Angular  mean_squared_error   1   \n",
       "109          2048              1    Angular  mean_squared_error   2   \n",
       "24           2048              3    Angular  mean_squared_error   1   \n",
       "36           4096              2    Angular  mean_squared_error   1   \n",
       "108          2048              1    Angular  mean_squared_error   1   \n",
       "18           2048              1    Angular  mean_squared_error   1   \n",
       "\n",
       "      monitor_value                                          optimizer  \\\n",
       "32   val_custom_mae  <class 'tensorflow.python.keras.optimizer_v2.a...   \n",
       "123  val_custom_mae  <class 'tensorflow.python.keras.optimizer_v2.a...   \n",
       "17   val_custom_mae  <class 'tensorflow.python.keras.optimizer_v2.a...   \n",
       "37   val_custom_mae  <class 'tensorflow.python.keras.optimizer_v2.a...   \n",
       "126  val_custom_mae  <class 'tensorflow.python.keras.optimizer_v2.a...   \n",
       "109  val_custom_mae  <class 'tensorflow.python.keras.optimizer_v2.a...   \n",
       "24   val_custom_mae  <class 'tensorflow.python.keras.optimizer_v2.a...   \n",
       "36   val_custom_mae  <class 'tensorflow.python.keras.optimizer_v2.a...   \n",
       "108  val_custom_mae  <class 'tensorflow.python.keras.optimizer_v2.a...   \n",
       "18   val_custom_mae  <class 'tensorflow.python.keras.optimizer_v2.a...   \n",
       "\n",
       "    reduction_metric  \n",
       "32        custom_mae  \n",
       "123       custom_mae  \n",
       "17        custom_mae  \n",
       "37        custom_mae  \n",
       "126       custom_mae  \n",
       "109       custom_mae  \n",
       "24        custom_mae  \n",
       "36        custom_mae  \n",
       "108       custom_mae  \n",
       "18        custom_mae  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_results = _MODEL_DIR + '..\\\\{}_{}_Base{}_Results.csv'.format(_DATASET_NAME, global_hyper_parameter['label_type'][0], _note)\n",
    "df = pd.read_csv(base_results).drop(columns = ['round_epochs', 'samples', 'epochs'], axis = 0)\n",
    "sort_value = df['monitor_value'][0]\n",
    "df = df.sort_values(sort_value, axis = 0, ascending = True, inplace = False, kind = 'quicksort', na_position = 'last')\n",
    "print('Displaying: {}'.format(base_results))\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSerach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_params(top_results_index):\n",
    "    \n",
    "    #     Adam = RMSprop + Momentum (lr=0.001)\n",
    "    #     Nadam = Adam RMSprop + Nesterov-Momentum (lr=0.002)\n",
    "    #     RMSprop = (lr=0.001)\n",
    "    #     SGD = (lr=0.01)\n",
    "    #     Adagrad\n",
    "\n",
    "    hyper_parameter = global_hyper_parameter\n",
    "\n",
    "    hyper_parameter['samples'] = [100000] \n",
    "    hyper_parameter['epochs'] = [400]\n",
    "    hyper_parameter['batch_size'] = [df.iloc[top_results_index]['batch_size']]\n",
    "    hyper_parameter['optimizer'] = [make_optimizer(df.loc[top_results_index]['optimizer'])]\n",
    "    hyper_parameter['lr'] = [df.iloc[top_results_index]['lr']]\n",
    "    hyper_parameter['first_neuron'] = [df.iloc[top_results_index]['first_neuron']]\n",
    "    hyper_parameter['dropout'] = [df.iloc[top_results_index]['dropout']]\n",
    "    hyper_parameter['activation'] = [df.iloc[top_results_index]['activation']]\n",
    "    hyper_parameter['leaky_alpha'] = [0.1] #Default bei LeakyReLU, sonst PReLU\n",
    "    hyper_parameter['hidden_layers'] = [df.iloc[top_results_index]['hidden_layers']]\n",
    "    \n",
    "    hyper_parameter['loss_function'] = [df.iloc[top_results_index]['loss_function']]\n",
    "    hyper_parameter['reduction_metric'] = [df.iloc[top_results_index]['reduction_metric']]\n",
    "    hyper_parameter['monitor_value'] = [df.iloc[top_results_index]['monitor_value']]\n",
    "\n",
    "    return hyper_parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from IPython.display import Image\n",
    "#print(_CSV_FILE)\n",
    "#df = pd.read_csv(_CSV_FILE)\n",
    "#df.head()\n",
    "#print(df.iloc[0]['Filename RGB'])\n",
    "##Image(df.iloc[0]['Filename RGB'])\n",
    "##Image('../buddha00000001-0-5-0-10.png')\n",
    "##Image('../../data_generation/dataset/201019_2253_final/buddha/rgb/buddha00000000-0-5-0-5.png')\n",
    "#Image('..\\\\..\\\\data_generation\\\\dataset\\\\201019_2253_final\\\\buddha\\\\rgb\\\\buddha00000000-0-5-0-5.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Talos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'leakyrelu', 'batch_size': 32, 'dropout': 0.25, 'epochs': 400, 'first_neuron': 4096, 'hidden_layers': 0, 'label_type': 'Angular', 'leaky_alpha': 0.1, 'loss_function': 'mean_squared_error', 'lr': 5, 'monitor_value': 'val_custom_mae', 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>, 'reduction_metric': 'custom_mae', 'samples': 100000}\n",
      "==========================Params:\n",
      "{'activation': 'leakyrelu', 'batch_size': 32, 'dropout': 0.25, 'epochs': 400, 'first_neuron': 4096, 'hidden_layers': 0, 'label_type': 'Angular', 'leaky_alpha': 0.1, 'loss_function': 'mean_squared_error', 'lr': 5, 'monitor_value': 'val_custom_mae', 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>, 'reduction_metric': 'custom_mae', 'samples': 100000}\n",
      "==========================\n",
      "Y-Col: ['Elevation', 'Azimuth']\n",
      "Train Data Generator: Found 80000 validated image filenames.\n",
      "Validation Data Generator: Found 20000 validated image filenames.\n",
      "Steps per Epoch: 2500, Validation Steps: 625\n",
      "_________________________________________________________________\n",
      "   Network Layer        Trainable\n",
      "=================================================================\n",
      "         input_1                0\n",
      "    block1_conv1                0\n",
      "    block1_conv2                0\n",
      "     block1_pool                0\n",
      "    block2_conv1                0\n",
      "    block2_conv2                0\n",
      "     block2_pool                0\n",
      "    block3_conv1                0\n",
      "    block3_conv2                0\n",
      "    block3_conv3                0\n",
      "     block3_pool                0\n",
      "    block4_conv1                0\n",
      "    block4_conv2                0\n",
      "    block4_conv3                0\n",
      "     block4_pool                0\n",
      "    block5_conv1                1\n",
      "    block5_conv2                1\n",
      "    block5_conv3                1\n",
      "     block5_pool                1\n",
      "_________________________________________________________________\n",
      "\n",
      "Number Hidden Layers 0\n",
      "Fully Connected Layers added to Base Network\n",
      "Using Loss: mean_squared_error \n",
      "and Reduction Metric: [<function custom_mae at 0x00000183375EFEE8>]\n",
      "Model was compiled\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 7, 7, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "sequential_1 (Sequential)    (None, 2)                 102772738 \n",
      "=================================================================\n",
      "Total params: 117,487,426\n",
      "Trainable params: 109,852,162\n",
      "Non-trainable params: 7,635,264\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Checkpointer was created\n",
      "CSV Logger was created\n",
      "Learning Rate Reducer was created\n",
      "Early Stopper was created\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 2500 steps, validate for 625 steps\n",
      "Epoch 1/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 4488.3960 - custom_mae: 44.9357\n",
      "Epoch 00001: val_custom_mae improved from inf to 33.19179, saving model to ..\\fast_output\\SYNTH_Regression_MSE\\201019_2253_final_Angular_Top_1_Custom-MAE\\Synth_TD\\CNN_Base_32_Model_and_Weights_80000.hdf5\n",
      "2500/2500 [==============================] - 343s 137ms/step - loss: 4487.7997 - custom_mae: 44.9306 - val_loss: 2697.1964 - val_custom_mae: 33.1918\n",
      "Epoch 2/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 2585.2408 - custom_mae: 31.7110\n",
      "Epoch 00002: val_custom_mae improved from 33.19179 to 28.61168, saving model to ..\\fast_output\\SYNTH_Regression_MSE\\201019_2253_final_Angular_Top_1_Custom-MAE\\Synth_TD\\CNN_Base_32_Model_and_Weights_80000.hdf5\n",
      "2500/2500 [==============================] - 262s 105ms/step - loss: 2585.1273 - custom_mae: 31.7094 - val_loss: 2129.2584 - val_custom_mae: 28.6117\n",
      "Epoch 3/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 2073.9840 - custom_mae: 27.3665\n",
      "Epoch 00003: val_custom_mae improved from 28.61168 to 26.51459, saving model to ..\\fast_output\\SYNTH_Regression_MSE\\201019_2253_final_Angular_Top_1_Custom-MAE\\Synth_TD\\CNN_Base_32_Model_and_Weights_80000.hdf5\n",
      "2500/2500 [==============================] - 262s 105ms/step - loss: 2073.7872 - custom_mae: 27.3661 - val_loss: 1917.4701 - val_custom_mae: 26.5146\n",
      "Epoch 4/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 1810.6696 - custom_mae: 24.9029\n",
      "Epoch 00004: val_custom_mae improved from 26.51459 to 23.05932, saving model to ..\\fast_output\\SYNTH_Regression_MSE\\201019_2253_final_Angular_Top_1_Custom-MAE\\Synth_TD\\CNN_Base_32_Model_and_Weights_80000.hdf5\n",
      "2500/2500 [==============================] - 262s 105ms/step - loss: 1810.4439 - custom_mae: 24.9019 - val_loss: 1573.7567 - val_custom_mae: 23.0593\n",
      "Epoch 5/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 1634.3614 - custom_mae: 23.1755\n",
      "Epoch 00005: val_custom_mae improved from 23.05932 to 21.94471, saving model to ..\\fast_output\\SYNTH_Regression_MSE\\201019_2253_final_Angular_Top_1_Custom-MAE\\Synth_TD\\CNN_Base_32_Model_and_Weights_80000.hdf5\n",
      "2500/2500 [==============================] - 262s 105ms/step - loss: 1634.5063 - custom_mae: 23.1756 - val_loss: 1485.5645 - val_custom_mae: 21.9447\n",
      "Epoch 6/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 1510.9180 - custom_mae: 21.9060 ETA: 1s - loss: 1510.9336\n",
      "Epoch 00006: val_custom_mae improved from 21.94471 to 21.70771, saving model to ..\\fast_output\\SYNTH_Regression_MSE\\201019_2253_final_Angular_Top_1_Custom-MAE\\Synth_TD\\CNN_Base_32_Model_and_Weights_80000.hdf5\n",
      "2500/2500 [==============================] - 262s 105ms/step - loss: 1510.7297 - custom_mae: 21.9050 - val_loss: 1478.8701 - val_custom_mae: 21.7077\n",
      "Epoch 7/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 1423.7219 - custom_mae: 21.0455\n",
      "Epoch 00007: val_custom_mae improved from 21.70771 to 20.75148, saving model to ..\\fast_output\\SYNTH_Regression_MSE\\201019_2253_final_Angular_Top_1_Custom-MAE\\Synth_TD\\CNN_Base_32_Model_and_Weights_80000.hdf5\n",
      "2500/2500 [==============================] - 263s 105ms/step - loss: 1423.5362 - custom_mae: 21.0443 - val_loss: 1356.9530 - val_custom_mae: 20.7515\n",
      "Epoch 8/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 1337.8906 - custom_mae: 20.1586\n",
      "Epoch 00008: val_custom_mae improved from 20.75148 to 19.46762, saving model to ..\\fast_output\\SYNTH_Regression_MSE\\201019_2253_final_Angular_Top_1_Custom-MAE\\Synth_TD\\CNN_Base_32_Model_and_Weights_80000.hdf5\n",
      "2500/2500 [==============================] - 263s 105ms/step - loss: 1338.1305 - custom_mae: 20.1599 - val_loss: 1277.7846 - val_custom_mae: 19.4676\n",
      "Epoch 9/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 1285.6619 - custom_mae: 19.5157\n",
      "Epoch 00009: val_custom_mae improved from 19.46762 to 18.84425, saving model to ..\\fast_output\\SYNTH_Regression_MSE\\201019_2253_final_Angular_Top_1_Custom-MAE\\Synth_TD\\CNN_Base_32_Model_and_Weights_80000.hdf5\n",
      "2500/2500 [==============================] - 263s 105ms/step - loss: 1286.0113 - custom_mae: 19.5182 - val_loss: 1232.9452 - val_custom_mae: 18.8442\n",
      "Epoch 10/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 1232.2215 - custom_mae: 18.8787\n",
      "Epoch 00010: val_custom_mae improved from 18.84425 to 18.83744, saving model to ..\\fast_output\\SYNTH_Regression_MSE\\201019_2253_final_Angular_Top_1_Custom-MAE\\Synth_TD\\CNN_Base_32_Model_and_Weights_80000.hdf5\n",
      "2500/2500 [==============================] - 262s 105ms/step - loss: 1232.3955 - custom_mae: 18.8806 - val_loss: 1255.8252 - val_custom_mae: 18.8374\n",
      "Epoch 11/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 1180.2111 - custom_mae: 18.3466\n",
      "Epoch 00011: val_custom_mae improved from 18.83744 to 18.05416, saving model to ..\\fast_output\\SYNTH_Regression_MSE\\201019_2253_final_Angular_Top_1_Custom-MAE\\Synth_TD\\CNN_Base_32_Model_and_Weights_80000.hdf5\n",
      "2500/2500 [==============================] - 263s 105ms/step - loss: 1180.1631 - custom_mae: 18.3465 - val_loss: 1156.5838 - val_custom_mae: 18.0542\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 1145.5901 - custom_mae: 17.9639\n",
      "Epoch 00012: val_custom_mae improved from 18.05416 to 17.76940, saving model to ..\\fast_output\\SYNTH_Regression_MSE\\201019_2253_final_Angular_Top_1_Custom-MAE\\Synth_TD\\CNN_Base_32_Model_and_Weights_80000.hdf5\n",
      "2500/2500 [==============================] - 263s 105ms/step - loss: 1145.6010 - custom_mae: 17.9638 - val_loss: 1145.9526 - val_custom_mae: 17.7694\n",
      "Epoch 13/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 1104.1570 - custom_mae: 17.4580\n",
      "Epoch 00013: val_custom_mae did not improve from 17.76940\n",
      "2500/2500 [==============================] - 257s 103ms/step - loss: 1104.2540 - custom_mae: 17.4587 - val_loss: 1202.2596 - val_custom_mae: 18.6841\n",
      "Epoch 14/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 1079.4092 - custom_mae: 17.0751\n",
      "Epoch 00014: val_custom_mae improved from 17.76940 to 16.92342, saving model to ..\\fast_output\\SYNTH_Regression_MSE\\201019_2253_final_Angular_Top_1_Custom-MAE\\Synth_TD\\CNN_Base_32_Model_and_Weights_80000.hdf5\n",
      "2500/2500 [==============================] - 262s 105ms/step - loss: 1079.2665 - custom_mae: 17.0744 - val_loss: 1072.1485 - val_custom_mae: 16.9234\n",
      "Epoch 15/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 1046.0632 - custom_mae: 16.7861 - ETA: 0s - loss: 1045.3071 -\n",
      "Epoch 00015: val_custom_mae improved from 16.92342 to 16.72660, saving model to ..\\fast_output\\SYNTH_Regression_MSE\\201019_2253_final_Angular_Top_1_Custom-MAE\\Synth_TD\\CNN_Base_32_Model_and_Weights_80000.hdf5\n",
      "2500/2500 [==============================] - 263s 105ms/step - loss: 1045.8962 - custom_mae: 16.7846 - val_loss: 1057.1082 - val_custom_mae: 16.7266\n",
      "Epoch 16/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 1014.2566 - custom_mae: 16.3407\n",
      "Epoch 00016: val_custom_mae improved from 16.72660 to 16.61374, saving model to ..\\fast_output\\SYNTH_Regression_MSE\\201019_2253_final_Angular_Top_1_Custom-MAE\\Synth_TD\\CNN_Base_32_Model_and_Weights_80000.hdf5\n",
      "2500/2500 [==============================] - 262s 105ms/step - loss: 1014.4734 - custom_mae: 16.3423 - val_loss: 1075.1169 - val_custom_mae: 16.6137\n",
      "Epoch 17/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 992.9848 - custom_mae: 16.0594\n",
      "Epoch 00017: val_custom_mae improved from 16.61374 to 16.43920, saving model to ..\\fast_output\\SYNTH_Regression_MSE\\201019_2253_final_Angular_Top_1_Custom-MAE\\Synth_TD\\CNN_Base_32_Model_and_Weights_80000.hdf5\n",
      "2500/2500 [==============================] - 263s 105ms/step - loss: 993.2458 - custom_mae: 16.0620 - val_loss: 1027.6184 - val_custom_mae: 16.4392\n",
      "Epoch 18/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 977.3943 - custom_mae: 15.8499\n",
      "Epoch 00018: val_custom_mae improved from 16.43920 to 15.83345, saving model to ..\\fast_output\\SYNTH_Regression_MSE\\201019_2253_final_Angular_Top_1_Custom-MAE\\Synth_TD\\CNN_Base_32_Model_and_Weights_80000.hdf5\n",
      "2500/2500 [==============================] - 263s 105ms/step - loss: 977.3784 - custom_mae: 15.8501 - val_loss: 989.1422 - val_custom_mae: 15.8335\n",
      "Epoch 19/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 957.0408 - custom_mae: 15.6033\n",
      "Epoch 00019: val_custom_mae did not improve from 15.83345\n",
      "2500/2500 [==============================] - 257s 103ms/step - loss: 956.8185 - custom_mae: 15.6022 - val_loss: 992.1797 - val_custom_mae: 16.1879\n",
      "Epoch 20/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 932.9451 - custom_mae: 15.3941\n",
      "Epoch 00020: val_custom_mae improved from 15.83345 to 15.46689, saving model to ..\\fast_output\\SYNTH_Regression_MSE\\201019_2253_final_Angular_Top_1_Custom-MAE\\Synth_TD\\CNN_Base_32_Model_and_Weights_80000.hdf5\n",
      "2500/2500 [==============================] - 263s 105ms/step - loss: 933.0286 - custom_mae: 15.3955 - val_loss: 945.2710 - val_custom_mae: 15.4669\n",
      "Epoch 21/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 910.3071 - custom_mae: 15.1066\n",
      "Epoch 00021: val_custom_mae improved from 15.46689 to 15.18869, saving model to ..\\fast_output\\SYNTH_Regression_MSE\\201019_2253_final_Angular_Top_1_Custom-MAE\\Synth_TD\\CNN_Base_32_Model_and_Weights_80000.hdf5\n",
      "2500/2500 [==============================] - 263s 105ms/step - loss: 910.3340 - custom_mae: 15.1066 - val_loss: 943.6184 - val_custom_mae: 15.1887\n",
      "Epoch 22/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 904.0541 - custom_mae: 14.9237\n",
      "Epoch 00022: val_custom_mae did not improve from 15.18869\n",
      "2500/2500 [==============================] - 259s 104ms/step - loss: 903.8830 - custom_mae: 14.9229 - val_loss: 1182.3700 - val_custom_mae: 16.5330\n",
      "Epoch 23/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 876.9913 - custom_mae: 14.6411\n",
      "Epoch 00023: val_custom_mae did not improve from 15.18869\n",
      "2500/2500 [==============================] - 314s 126ms/step - loss: 876.8210 - custom_mae: 14.6399 - val_loss: 938.1773 - val_custom_mae: 15.2727\n",
      "Epoch 24/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 865.4742 - custom_mae: 14.4228- ETA:  - ETA: 0s - loss: 865.5209 - custom_mae: 14.4226\n",
      "Epoch 00024: val_custom_mae improved from 15.18869 to 14.63695, saving model to ..\\fast_output\\SYNTH_Regression_MSE\\201019_2253_final_Angular_Top_1_Custom-MAE\\Synth_TD\\CNN_Base_32_Model_and_Weights_80000.hdf5\n",
      "2500/2500 [==============================] - 271s 109ms/step - loss: 865.3421 - custom_mae: 14.4209 - val_loss: 906.1933 - val_custom_mae: 14.6370\n",
      "Epoch 25/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 847.0401 - custom_mae: 14.2265\n",
      "Epoch 00025: val_custom_mae improved from 14.63695 to 14.50827, saving model to ..\\fast_output\\SYNTH_Regression_MSE\\201019_2253_final_Angular_Top_1_Custom-MAE\\Synth_TD\\CNN_Base_32_Model_and_Weights_80000.hdf5\n",
      "2500/2500 [==============================] - 263s 105ms/step - loss: 846.9833 - custom_mae: 14.2259 - val_loss: 896.9583 - val_custom_mae: 14.5083\n",
      "Epoch 26/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 837.6663 - custom_mae: 14.0836- ETA: 4s - loss: 83 - ETA: 2s - loss: 838.2207 - - ETA: 0s - loss: 838.3208 - custom_mae: 1\n",
      "Epoch 00026: val_custom_mae improved from 14.50827 to 14.33145, saving model to ..\\fast_output\\SYNTH_Regression_MSE\\201019_2253_final_Angular_Top_1_Custom-MAE\\Synth_TD\\CNN_Base_32_Model_and_Weights_80000.hdf5\n",
      "2500/2500 [==============================] - 263s 105ms/step - loss: 837.6878 - custom_mae: 14.0832 - val_loss: 881.4897 - val_custom_mae: 14.3315\n",
      "Epoch 27/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 819.7546 - custom_mae: 13.9207- ETA: 2s - loss:\n",
      "Epoch 00027: val_custom_mae did not improve from 14.33145\n",
      "2500/2500 [==============================] - 258s 103ms/step - loss: 820.0477 - custom_mae: 13.9227 - val_loss: 912.5973 - val_custom_mae: 14.5120\n",
      "Epoch 28/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 808.5877 - custom_mae: 13.7319\n",
      "Epoch 00028: val_custom_mae improved from 14.33145 to 14.00408, saving model to ..\\fast_output\\SYNTH_Regression_MSE\\201019_2253_final_Angular_Top_1_Custom-MAE\\Synth_TD\\CNN_Base_32_Model_and_Weights_80000.hdf5\n",
      "2500/2500 [==============================] - 263s 105ms/step - loss: 808.5442 - custom_mae: 13.7313 - val_loss: 840.9607 - val_custom_mae: 14.0041\n",
      "Epoch 29/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 798.5655 - custom_mae: 13.5615- ETA: 1s - loss: 799.3321 - custom_m\n",
      "Epoch 00029: val_custom_mae improved from 14.00408 to 13.74509, saving model to ..\\fast_output\\SYNTH_Regression_MSE\\201019_2253_final_Angular_Top_1_Custom-MAE\\Synth_TD\\CNN_Base_32_Model_and_Weights_80000.hdf5\n",
      "2500/2500 [==============================] - 263s 105ms/step - loss: 798.5681 - custom_mae: 13.5624 - val_loss: 852.2445 - val_custom_mae: 13.7451\n",
      "Epoch 30/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 786.2947 - custom_mae: 13.4163\n",
      "Epoch 00030: val_custom_mae improved from 13.74509 to 13.73055, saving model to ..\\fast_output\\SYNTH_Regression_MSE\\201019_2253_final_Angular_Top_1_Custom-MAE\\Synth_TD\\CNN_Base_32_Model_and_Weights_80000.hdf5\n",
      "2500/2500 [==============================] - 263s 105ms/step - loss: 786.2466 - custom_mae: 13.4159 - val_loss: 842.7901 - val_custom_mae: 13.7306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 775.9906 - custom_mae: 13.3015\n",
      "Epoch 00031: val_custom_mae improved from 13.73055 to 13.69181, saving model to ..\\fast_output\\SYNTH_Regression_MSE\\201019_2253_final_Angular_Top_1_Custom-MAE\\Synth_TD\\CNN_Base_32_Model_and_Weights_80000.hdf5\n",
      "2500/2500 [==============================] - 263s 105ms/step - loss: 776.1195 - custom_mae: 13.3023 - val_loss: 821.4889 - val_custom_mae: 13.6918\n",
      "Epoch 32/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 762.8064 - custom_mae: 13.1144\n",
      "Epoch 00032: val_custom_mae improved from 13.69181 to 13.38246, saving model to ..\\fast_output\\SYNTH_Regression_MSE\\201019_2253_final_Angular_Top_1_Custom-MAE\\Synth_TD\\CNN_Base_32_Model_and_Weights_80000.hdf5\n",
      "2500/2500 [==============================] - 264s 105ms/step - loss: 762.6357 - custom_mae: 13.1135 - val_loss: 817.1504 - val_custom_mae: 13.3825\n",
      "Epoch 33/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 751.2603 - custom_mae: 12.9055\n",
      "Epoch 00033: val_custom_mae improved from 13.38246 to 13.29384, saving model to ..\\fast_output\\SYNTH_Regression_MSE\\201019_2253_final_Angular_Top_1_Custom-MAE\\Synth_TD\\CNN_Base_32_Model_and_Weights_80000.hdf5\n",
      "2500/2500 [==============================] - 263s 105ms/step - loss: 751.4997 - custom_mae: 12.9070 - val_loss: 830.1911 - val_custom_mae: 13.2938\n",
      "Epoch 34/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 746.1592 - custom_mae: 12.8546\n",
      "Epoch 00034: val_custom_mae improved from 13.29384 to 13.27421, saving model to ..\\fast_output\\SYNTH_Regression_MSE\\201019_2253_final_Angular_Top_1_Custom-MAE\\Synth_TD\\CNN_Base_32_Model_and_Weights_80000.hdf5\n",
      "2500/2500 [==============================] - 263s 105ms/step - loss: 746.0425 - custom_mae: 12.8539 - val_loss: 793.4282 - val_custom_mae: 13.2742\n",
      "Epoch 35/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 737.3648 - custom_mae: 12.6728\n",
      "Epoch 00035: val_custom_mae improved from 13.27421 to 12.95866, saving model to ..\\fast_output\\SYNTH_Regression_MSE\\201019_2253_final_Angular_Top_1_Custom-MAE\\Synth_TD\\CNN_Base_32_Model_and_Weights_80000.hdf5\n",
      "2500/2500 [==============================] - 263s 105ms/step - loss: 737.3620 - custom_mae: 12.6728 - val_loss: 802.2130 - val_custom_mae: 12.9587\n",
      "Epoch 36/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 727.2559 - custom_mae: 12.5660\n",
      "Epoch 00036: val_custom_mae did not improve from 12.95866\n",
      "2500/2500 [==============================] - 258s 103ms/step - loss: 727.3121 - custom_mae: 12.5662 - val_loss: 782.4965 - val_custom_mae: 13.1601\n",
      "Epoch 37/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 714.7142 - custom_mae: 12.4537\n",
      "Epoch 00037: val_custom_mae improved from 12.95866 to 12.86986, saving model to ..\\fast_output\\SYNTH_Regression_MSE\\201019_2253_final_Angular_Top_1_Custom-MAE\\Synth_TD\\CNN_Base_32_Model_and_Weights_80000.hdf5\n",
      "2500/2500 [==============================] - 263s 105ms/step - loss: 714.7988 - custom_mae: 12.4539 - val_loss: 812.4589 - val_custom_mae: 12.8699\n",
      "Epoch 38/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 711.4025 - custom_mae: 12.3564- ETA: 1s - loss: 710.9606 - custom_m\n",
      "Epoch 00038: val_custom_mae did not improve from 12.86986\n",
      "2500/2500 [==============================] - 258s 103ms/step - loss: 711.1849 - custom_mae: 12.3548 - val_loss: 800.7828 - val_custom_mae: 13.4869\n",
      "Epoch 39/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 701.8408 - custom_mae: 12.2429\n",
      "Epoch 00039: val_custom_mae did not improve from 12.86986\n",
      "2500/2500 [==============================] - 258s 103ms/step - loss: 701.7644 - custom_mae: 12.2417 - val_loss: 778.7025 - val_custom_mae: 13.3321\n",
      "Epoch 40/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 689.0401 - custom_mae: 12.0446\n",
      "Epoch 00040: val_custom_mae improved from 12.86986 to 12.37804, saving model to ..\\fast_output\\SYNTH_Regression_MSE\\201019_2253_final_Angular_Top_1_Custom-MAE\\Synth_TD\\CNN_Base_32_Model_and_Weights_80000.hdf5\n",
      "2500/2500 [==============================] - 263s 105ms/step - loss: 689.5070 - custom_mae: 12.0476 - val_loss: 752.0702 - val_custom_mae: 12.3780\n",
      "Epoch 41/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 683.5652 - custom_mae: 11.9875\n",
      "Epoch 00041: val_custom_mae improved from 12.37804 to 12.15529, saving model to ..\\fast_output\\SYNTH_Regression_MSE\\201019_2253_final_Angular_Top_1_Custom-MAE\\Synth_TD\\CNN_Base_32_Model_and_Weights_80000.hdf5\n",
      "2500/2500 [==============================] - 264s 105ms/step - loss: 683.7615 - custom_mae: 11.9885 - val_loss: 746.2392 - val_custom_mae: 12.1553\n",
      "Epoch 42/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 671.9608 - custom_mae: 11.8108\n",
      "Epoch 00042: val_custom_mae improved from 12.15529 to 11.98492, saving model to ..\\fast_output\\SYNTH_Regression_MSE\\201019_2253_final_Angular_Top_1_Custom-MAE\\Synth_TD\\CNN_Base_32_Model_and_Weights_80000.hdf5\n",
      "2500/2500 [==============================] - 264s 105ms/step - loss: 672.4301 - custom_mae: 11.8134 - val_loss: 736.2451 - val_custom_mae: 11.9849\n",
      "Epoch 43/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 670.2532 - custom_mae: 11.8079\n",
      "Epoch 00043: val_custom_mae did not improve from 11.98492\n",
      "2500/2500 [==============================] - 258s 103ms/step - loss: 670.6447 - custom_mae: 11.8096 - val_loss: 756.7769 - val_custom_mae: 12.4601\n",
      "Epoch 44/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 669.5918 - custom_mae: 11.6438\n",
      "Epoch 00044: val_custom_mae did not improve from 11.98492\n",
      "2500/2500 [==============================] - 258s 103ms/step - loss: 669.3899 - custom_mae: 11.6425 - val_loss: 816.2203 - val_custom_mae: 13.0393\n",
      "Epoch 45/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 654.5458 - custom_mae: 11.5571- ETA: 0s - loss: 654.5270 - custom_mae\n",
      "Epoch 00045: val_custom_mae improved from 11.98492 to 11.88813, saving model to ..\\fast_output\\SYNTH_Regression_MSE\\201019_2253_final_Angular_Top_1_Custom-MAE\\Synth_TD\\CNN_Base_32_Model_and_Weights_80000.hdf5\n",
      "2500/2500 [==============================] - 264s 105ms/step - loss: 654.3977 - custom_mae: 11.5559 - val_loss: 720.7702 - val_custom_mae: 11.8881\n",
      "Epoch 46/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 648.2901 - custom_mae: 11.4323\n",
      "Epoch 00046: val_custom_mae did not improve from 11.88813\n",
      "2500/2500 [==============================] - 258s 103ms/step - loss: 648.5121 - custom_mae: 11.4343 - val_loss: 779.5576 - val_custom_mae: 12.7789\n",
      "Epoch 47/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 647.2650 - custom_mae: 11.4102\n",
      "Epoch 00047: val_custom_mae did not improve from 11.88813\n",
      "2500/2500 [==============================] - 258s 103ms/step - loss: 647.1092 - custom_mae: 11.4091 - val_loss: 744.9821 - val_custom_mae: 12.0484\n",
      "Epoch 48/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 639.7320 - custom_mae: 11.3119\n",
      "Epoch 00048: val_custom_mae did not improve from 11.88813\n",
      "2500/2500 [==============================] - 258s 103ms/step - loss: 639.5722 - custom_mae: 11.3113 - val_loss: 736.1089 - val_custom_mae: 12.1806\n",
      "Epoch 49/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 626.2975 - custom_mae: 11.1541\n",
      "Epoch 00049: val_custom_mae improved from 11.88813 to 11.68621, saving model to ..\\fast_output\\SYNTH_Regression_MSE\\201019_2253_final_Angular_Top_1_Custom-MAE\\Synth_TD\\CNN_Base_32_Model_and_Weights_80000.hdf5\n",
      "2500/2500 [==============================] - 263s 105ms/step - loss: 626.5407 - custom_mae: 11.1554 - val_loss: 741.3730 - val_custom_mae: 11.6862\n",
      "Epoch 50/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 624.0013 - custom_mae: 11.0580- ETA: 2s - loss: 6\n",
      "Epoch 00050: val_custom_mae improved from 11.68621 to 11.42571, saving model to ..\\fast_output\\SYNTH_Regression_MSE\\201019_2253_final_Angular_Top_1_Custom-MAE\\Synth_TD\\CNN_Base_32_Model_and_Weights_80000.hdf5\n",
      "2500/2500 [==============================] - 264s 105ms/step - loss: 623.9340 - custom_mae: 11.0576 - val_loss: 702.2141 - val_custom_mae: 11.4257\n",
      "Epoch 51/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2499/2500 [============================>.] - ETA: 0s - loss: 621.2669 - custom_mae: 11.0631- ETA: 2s - loss: 622.3814 - cus - ETA: 0s - loss: 621.8895 - custom_ma\n",
      "Epoch 00051: val_custom_mae did not improve from 11.42571\n",
      "2500/2500 [==============================] - 258s 103ms/step - loss: 621.3205 - custom_mae: 11.0637 - val_loss: 730.9376 - val_custom_mae: 11.7770\n",
      "Epoch 52/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 613.9469 - custom_mae: 10.9458\n",
      "Epoch 00052: val_custom_mae improved from 11.42571 to 11.24962, saving model to ..\\fast_output\\SYNTH_Regression_MSE\\201019_2253_final_Angular_Top_1_Custom-MAE\\Synth_TD\\CNN_Base_32_Model_and_Weights_80000.hdf5\n",
      "2500/2500 [==============================] - 264s 106ms/step - loss: 613.9889 - custom_mae: 10.9465 - val_loss: 700.6134 - val_custom_mae: 11.2496\n",
      "Epoch 53/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 610.7838 - custom_mae: 10.8387- ETA: 1s - loss: 611.1177 - custom_m\n",
      "Epoch 00053: val_custom_mae improved from 11.24962 to 11.01536, saving model to ..\\fast_output\\SYNTH_Regression_MSE\\201019_2253_final_Angular_Top_1_Custom-MAE\\Synth_TD\\CNN_Base_32_Model_and_Weights_80000.hdf5\n",
      "2500/2500 [==============================] - 264s 106ms/step - loss: 611.0715 - custom_mae: 10.8411 - val_loss: 689.5042 - val_custom_mae: 11.0154\n",
      "Epoch 54/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 608.2225 - custom_mae: 10.8429\n",
      "Epoch 00054: val_custom_mae improved from 11.01536 to 10.97032, saving model to ..\\fast_output\\SYNTH_Regression_MSE\\201019_2253_final_Angular_Top_1_Custom-MAE\\Synth_TD\\CNN_Base_32_Model_and_Weights_80000.hdf5\n",
      "2500/2500 [==============================] - 264s 106ms/step - loss: 608.1735 - custom_mae: 10.8423 - val_loss: 684.0159 - val_custom_mae: 10.9703\n",
      "Epoch 55/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 605.3410 - custom_mae: 10.7131- ETA: 6s - loss: 603.\n",
      "Epoch 00055: val_custom_mae did not improve from 10.97032\n",
      "2500/2500 [==============================] - 259s 104ms/step - loss: 605.1689 - custom_mae: 10.7120 - val_loss: 673.6404 - val_custom_mae: 11.3098\n",
      "Epoch 56/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 597.1847 - custom_mae: 10.6436\n",
      "Epoch 00056: val_custom_mae improved from 10.97032 to 10.78169, saving model to ..\\fast_output\\SYNTH_Regression_MSE\\201019_2253_final_Angular_Top_1_Custom-MAE\\Synth_TD\\CNN_Base_32_Model_and_Weights_80000.hdf5\n",
      "2500/2500 [==============================] - 263s 105ms/step - loss: 597.4022 - custom_mae: 10.6446 - val_loss: 680.4285 - val_custom_mae: 10.7817\n",
      "Epoch 57/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 592.8180 - custom_mae: 10.5787\n",
      "Epoch 00057: val_custom_mae improved from 10.78169 to 10.73231, saving model to ..\\fast_output\\SYNTH_Regression_MSE\\201019_2253_final_Angular_Top_1_Custom-MAE\\Synth_TD\\CNN_Base_32_Model_and_Weights_80000.hdf5\n",
      "2500/2500 [==============================] - 264s 106ms/step - loss: 592.7654 - custom_mae: 10.5783 - val_loss: 670.4358 - val_custom_mae: 10.7323\n",
      "Epoch 58/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 588.8904 - custom_mae: 10.5236\n",
      "Epoch 00058: val_custom_mae did not improve from 10.73231\n",
      "2500/2500 [==============================] - 259s 103ms/step - loss: 589.1647 - custom_mae: 10.5252 - val_loss: 676.5676 - val_custom_mae: 10.7643\n",
      "Epoch 59/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 583.0732 - custom_mae: 10.4455\n",
      "Epoch 00059: val_custom_mae did not improve from 10.73231\n",
      "2500/2500 [==============================] - 258s 103ms/step - loss: 583.2025 - custom_mae: 10.4457 - val_loss: 674.2885 - val_custom_mae: 10.8999\n",
      "Epoch 60/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 579.3461 - custom_mae: 10.3357- E\n",
      "Epoch 00060: val_custom_mae did not improve from 10.73231\n",
      "2500/2500 [==============================] - 259s 103ms/step - loss: 579.4982 - custom_mae: 10.3361 - val_loss: 679.0424 - val_custom_mae: 10.8573\n",
      "Epoch 61/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 568.6784 - custom_mae: 10.2677\n",
      "Epoch 00061: val_custom_mae did not improve from 10.73231\n",
      "2500/2500 [==============================] - 259s 103ms/step - loss: 568.7721 - custom_mae: 10.2678 - val_loss: 686.7211 - val_custom_mae: 10.9593\n",
      "Epoch 62/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 581.6944 - custom_mae: 10.2932\n",
      "Epoch 00062: val_custom_mae did not improve from 10.73231\n",
      "2500/2500 [==============================] - 258s 103ms/step - loss: 581.5818 - custom_mae: 10.2925 - val_loss: 671.0864 - val_custom_mae: 11.1224\n",
      "Epoch 63/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 566.9676 - custom_mae: 10.1560- ETA: 2s - loss: 567.7962 - custom - ETA: 1s - loss: 567.7440 - custom_mae - ETA: 0s - loss: 567.0864 - custom_mae: 10.\n",
      "Epoch 00063: val_custom_mae improved from 10.73231 to 10.59355, saving model to ..\\fast_output\\SYNTH_Regression_MSE\\201019_2253_final_Angular_Top_1_Custom-MAE\\Synth_TD\\CNN_Base_32_Model_and_Weights_80000.hdf5\n",
      "2500/2500 [==============================] - 264s 106ms/step - loss: 566.8054 - custom_mae: 10.1552 - val_loss: 662.8451 - val_custom_mae: 10.5935\n",
      "Epoch 64/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 568.5095 - custom_mae: 10.1207\n",
      "Epoch 00064: val_custom_mae did not improve from 10.59355\n",
      "2500/2500 [==============================] - 260s 104ms/step - loss: 568.3159 - custom_mae: 10.1193 - val_loss: 655.0589 - val_custom_mae: 10.7131\n",
      "Epoch 65/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 564.5241 - custom_mae: 10.1021\n",
      "Epoch 00065: val_custom_mae improved from 10.59355 to 10.39332, saving model to ..\\fast_output\\SYNTH_Regression_MSE\\201019_2253_final_Angular_Top_1_Custom-MAE\\Synth_TD\\CNN_Base_32_Model_and_Weights_80000.hdf5\n",
      "2500/2500 [==============================] - 264s 106ms/step - loss: 564.5361 - custom_mae: 10.1020 - val_loss: 645.6225 - val_custom_mae: 10.3933\n",
      "Epoch 66/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 558.1212 - custom_mae: 10.0087\n",
      "Epoch 00066: val_custom_mae did not improve from 10.39332\n",
      "2500/2500 [==============================] - 259s 103ms/step - loss: 558.1819 - custom_mae: 10.0090 - val_loss: 667.1950 - val_custom_mae: 10.6386\n",
      "Epoch 67/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 549.4770 - custom_mae: 9.9205\n",
      "Epoch 00067: val_custom_mae did not improve from 10.39332\n",
      "2500/2500 [==============================] - 259s 104ms/step - loss: 549.3352 - custom_mae: 9.9193 - val_loss: 627.2196 - val_custom_mae: 10.4941\n",
      "Epoch 68/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 547.5481 - custom_mae: 9.8721\n",
      "Epoch 00068: val_custom_mae improved from 10.39332 to 10.05414, saving model to ..\\fast_output\\SYNTH_Regression_MSE\\201019_2253_final_Angular_Top_1_Custom-MAE\\Synth_TD\\CNN_Base_32_Model_and_Weights_80000.hdf5\n",
      "2500/2500 [==============================] - 264s 106ms/step - loss: 547.7486 - custom_mae: 9.8736 - val_loss: 659.4097 - val_custom_mae: 10.0541\n",
      "Epoch 69/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 550.7478 - custom_mae: 9.8670\n",
      "Epoch 00069: val_custom_mae did not improve from 10.05414\n",
      "2500/2500 [==============================] - 259s 104ms/step - loss: 551.0364 - custom_mae: 9.8680 - val_loss: 633.5764 - val_custom_mae: 10.3234\n",
      "Epoch 70/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 547.1985 - custom_mae: 9.8288\n",
      "Epoch 00070: val_custom_mae did not improve from 10.05414\n",
      "2500/2500 [==============================] - 259s 104ms/step - loss: 547.1085 - custom_mae: 9.8283 - val_loss: 638.4378 - val_custom_mae: 10.2446\n",
      "Epoch 71/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 539.5585 - custom_mae: 9.7655\n",
      "Epoch 00071: val_custom_mae did not improve from 10.05414\n",
      "2500/2500 [==============================] - 259s 104ms/step - loss: 539.8612 - custom_mae: 9.7675 - val_loss: 626.3806 - val_custom_mae: 10.1506\n",
      "Epoch 72/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 535.1765 - custom_mae: 9.6705\n",
      "Epoch 00072: val_custom_mae did not improve from 10.05414\n",
      "2500/2500 [==============================] - 259s 104ms/step - loss: 534.9991 - custom_mae: 9.6693 - val_loss: 713.5165 - val_custom_mae: 10.6324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 536.5152 - custom_mae: 9.6406\n",
      "Epoch 00073: val_custom_mae improved from 10.05414 to 10.02878, saving model to ..\\fast_output\\SYNTH_Regression_MSE\\201019_2253_final_Angular_Top_1_Custom-MAE\\Synth_TD\\CNN_Base_32_Model_and_Weights_80000.hdf5\n",
      "2500/2500 [==============================] - 264s 106ms/step - loss: 536.4240 - custom_mae: 9.6402 - val_loss: 634.5762 - val_custom_mae: 10.0288\n",
      "Epoch 74/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 539.3063 - custom_mae: 9.6556\n",
      "Epoch 00074: val_custom_mae did not improve from 10.02878\n",
      "2500/2500 [==============================] - 259s 104ms/step - loss: 539.4798 - custom_mae: 9.6555 - val_loss: 640.2142 - val_custom_mae: 10.0399\n",
      "Epoch 75/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 529.9863 - custom_mae: 9.5674\n",
      "Epoch 00075: val_custom_mae did not improve from 10.02878\n",
      "2500/2500 [==============================] - 259s 104ms/step - loss: 529.8565 - custom_mae: 9.5669 - val_loss: 630.6220 - val_custom_mae: 10.2489\n",
      "Epoch 76/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 528.8648 - custom_mae: 9.5026\n",
      "Epoch 00076: val_custom_mae improved from 10.02878 to 9.90119, saving model to ..\\fast_output\\SYNTH_Regression_MSE\\201019_2253_final_Angular_Top_1_Custom-MAE\\Synth_TD\\CNN_Base_32_Model_and_Weights_80000.hdf5\n",
      "2500/2500 [==============================] - 265s 106ms/step - loss: 528.9245 - custom_mae: 9.5039 - val_loss: 625.8524 - val_custom_mae: 9.9012\n",
      "Epoch 77/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 531.7303 - custom_mae: 9.4957\n",
      "Epoch 00077: val_custom_mae improved from 9.90119 to 9.74415, saving model to ..\\fast_output\\SYNTH_Regression_MSE\\201019_2253_final_Angular_Top_1_Custom-MAE\\Synth_TD\\CNN_Base_32_Model_and_Weights_80000.hdf5\n",
      "2500/2500 [==============================] - 266s 106ms/step - loss: 531.8596 - custom_mae: 9.4959 - val_loss: 620.4344 - val_custom_mae: 9.7441\n",
      "Epoch 78/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 521.8802 - custom_mae: 9.4167 ETA: 0s - loss: 522.1554 - custom_mae: \n",
      "Epoch 00078: val_custom_mae did not improve from 9.74415\n",
      "2500/2500 [==============================] - 259s 104ms/step - loss: 521.6970 - custom_mae: 9.4152 - val_loss: 648.6108 - val_custom_mae: 9.9273\n",
      "Epoch 79/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 521.1761 - custom_mae: 9.3915\n",
      "Epoch 00079: val_custom_mae did not improve from 9.74415\n",
      "2500/2500 [==============================] - 259s 104ms/step - loss: 521.2076 - custom_mae: 9.3915 - val_loss: 631.7232 - val_custom_mae: 9.9218\n",
      "Epoch 80/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 519.9641 - custom_mae: 9.3374\n",
      "Epoch 00080: val_custom_mae did not improve from 9.74415\n",
      "2500/2500 [==============================] - 259s 104ms/step - loss: 520.0352 - custom_mae: 9.3380 - val_loss: 623.4986 - val_custom_mae: 10.1084\n",
      "Epoch 81/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 516.4407 - custom_mae: 9.3064\n",
      "Epoch 00081: val_custom_mae did not improve from 9.74415\n",
      "2500/2500 [==============================] - 259s 104ms/step - loss: 516.6845 - custom_mae: 9.3075 - val_loss: 625.9910 - val_custom_mae: 10.2756\n",
      "Epoch 82/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 522.1924 - custom_mae: 9.2881\n",
      "Epoch 00082: val_custom_mae improved from 9.74415 to 9.65467, saving model to ..\\fast_output\\SYNTH_Regression_MSE\\201019_2253_final_Angular_Top_1_Custom-MAE\\Synth_TD\\CNN_Base_32_Model_and_Weights_80000.hdf5\n",
      "2500/2500 [==============================] - 265s 106ms/step - loss: 522.0219 - custom_mae: 9.2871 - val_loss: 627.1946 - val_custom_mae: 9.6547\n",
      "Epoch 83/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 511.1657 - custom_mae: 9.2180\n",
      "Epoch 00083: val_custom_mae did not improve from 9.65467\n",
      "2500/2500 [==============================] - 260s 104ms/step - loss: 511.5172 - custom_mae: 9.2202 - val_loss: 620.0484 - val_custom_mae: 9.8286\n",
      "Epoch 84/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 513.5917 - custom_mae: 9.1801\n",
      "Epoch 00084: val_custom_mae improved from 9.65467 to 9.52797, saving model to ..\\fast_output\\SYNTH_Regression_MSE\\201019_2253_final_Angular_Top_1_Custom-MAE\\Synth_TD\\CNN_Base_32_Model_and_Weights_80000.hdf5\n",
      "2500/2500 [==============================] - 265s 106ms/step - loss: 513.6376 - custom_mae: 9.1802 - val_loss: 619.0627 - val_custom_mae: 9.5280\n",
      "Epoch 85/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 519.1090 - custom_mae: 9.2163 ETA: 0s - loss: 518.4208 - \n",
      "Epoch 00085: val_custom_mae did not improve from 9.52797\n",
      "2500/2500 [==============================] - 260s 104ms/step - loss: 518.9524 - custom_mae: 9.2154 - val_loss: 636.8658 - val_custom_mae: 9.9727\n",
      "Epoch 86/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 508.8972 - custom_mae: 9.1236\n",
      "Epoch 00086: val_custom_mae did not improve from 9.52797\n",
      "2500/2500 [==============================] - 259s 104ms/step - loss: 509.0065 - custom_mae: 9.1245 - val_loss: 650.5207 - val_custom_mae: 9.8264\n",
      "Epoch 87/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 501.1312 - custom_mae: 9.0565 ETA: 2s - loss: 502.5569 - custom_m\n",
      "Epoch 00087: val_custom_mae improved from 9.52797 to 9.44196, saving model to ..\\fast_output\\SYNTH_Regression_MSE\\201019_2253_final_Angular_Top_1_Custom-MAE\\Synth_TD\\CNN_Base_32_Model_and_Weights_80000.hdf5\n",
      "2500/2500 [==============================] - 265s 106ms/step - loss: 501.2189 - custom_mae: 9.0571 - val_loss: 604.6310 - val_custom_mae: 9.4420\n",
      "Epoch 88/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 505.3414 - custom_mae: 9.0715\n",
      "Epoch 00088: val_custom_mae did not improve from 9.44196\n",
      "2500/2500 [==============================] - 260s 104ms/step - loss: 505.2401 - custom_mae: 9.0707 - val_loss: 615.7326 - val_custom_mae: 10.0274\n",
      "Epoch 89/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 503.6911 - custom_mae: 9.0346\n",
      "Epoch 00089: val_custom_mae did not improve from 9.44196\n",
      "2500/2500 [==============================] - 259s 104ms/step - loss: 503.6103 - custom_mae: 9.0343 - val_loss: 637.9644 - val_custom_mae: 9.6939\n",
      "Epoch 90/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 500.9724 - custom_mae: 8.9853\n",
      "Epoch 00090: val_custom_mae did not improve from 9.44196\n",
      "2500/2500 [==============================] - 259s 104ms/step - loss: 501.2713 - custom_mae: 8.9872 - val_loss: 616.2746 - val_custom_mae: 9.6086\n",
      "Epoch 91/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 506.7037 - custom_mae: 8.9853\n",
      "Epoch 00091: val_custom_mae improved from 9.44196 to 9.36165, saving model to ..\\fast_output\\SYNTH_Regression_MSE\\201019_2253_final_Angular_Top_1_Custom-MAE\\Synth_TD\\CNN_Base_32_Model_and_Weights_80000.hdf5\n",
      "2500/2500 [==============================] - 265s 106ms/step - loss: 506.9851 - custom_mae: 8.9872 - val_loss: 593.7853 - val_custom_mae: 9.3616\n",
      "Epoch 92/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 499.2251 - custom_mae: 8.9083\n",
      "Epoch 00092: val_custom_mae improved from 9.36165 to 9.34310, saving model to ..\\fast_output\\SYNTH_Regression_MSE\\201019_2253_final_Angular_Top_1_Custom-MAE\\Synth_TD\\CNN_Base_32_Model_and_Weights_80000.hdf5\n",
      "2500/2500 [==============================] - 265s 106ms/step - loss: 499.2206 - custom_mae: 8.9089 - val_loss: 600.9071 - val_custom_mae: 9.3431\n",
      "Epoch 93/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 505.0049 - custom_mae: 8.9303\n",
      "Epoch 00093: val_custom_mae did not improve from 9.34310\n",
      "2500/2500 [==============================] - 259s 104ms/step - loss: 505.4973 - custom_mae: 8.9328 - val_loss: 625.3079 - val_custom_mae: 9.4735\n",
      "Epoch 94/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 494.9723 - custom_mae: 8.8276 ETA: 0s - loss: 494.7472 - custom - ETA: 0s - loss: 494.9859 - custom_mae: 8.\n",
      "Epoch 00094: val_custom_mae did not improve from 9.34310\n",
      "2500/2500 [==============================] - 260s 104ms/step - loss: 495.0721 - custom_mae: 8.8279 - val_loss: 593.7249 - val_custom_mae: 9.4001\n",
      "Epoch 95/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2499/2500 [============================>.] - ETA: 0s - loss: 494.4797 - custom_mae: 8.8308 ETA: 5s - loss: 4 - ETA: 3s\n",
      "Epoch 00095: val_custom_mae improved from 9.34310 to 9.27312, saving model to ..\\fast_output\\SYNTH_Regression_MSE\\201019_2253_final_Angular_Top_1_Custom-MAE\\Synth_TD\\CNN_Base_32_Model_and_Weights_80000.hdf5\n",
      "2500/2500 [==============================] - 265s 106ms/step - loss: 494.5451 - custom_mae: 8.8315 - val_loss: 584.8192 - val_custom_mae: 9.2731\n",
      "Epoch 96/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 490.1615 - custom_mae: 8.8151\n",
      "Epoch 00096: val_custom_mae did not improve from 9.27312\n",
      "2500/2500 [==============================] - 260s 104ms/step - loss: 490.0508 - custom_mae: 8.8149 - val_loss: 658.1460 - val_custom_mae: 9.6869\n",
      "Epoch 97/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 483.9288 - custom_mae: 8.7345\n",
      "Epoch 00097: val_custom_mae did not improve from 9.27312\n",
      "2500/2500 [==============================] - 259s 104ms/step - loss: 483.8272 - custom_mae: 8.7336 - val_loss: 585.2310 - val_custom_mae: 9.3183\n",
      "Epoch 98/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 491.9590 - custom_mae: 8.7440\n",
      "Epoch 00098: val_custom_mae did not improve from 9.27312\n",
      "2500/2500 [==============================] - 260s 104ms/step - loss: 491.9507 - custom_mae: 8.7441 - val_loss: 579.3223 - val_custom_mae: 9.2768\n",
      "Epoch 99/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 486.0124 - custom_mae: 8.6854\n",
      "Epoch 00099: val_custom_mae improved from 9.27312 to 9.20018, saving model to ..\\fast_output\\SYNTH_Regression_MSE\\201019_2253_final_Angular_Top_1_Custom-MAE\\Synth_TD\\CNN_Base_32_Model_and_Weights_80000.hdf5\n",
      "2500/2500 [==============================] - 265s 106ms/step - loss: 485.8601 - custom_mae: 8.6846 - val_loss: 586.4070 - val_custom_mae: 9.2002\n",
      "Epoch 100/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 486.1265 - custom_mae: 8.6898\n",
      "Epoch 00100: val_custom_mae did not improve from 9.20018\n",
      "2500/2500 [==============================] - 260s 104ms/step - loss: 485.9685 - custom_mae: 8.6887 - val_loss: 604.9126 - val_custom_mae: 9.2803\n",
      "Epoch 101/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 488.1382 - custom_mae: 8.7011 ETA: 3s - loss: 487\n",
      "Epoch 00101: val_custom_mae did not improve from 9.20018\n",
      "2500/2500 [==============================] - 259s 104ms/step - loss: 488.1747 - custom_mae: 8.7017 - val_loss: 603.6763 - val_custom_mae: 9.4266\n",
      "Epoch 102/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 477.1967 - custom_mae: 8.6210\n",
      "Epoch 00102: val_custom_mae did not improve from 9.20018\n",
      "2500/2500 [==============================] - 259s 104ms/step - loss: 477.1965 - custom_mae: 8.6211 - val_loss: 600.8405 - val_custom_mae: 9.5685\n",
      "Epoch 103/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 482.1916 - custom_mae: 8.6159\n",
      "Epoch 00103: val_custom_mae improved from 9.20018 to 9.12058, saving model to ..\\fast_output\\SYNTH_Regression_MSE\\201019_2253_final_Angular_Top_1_Custom-MAE\\Synth_TD\\CNN_Base_32_Model_and_Weights_80000.hdf5\n",
      "2500/2500 [==============================] - 265s 106ms/step - loss: 482.1065 - custom_mae: 8.6151 - val_loss: 577.6046 - val_custom_mae: 9.1206\n",
      "Epoch 104/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 483.0405 - custom_mae: 8.6085\n",
      "Epoch 00104: val_custom_mae did not improve from 9.12058\n",
      "2500/2500 [==============================] - 260s 104ms/step - loss: 482.9822 - custom_mae: 8.6079 - val_loss: 593.3201 - val_custom_mae: 9.3081\n",
      "Epoch 105/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 475.4642 - custom_mae: 8.5409\n",
      "Epoch 00105: val_custom_mae did not improve from 9.12058\n",
      "2500/2500 [==============================] - 259s 104ms/step - loss: 475.5946 - custom_mae: 8.5418 - val_loss: 599.1812 - val_custom_mae: 9.1267\n",
      "Epoch 106/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 466.0514 - custom_mae: 8.4888\n",
      "Epoch 00106: val_custom_mae did not improve from 9.12058\n",
      "2500/2500 [==============================] - 260s 104ms/step - loss: 466.3022 - custom_mae: 8.4900 - val_loss: 621.4568 - val_custom_mae: 9.5233\n",
      "Epoch 107/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 479.3437 - custom_mae: 8.5290\n",
      "Epoch 00107: val_custom_mae did not improve from 9.12058\n",
      "2500/2500 [==============================] - 260s 104ms/step - loss: 479.5386 - custom_mae: 8.5305 - val_loss: 603.9452 - val_custom_mae: 9.1788\n",
      "Epoch 108/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 476.2605 - custom_mae: 8.5053\n",
      "Epoch 00108: val_custom_mae did not improve from 9.12058\n",
      "2500/2500 [==============================] - 260s 104ms/step - loss: 476.2610 - custom_mae: 8.5054 - val_loss: 589.7113 - val_custom_mae: 9.2693\n",
      "Epoch 109/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 470.7702 - custom_mae: 8.4733\n",
      "Epoch 00109: val_custom_mae improved from 9.12058 to 9.07977, saving model to ..\\fast_output\\SYNTH_Regression_MSE\\201019_2253_final_Angular_Top_1_Custom-MAE\\Synth_TD\\CNN_Base_32_Model_and_Weights_80000.hdf5\n",
      "2500/2500 [==============================] - 265s 106ms/step - loss: 470.6126 - custom_mae: 8.4723 - val_loss: 582.2702 - val_custom_mae: 9.0798\n",
      "Epoch 110/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 475.4160 - custom_mae: 8.4392\n",
      "Epoch 00110: val_custom_mae did not improve from 9.07977\n",
      "2500/2500 [==============================] - 260s 104ms/step - loss: 475.2818 - custom_mae: 8.4384 - val_loss: 604.2322 - val_custom_mae: 9.2515\n",
      "Epoch 111/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 470.7042 - custom_mae: 8.4097\n",
      "Epoch 00111: val_custom_mae did not improve from 9.07977\n",
      "2500/2500 [==============================] - 260s 104ms/step - loss: 470.9748 - custom_mae: 8.4102 - val_loss: 598.8458 - val_custom_mae: 9.1845\n",
      "Epoch 112/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 467.9449 - custom_mae: 8.3789\n",
      "Epoch 00112: val_custom_mae did not improve from 9.07977\n",
      "2500/2500 [==============================] - 260s 104ms/step - loss: 467.9398 - custom_mae: 8.3786 - val_loss: 663.9536 - val_custom_mae: 9.1575\n",
      "Epoch 113/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 461.6602 - custom_mae: 8.3311\n",
      "Epoch 00113: val_custom_mae improved from 9.07977 to 8.67124, saving model to ..\\fast_output\\SYNTH_Regression_MSE\\201019_2253_final_Angular_Top_1_Custom-MAE\\Synth_TD\\CNN_Base_32_Model_and_Weights_80000.hdf5\n",
      "2500/2500 [==============================] - 266s 106ms/step - loss: 462.0771 - custom_mae: 8.3318 - val_loss: 566.4824 - val_custom_mae: 8.6712\n",
      "Epoch 114/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 474.6727 - custom_mae: 8.3796\n",
      "Epoch 00114: val_custom_mae did not improve from 8.67124\n",
      "2500/2500 [==============================] - 261s 104ms/step - loss: 474.7059 - custom_mae: 8.3796 - val_loss: 556.2905 - val_custom_mae: 8.8647\n",
      "Epoch 115/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 463.8303 - custom_mae: 8.2911\n",
      "Epoch 00115: val_custom_mae did not improve from 8.67124\n",
      "2500/2500 [==============================] - 260s 104ms/step - loss: 463.8485 - custom_mae: 8.2916 - val_loss: 595.2320 - val_custom_mae: 9.3239\n",
      "Epoch 116/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 466.5291 - custom_mae: 8.3288 ETA: 0s - loss: 466.6395 - custom_mae: 8.\n",
      "Epoch 00116: val_custom_mae did not improve from 8.67124\n",
      "2500/2500 [==============================] - 260s 104ms/step - loss: 466.6486 - custom_mae: 8.3298 - val_loss: 610.1405 - val_custom_mae: 8.9010\n",
      "Epoch 117/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 466.7143 - custom_mae: 8.2757 ETA: 5s\n",
      "Epoch 00117: val_custom_mae did not improve from 8.67124\n",
      "2500/2500 [==============================] - 260s 104ms/step - loss: 466.7868 - custom_mae: 8.2767 - val_loss: 596.0274 - val_custom_mae: 8.9266\n",
      "Epoch 118/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 463.2836 - custom_mae: 8.2512\n",
      "Epoch 00118: val_custom_mae did not improve from 8.67124\n",
      "2500/2500 [==============================] - 260s 104ms/step - loss: 463.2726 - custom_mae: 8.2509 - val_loss: 595.2146 - val_custom_mae: 8.8105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 466.1935 - custom_mae: 8.2425 ETA\n",
      "Epoch 00119: val_custom_mae did not improve from 8.67124\n",
      "2500/2500 [==============================] - 260s 104ms/step - loss: 466.0859 - custom_mae: 8.2420 - val_loss: 634.0714 - val_custom_mae: 9.0639\n",
      "Epoch 120/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 457.6205 - custom_mae: 8.1983\n",
      "Epoch 00120: val_custom_mae did not improve from 8.67124\n",
      "2500/2500 [==============================] - 260s 104ms/step - loss: 457.8822 - custom_mae: 8.1998 - val_loss: 594.1974 - val_custom_mae: 9.0672\n",
      "Epoch 121/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 461.1258 - custom_mae: 8.1645\n",
      "Epoch 00121: val_custom_mae did not improve from 8.67124\n",
      "2500/2500 [==============================] - 260s 104ms/step - loss: 460.9573 - custom_mae: 8.1629 - val_loss: 579.1393 - val_custom_mae: 8.6823\n",
      "Epoch 122/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 455.6953 - custom_mae: 8.1513 ETA: 0s - loss: 455.6642 - custom_mae: 8.15\n",
      "Epoch 00122: val_custom_mae did not improve from 8.67124\n",
      "2500/2500 [==============================] - 261s 104ms/step - loss: 455.5472 - custom_mae: 8.1504 - val_loss: 589.8630 - val_custom_mae: 8.9309\n",
      "Epoch 123/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 458.3793 - custom_mae: 8.1566\n",
      "Epoch 00123: val_custom_mae did not improve from 8.67124\n",
      "2500/2500 [==============================] - 260s 104ms/step - loss: 458.3998 - custom_mae: 8.1567 - val_loss: 583.4857 - val_custom_mae: 8.8146\n",
      "Epoch 124/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 462.9202 - custom_mae: 8.1524\n",
      "Epoch 00124: val_custom_mae improved from 8.67124 to 8.55608, saving model to ..\\fast_output\\SYNTH_Regression_MSE\\201019_2253_final_Angular_Top_1_Custom-MAE\\Synth_TD\\CNN_Base_32_Model_and_Weights_80000.hdf5\n",
      "2500/2500 [==============================] - 265s 106ms/step - loss: 462.7647 - custom_mae: 8.1514 - val_loss: 576.5342 - val_custom_mae: 8.5561\n",
      "Epoch 125/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 455.5750 - custom_mae: 8.1186\n",
      "Epoch 00125: val_custom_mae did not improve from 8.55608\n",
      "2500/2500 [==============================] - 260s 104ms/step - loss: 455.6352 - custom_mae: 8.1193 - val_loss: 603.2057 - val_custom_mae: 8.8967\n",
      "Epoch 126/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 457.7783 - custom_mae: 8.1101 - ETA: 5s - loss: 458.524\n",
      "Epoch 00126: val_custom_mae did not improve from 8.55608\n",
      "2500/2500 [==============================] - 260s 104ms/step - loss: 457.6937 - custom_mae: 8.1102 - val_loss: 596.7539 - val_custom_mae: 8.9567\n",
      "Epoch 127/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 452.5310 - custom_mae: 8.0545 - ETA: - ETA: 5s - l\n",
      "Epoch 00127: val_custom_mae did not improve from 8.55608\n",
      "\n",
      "Epoch 00127: ReduceLROnPlateau reducing learning rate to 5.000000000000001e-07.\n",
      "2500/2500 [==============================] - 260s 104ms/step - loss: 452.5754 - custom_mae: 8.0549 - val_loss: 577.8730 - val_custom_mae: 8.6989\n",
      "Epoch 128/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 420.6761 - custom_mae: 7.6760\n",
      "Epoch 00128: val_custom_mae improved from 8.55608 to 8.33224, saving model to ..\\fast_output\\SYNTH_Regression_MSE\\201019_2253_final_Angular_Top_1_Custom-MAE\\Synth_TD\\CNN_Base_32_Model_and_Weights_80000.hdf5\n",
      "2500/2500 [==============================] - 266s 106ms/step - loss: 420.7337 - custom_mae: 7.6764 - val_loss: 549.8661 - val_custom_mae: 8.3322\n",
      "Epoch 129/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 408.6208 - custom_mae: 7.5720\n",
      "Epoch 00129: val_custom_mae improved from 8.33224 to 8.28937, saving model to ..\\fast_output\\SYNTH_Regression_MSE\\201019_2253_final_Angular_Top_1_Custom-MAE\\Synth_TD\\CNN_Base_32_Model_and_Weights_80000.hdf5\n",
      "2500/2500 [==============================] - 266s 107ms/step - loss: 408.7146 - custom_mae: 7.5722 - val_loss: 542.4651 - val_custom_mae: 8.2894\n",
      "Epoch 130/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 404.8159 - custom_mae: 7.5426\n",
      "Epoch 00130: val_custom_mae improved from 8.28937 to 8.21715, saving model to ..\\fast_output\\SYNTH_Regression_MSE\\201019_2253_final_Angular_Top_1_Custom-MAE\\Synth_TD\\CNN_Base_32_Model_and_Weights_80000.hdf5\n",
      "2500/2500 [==============================] - 266s 107ms/step - loss: 404.9785 - custom_mae: 7.5436 - val_loss: 535.6905 - val_custom_mae: 8.2171\n",
      "Epoch 131/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 408.2141 - custom_mae: 7.4866\n",
      "Epoch 00131: val_custom_mae did not improve from 8.21715\n",
      "2500/2500 [==============================] - 261s 104ms/step - loss: 408.1024 - custom_mae: 7.4859 - val_loss: 538.3999 - val_custom_mae: 8.3003\n",
      "Epoch 132/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 407.3092 - custom_mae: 7.4664\n",
      "Epoch 00132: val_custom_mae did not improve from 8.21715\n",
      "2500/2500 [==============================] - 261s 104ms/step - loss: 407.1751 - custom_mae: 7.4654 - val_loss: 535.0205 - val_custom_mae: 8.2202\n",
      "Epoch 133/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 405.4384 - custom_mae: 7.4872\n",
      "Epoch 00133: val_custom_mae improved from 8.21715 to 8.18810, saving model to ..\\fast_output\\SYNTH_Regression_MSE\\201019_2253_final_Angular_Top_1_Custom-MAE\\Synth_TD\\CNN_Base_32_Model_and_Weights_80000.hdf5\n",
      "2500/2500 [==============================] - 265s 106ms/step - loss: 405.2988 - custom_mae: 7.4864 - val_loss: 536.4332 - val_custom_mae: 8.1881\n",
      "Epoch 134/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 407.2155 - custom_mae: 7.4590\n",
      "Epoch 00134: val_custom_mae did not improve from 8.18810\n",
      "2500/2500 [==============================] - 260s 104ms/step - loss: 407.1647 - custom_mae: 7.4586 - val_loss: 541.1959 - val_custom_mae: 8.2318\n",
      "Epoch 135/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 404.9733 - custom_mae: 7.4633 ETA: 0s - loss: 404.3227 - cust\n",
      "Epoch 00135: val_custom_mae improved from 8.18810 to 8.13344, saving model to ..\\fast_output\\SYNTH_Regression_MSE\\201019_2253_final_Angular_Top_1_Custom-MAE\\Synth_TD\\CNN_Base_32_Model_and_Weights_80000.hdf5\n",
      "2500/2500 [==============================] - 266s 106ms/step - loss: 404.8362 - custom_mae: 7.4624 - val_loss: 530.8631 - val_custom_mae: 8.1334\n",
      "Epoch 136/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 408.1611 - custom_mae: 7.4723\n",
      "Epoch 00136: val_custom_mae did not improve from 8.13344\n",
      "2500/2500 [==============================] - 261s 104ms/step - loss: 408.0491 - custom_mae: 7.4720 - val_loss: 531.9409 - val_custom_mae: 8.1841\n",
      "Epoch 137/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 399.1876 - custom_mae: 7.4209\n",
      "Epoch 00137: val_custom_mae improved from 8.13344 to 8.12590, saving model to ..\\fast_output\\SYNTH_Regression_MSE\\201019_2253_final_Angular_Top_1_Custom-MAE\\Synth_TD\\CNN_Base_32_Model_and_Weights_80000.hdf5\n",
      "2500/2500 [==============================] - 266s 106ms/step - loss: 399.4059 - custom_mae: 7.4215 - val_loss: 533.3945 - val_custom_mae: 8.1259\n",
      "Epoch 138/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 400.3855 - custom_mae: 7.4303\n",
      "Epoch 00138: val_custom_mae did not improve from 8.12590\n",
      "2500/2500 [==============================] - 261s 104ms/step - loss: 400.5736 - custom_mae: 7.4316 - val_loss: 528.9983 - val_custom_mae: 8.1478\n",
      "Epoch 139/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 402.4760 - custom_mae: 7.4239\n",
      "Epoch 00139: val_custom_mae improved from 8.12590 to 8.12222, saving model to ..\\fast_output\\SYNTH_Regression_MSE\\201019_2253_final_Angular_Top_1_Custom-MAE\\Synth_TD\\CNN_Base_32_Model_and_Weights_80000.hdf5\n",
      "2500/2500 [==============================] - 265s 106ms/step - loss: 402.4738 - custom_mae: 7.4239 - val_loss: 530.7259 - val_custom_mae: 8.1222\n",
      "Epoch 140/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 400.5849 - custom_mae: 7.4052\n",
      "Epoch 00140: val_custom_mae did not improve from 8.12222\n",
      "2500/2500 [==============================] - 268s 107ms/step - loss: 400.5147 - custom_mae: 7.4048 - val_loss: 534.2050 - val_custom_mae: 8.2045\n",
      "Epoch 141/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2499/2500 [============================>.] - ETA: 0s - loss: 398.0684 - custom_mae: 7.3892\n",
      "Epoch 00141: val_custom_mae did not improve from 8.12222\n",
      "2500/2500 [==============================] - 261s 104ms/step - loss: 398.1868 - custom_mae: 7.3899 - val_loss: 533.7206 - val_custom_mae: 8.1289\n",
      "Epoch 142/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 399.9935 - custom_mae: 7.4095\n",
      "Epoch 00142: val_custom_mae did not improve from 8.12222\n",
      "2500/2500 [==============================] - 260s 104ms/step - loss: 399.8605 - custom_mae: 7.4084 - val_loss: 534.4983 - val_custom_mae: 8.1298\n",
      "Epoch 143/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 405.5488 - custom_mae: 7.4020 ETA - E - ETA\n",
      "Epoch 00143: val_custom_mae improved from 8.12222 to 8.06939, saving model to ..\\fast_output\\SYNTH_Regression_MSE\\201019_2253_final_Angular_Top_1_Custom-MAE\\Synth_TD\\CNN_Base_32_Model_and_Weights_80000.hdf5\n",
      "2500/2500 [==============================] - 266s 106ms/step - loss: 405.4508 - custom_mae: 7.4015 - val_loss: 530.6613 - val_custom_mae: 8.0694\n",
      "Epoch 144/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 397.7113 - custom_mae: 7.3840\n",
      "Epoch 00144: val_custom_mae did not improve from 8.06939\n",
      "2500/2500 [==============================] - 261s 104ms/step - loss: 397.5651 - custom_mae: 7.3827 - val_loss: 531.0860 - val_custom_mae: 8.0999\n",
      "Epoch 145/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 401.4370 - custom_mae: 7.4046 ETA: 0s - loss: 401.6259 - custom_m\n",
      "Epoch 00145: val_custom_mae did not improve from 8.06939\n",
      "2500/2500 [==============================] - 261s 105ms/step - loss: 401.4311 - custom_mae: 7.4047 - val_loss: 525.3307 - val_custom_mae: 8.0999\n",
      "Epoch 146/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 402.5518 - custom_mae: 7.4079\n",
      "Epoch 00146: val_custom_mae did not improve from 8.06939\n",
      "2500/2500 [==============================] - 260s 104ms/step - loss: 402.7908 - custom_mae: 7.4094 - val_loss: 527.0468 - val_custom_mae: 8.1225\n",
      "Epoch 147/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 395.7141 - custom_mae: 7.3794\n",
      "Epoch 00147: val_custom_mae did not improve from 8.06939\n",
      "2500/2500 [==============================] - 261s 104ms/step - loss: 395.6408 - custom_mae: 7.3789 - val_loss: 534.1554 - val_custom_mae: 8.1013\n",
      "Epoch 148/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 400.1984 - custom_mae: 7.3820 ETA: 9s - loss: - E\n",
      "Epoch 00148: val_custom_mae did not improve from 8.06939\n",
      "2500/2500 [==============================] - 261s 104ms/step - loss: 400.0851 - custom_mae: 7.3809 - val_loss: 527.6317 - val_custom_mae: 8.0715\n",
      "Epoch 149/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 395.8659 - custom_mae: 7.3530\n",
      "Epoch 00149: val_custom_mae did not improve from 8.06939\n",
      "2500/2500 [==============================] - 266s 106ms/step - loss: 395.7489 - custom_mae: 7.3525 - val_loss: 529.6737 - val_custom_mae: 8.0729\n",
      "Epoch 150/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 400.6805 - custom_mae: 7.3713\n",
      "Epoch 00150: val_custom_mae improved from 8.06939 to 8.05863, saving model to ..\\fast_output\\SYNTH_Regression_MSE\\201019_2253_final_Angular_Top_1_Custom-MAE\\Synth_TD\\CNN_Base_32_Model_and_Weights_80000.hdf5\n",
      "2500/2500 [==============================] - 267s 107ms/step - loss: 400.5597 - custom_mae: 7.3710 - val_loss: 526.9340 - val_custom_mae: 8.0586\n",
      "Epoch 151/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 400.0655 - custom_mae: 7.3855 ETA: 0s - loss: 399.7995 - custom_m\n",
      "Epoch 00151: val_custom_mae did not improve from 8.05863\n",
      "2500/2500 [==============================] - 261s 104ms/step - loss: 400.0972 - custom_mae: 7.3858 - val_loss: 531.3948 - val_custom_mae: 8.1583\n",
      "Epoch 152/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 396.4445 - custom_mae: 7.3570\n",
      "Epoch 00152: val_custom_mae improved from 8.05863 to 8.03432, saving model to ..\\fast_output\\SYNTH_Regression_MSE\\201019_2253_final_Angular_Top_1_Custom-MAE\\Synth_TD\\CNN_Base_32_Model_and_Weights_80000.hdf5\n",
      "2500/2500 [==============================] - 267s 107ms/step - loss: 396.6709 - custom_mae: 7.3589 - val_loss: 526.8290 - val_custom_mae: 8.0343\n",
      "Epoch 153/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 394.8337 - custom_mae: 7.3513 ETA: 0s - loss: 394.7584 - cust\n",
      "Epoch 00153: val_custom_mae did not improve from 8.03432\n",
      "2500/2500 [==============================] - 261s 104ms/step - loss: 394.8476 - custom_mae: 7.3511 - val_loss: 528.9254 - val_custom_mae: 8.0432\n",
      "Epoch 154/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 397.9060 - custom_mae: 7.3508\n",
      "Epoch 00154: val_custom_mae did not improve from 8.03432\n",
      "2500/2500 [==============================] - 261s 105ms/step - loss: 398.1239 - custom_mae: 7.3519 - val_loss: 531.4199 - val_custom_mae: 8.1061\n",
      "Epoch 155/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 399.0072 - custom_mae: 7.3599\n",
      "Epoch 00155: val_custom_mae did not improve from 8.03432\n",
      "2500/2500 [==============================] - 262s 105ms/step - loss: 398.9404 - custom_mae: 7.3598 - val_loss: 530.3734 - val_custom_mae: 8.1070\n",
      "Epoch 156/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 401.0982 - custom_mae: 7.3497\n",
      "Epoch 00156: val_custom_mae did not improve from 8.03432\n",
      "2500/2500 [==============================] - 262s 105ms/step - loss: 401.4361 - custom_mae: 7.3519 - val_loss: 527.5368 - val_custom_mae: 8.0916\n",
      "Epoch 157/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 401.2234 - custom_mae: 7.3593 ETA: 4s - los - ETA: 0s - loss: 401.1844 - \n",
      "Epoch 00157: val_custom_mae did not improve from 8.03432\n",
      "2500/2500 [==============================] - 262s 105ms/step - loss: 401.2891 - custom_mae: 7.3594 - val_loss: 526.4889 - val_custom_mae: 8.0771\n",
      "Epoch 158/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 394.1039 - custom_mae: 7.2988 ETA: 1s - loss: 393.3\n",
      "Epoch 00158: val_custom_mae improved from 8.03432 to 8.01662, saving model to ..\\fast_output\\SYNTH_Regression_MSE\\201019_2253_final_Angular_Top_1_Custom-MAE\\Synth_TD\\CNN_Base_32_Model_and_Weights_80000.hdf5\n",
      "\n",
      "Epoch 00158: ReduceLROnPlateau reducing learning rate to 5.000000000000001e-08.\n",
      "2500/2500 [==============================] - 267s 107ms/step - loss: 394.1658 - custom_mae: 7.2995 - val_loss: 528.0330 - val_custom_mae: 8.0166\n",
      "Epoch 159/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 393.3685 - custom_mae: 7.2963\n",
      "Epoch 00159: val_custom_mae did not improve from 8.01662\n",
      "2500/2500 [==============================] - 262s 105ms/step - loss: 393.4121 - custom_mae: 7.2973 - val_loss: 526.7384 - val_custom_mae: 8.0356\n",
      "Epoch 160/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 393.7870 - custom_mae: 7.3126\n",
      "Epoch 00160: val_custom_mae did not improve from 8.01662\n",
      "2500/2500 [==============================] - 263s 105ms/step - loss: 393.6886 - custom_mae: 7.3123 - val_loss: 524.8829 - val_custom_mae: 8.0287\n",
      "Epoch 161/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 394.4835 - custom_mae: 7.3036\n",
      "Epoch 00161: val_custom_mae did not improve from 8.01662\n",
      "2500/2500 [==============================] - 263s 105ms/step - loss: 394.4932 - custom_mae: 7.3040 - val_loss: 523.9274 - val_custom_mae: 8.0189\n",
      "Epoch 162/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 391.7734 - custom_mae: 7.2716\n",
      "Epoch 00162: val_custom_mae did not improve from 8.01662\n",
      "2500/2500 [==============================] - 263s 105ms/step - loss: 391.6933 - custom_mae: 7.2711 - val_loss: 524.2967 - val_custom_mae: 8.0169\n",
      "Epoch 163/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 389.7009 - custom_mae: 7.28 - ETA: 0s - loss: 389.5627 - custom_mae: 7.2826\n",
      "Epoch 00163: val_custom_mae did not improve from 8.01662\n",
      "2500/2500 [==============================] - 263s 105ms/step - loss: 389.4777 - custom_mae: 7.2821 - val_loss: 523.8500 - val_custom_mae: 8.0186\n",
      "Epoch 164/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2499/2500 [============================>.] - ETA: 0s - loss: 389.1102 - custom_mae: 7.2636\n",
      "Epoch 00164: val_custom_mae improved from 8.01662 to 8.01213, saving model to ..\\fast_output\\SYNTH_Regression_MSE\\201019_2253_final_Angular_Top_1_Custom-MAE\\Synth_TD\\CNN_Base_32_Model_and_Weights_80000.hdf5\n",
      "2500/2500 [==============================] - 269s 107ms/step - loss: 389.1263 - custom_mae: 7.2633 - val_loss: 523.6746 - val_custom_mae: 8.0121\n",
      "Epoch 165/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 389.8305 - custom_mae: 7.2653 E\n",
      "Epoch 00165: val_custom_mae did not improve from 8.01213\n",
      "2500/2500 [==============================] - 263s 105ms/step - loss: 389.7168 - custom_mae: 7.2643 - val_loss: 524.1069 - val_custom_mae: 8.0255\n",
      "Epoch 166/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 393.4299 - custom_mae: 7.2934\n",
      "Epoch 00166: val_custom_mae improved from 8.01213 to 8.01206, saving model to ..\\fast_output\\SYNTH_Regression_MSE\\201019_2253_final_Angular_Top_1_Custom-MAE\\Synth_TD\\CNN_Base_32_Model_and_Weights_80000.hdf5\n",
      "2500/2500 [==============================] - 268s 107ms/step - loss: 393.6389 - custom_mae: 7.2942 - val_loss: 524.1406 - val_custom_mae: 8.0121\n",
      "Epoch 167/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 394.1251 - custom_mae: 7.3020\n",
      "Epoch 00167: val_custom_mae did not improve from 8.01206\n",
      "2500/2500 [==============================] - 287s 115ms/step - loss: 394.2172 - custom_mae: 7.3031 - val_loss: 524.0020 - val_custom_mae: 8.0158\n",
      "Epoch 168/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 391.1017 - custom_mae: 7.2777\n",
      "Epoch 00168: val_custom_mae did not improve from 8.01206\n",
      "2500/2500 [==============================] - 262s 105ms/step - loss: 390.9683 - custom_mae: 7.2770 - val_loss: 523.7589 - val_custom_mae: 8.0133\n",
      "Epoch 169/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 389.3166 - custom_mae: 7.2620\n",
      "Epoch 00169: val_custom_mae improved from 8.01206 to 8.00571, saving model to ..\\fast_output\\SYNTH_Regression_MSE\\201019_2253_final_Angular_Top_1_Custom-MAE\\Synth_TD\\CNN_Base_32_Model_and_Weights_80000.hdf5\n",
      "2500/2500 [==============================] - 269s 107ms/step - loss: 389.2715 - custom_mae: 7.2619 - val_loss: 523.4177 - val_custom_mae: 8.0057\n",
      "Epoch 170/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 394.0463 - custom_mae: 7.2893\n",
      "Epoch 00170: val_custom_mae did not improve from 8.00571\n",
      "2500/2500 [==============================] - 326s 130ms/step - loss: 394.0192 - custom_mae: 7.2895 - val_loss: 524.4093 - val_custom_mae: 8.0090\n",
      "Epoch 171/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 393.6374 - custom_mae: 7.2708\n",
      "Epoch 00171: val_custom_mae did not improve from 8.00571\n",
      "2500/2500 [==============================] - 263s 105ms/step - loss: 393.4991 - custom_mae: 7.2699 - val_loss: 524.9959 - val_custom_mae: 8.0200\n",
      "Epoch 172/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 393.3796 - custom_mae: 7.2857 ETA: 1s - l\n",
      "Epoch 00172: val_custom_mae did not improve from 8.00571\n",
      "2500/2500 [==============================] - 263s 105ms/step - loss: 393.3780 - custom_mae: 7.2858 - val_loss: 523.8175 - val_custom_mae: 8.0146\n",
      "Epoch 173/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 390.0548 - custom_mae: 7.2727\n",
      "Epoch 00173: val_custom_mae improved from 8.00571 to 8.00412, saving model to ..\\fast_output\\SYNTH_Regression_MSE\\201019_2253_final_Angular_Top_1_Custom-MAE\\Synth_TD\\CNN_Base_32_Model_and_Weights_80000.hdf5\n",
      "2500/2500 [==============================] - 270s 108ms/step - loss: 389.9402 - custom_mae: 7.2722 - val_loss: 523.3434 - val_custom_mae: 8.0041\n",
      "Epoch 174/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 388.7991 - custom_mae: 7.2534 E\n",
      "Epoch 00174: val_custom_mae did not improve from 8.00412\n",
      "2500/2500 [==============================] - 330s 132ms/step - loss: 388.7546 - custom_mae: 7.2529 - val_loss: 523.6939 - val_custom_mae: 8.0083\n",
      "Epoch 175/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 390.0952 - custom_mae: 7.2564 ETA: 0s - loss: 390.8169 \n",
      "Epoch 00175: val_custom_mae did not improve from 8.00412\n",
      "2500/2500 [==============================] - 263s 105ms/step - loss: 389.9502 - custom_mae: 7.2550 - val_loss: 523.9816 - val_custom_mae: 8.0052\n",
      "Epoch 176/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 391.9442 - custom_mae: 7.2817\n",
      "Epoch 00176: val_custom_mae did not improve from 8.00412\n",
      "2500/2500 [==============================] - 264s 105ms/step - loss: 391.8212 - custom_mae: 7.2806 - val_loss: 523.7331 - val_custom_mae: 8.0113\n",
      "Epoch 177/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 388.3616 - custom_mae: 7.2566 ETA: 1s - l\n",
      "Epoch 00177: val_custom_mae improved from 8.00412 to 8.00140, saving model to ..\\fast_output\\SYNTH_Regression_MSE\\201019_2253_final_Angular_Top_1_Custom-MAE\\Synth_TD\\CNN_Base_32_Model_and_Weights_80000.hdf5\n",
      "2500/2500 [==============================] - 270s 108ms/step - loss: 388.3909 - custom_mae: 7.2568 - val_loss: 523.4365 - val_custom_mae: 8.0014\n",
      "Epoch 178/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 395.3875 - custom_mae: 7.3006\n",
      "Epoch 00178: val_custom_mae did not improve from 8.00140\n",
      "2500/2500 [==============================] - 275s 110ms/step - loss: 395.3700 - custom_mae: 7.3005 - val_loss: 523.8713 - val_custom_mae: 8.0124\n",
      "Epoch 179/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 393.2259 - custom_mae: 7.3029 E - E\n",
      "Epoch 00179: val_custom_mae did not improve from 8.00140\n",
      "2500/2500 [==============================] - 262s 105ms/step - loss: 393.3144 - custom_mae: 7.3030 - val_loss: 524.1214 - val_custom_mae: 8.0077\n",
      "Epoch 180/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 390.3921 - custom_mae: 7.2661\n",
      "Epoch 00180: val_custom_mae did not improve from 8.00140\n",
      "2500/2500 [==============================] - 263s 105ms/step - loss: 390.3145 - custom_mae: 7.2659 - val_loss: 524.2547 - val_custom_mae: 8.0144\n",
      "Epoch 181/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 389.6621 - custom_mae: 7.2798\n",
      "Epoch 00181: val_custom_mae improved from 8.00140 to 8.00101, saving model to ..\\fast_output\\SYNTH_Regression_MSE\\201019_2253_final_Angular_Top_1_Custom-MAE\\Synth_TD\\CNN_Base_32_Model_and_Weights_80000.hdf5\n",
      "2500/2500 [==============================] - 268s 107ms/step - loss: 389.5284 - custom_mae: 7.2789 - val_loss: 524.6406 - val_custom_mae: 8.0010\n",
      "Epoch 182/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 390.9444 - custom_mae: 7.2462 - ETA: 1 - ETA: 1s - l\n",
      "Epoch 00182: val_custom_mae did not improve from 8.00101\n",
      "2500/2500 [==============================] - 273s 109ms/step - loss: 391.2951 - custom_mae: 7.2477 - val_loss: 524.9668 - val_custom_mae: 8.0191\n",
      "Epoch 183/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 390.1603 - custom_mae: 7.2445\n",
      "Epoch 00183: val_custom_mae improved from 8.00101 to 7.99786, saving model to ..\\fast_output\\SYNTH_Regression_MSE\\201019_2253_final_Angular_Top_1_Custom-MAE\\Synth_TD\\CNN_Base_32_Model_and_Weights_80000.hdf5\n",
      "2500/2500 [==============================] - 268s 107ms/step - loss: 390.1354 - custom_mae: 7.2442 - val_loss: 523.4750 - val_custom_mae: 7.9979\n",
      "Epoch 184/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 391.8977 - custom_mae: 7.2883 ETA: \n",
      "Epoch 00184: val_custom_mae did not improve from 7.99786\n",
      "2500/2500 [==============================] - 324s 130ms/step - loss: 391.8693 - custom_mae: 7.2883 - val_loss: 524.3619 - val_custom_mae: 8.0062\n",
      "Epoch 185/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 392.8395 - custom_mae: 7.2768\n",
      "Epoch 00185: val_custom_mae did not improve from 7.99786\n",
      "2500/2500 [==============================] - 264s 106ms/step - loss: 392.7044 - custom_mae: 7.2759 - val_loss: 523.9040 - val_custom_mae: 8.0046\n",
      "Epoch 186/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2499/2500 [============================>.] - ETA: 0s - loss: 390.5815 - custom_mae: 7.2769 5 ETA: 1:01 - loss: 3 - ETA - ETA: 47s - loss: 390.6651 - custom_mae: 7. - ET - ETA: 2s - loss: 390.8854 - custom - ETA\n",
      "Epoch 00186: val_custom_mae improved from 7.99786 to 7.99005, saving model to ..\\fast_output\\SYNTH_Regression_MSE\\201019_2253_final_Angular_Top_1_Custom-MAE\\Synth_TD\\CNN_Base_32_Model_and_Weights_80000.hdf5\n",
      "2500/2500 [==============================] - 270s 108ms/step - loss: 391.0117 - custom_mae: 7.2798 - val_loss: 523.1510 - val_custom_mae: 7.9901\n",
      "Epoch 187/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 393.3057 - custom_mae: 7.2619\n",
      "Epoch 00187: val_custom_mae did not improve from 7.99005\n",
      "2500/2500 [==============================] - 326s 130ms/step - loss: 393.4544 - custom_mae: 7.2628 - val_loss: 524.0678 - val_custom_mae: 8.0254\n",
      "Epoch 188/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 392.0795 - custom_mae: 7.2881 ETA: 1s - loss: 391\n",
      "Epoch 00188: val_custom_mae did not improve from 7.99005\n",
      "2500/2500 [==============================] - 264s 106ms/step - loss: 391.9733 - custom_mae: 7.2873 - val_loss: 523.5315 - val_custom_mae: 8.0116\n",
      "Epoch 189/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 389.8967 - custom_mae: 7.2667  - ETA: 6s - loss: 391.4950  - ETA: 5s - los\n",
      "Epoch 00189: val_custom_mae improved from 7.99005 to 7.98937, saving model to ..\\fast_output\\SYNTH_Regression_MSE\\201019_2253_final_Angular_Top_1_Custom-MAE\\Synth_TD\\CNN_Base_32_Model_and_Weights_80000.hdf5\n",
      "2500/2500 [==============================] - 270s 108ms/step - loss: 389.7512 - custom_mae: 7.2653 - val_loss: 524.1595 - val_custom_mae: 7.9894\n",
      "Epoch 190/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 393.0664 - custom_mae: 7.2873\n",
      "Epoch 00190: val_custom_mae did not improve from 7.98937\n",
      "2500/2500 [==============================] - 332s 133ms/step - loss: 393.0613 - custom_mae: 7.2875 - val_loss: 523.1238 - val_custom_mae: 8.0044\n",
      "Epoch 191/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 393.4916 - custom_mae: 7.2584\n",
      "Epoch 00191: val_custom_mae did not improve from 7.98937\n",
      "2500/2500 [==============================] - 264s 106ms/step - loss: 393.5181 - custom_mae: 7.2581 - val_loss: 523.8441 - val_custom_mae: 7.9979\n",
      "Epoch 192/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 390.9211 - custom_mae: 7.2661\n",
      "Epoch 00192: val_custom_mae did not improve from 7.98937\n",
      "2500/2500 [==============================] - 265s 106ms/step - loss: 390.8184 - custom_mae: 7.2654 - val_loss: 522.7956 - val_custom_mae: 7.9984\n",
      "Epoch 193/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 391.3889 - custom_mae: 7.2703\n",
      "Epoch 00193: val_custom_mae did not improve from 7.98937\n",
      "2500/2500 [==============================] - 265s 106ms/step - loss: 391.4184 - custom_mae: 7.2702 - val_loss: 523.5862 - val_custom_mae: 8.0046\n",
      "Epoch 194/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 392.4405 - custom_mae: 7.2727\n",
      "Epoch 00194: val_custom_mae did not improve from 7.98937\n",
      "2500/2500 [==============================] - 264s 106ms/step - loss: 392.3815 - custom_mae: 7.2723 - val_loss: 523.2326 - val_custom_mae: 8.0034\n",
      "Epoch 195/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 388.1499 - custom_mae: 7.2492\n",
      "Epoch 00195: val_custom_mae did not improve from 7.98937\n",
      "2500/2500 [==============================] - 266s 106ms/step - loss: 388.1598 - custom_mae: 7.2493 - val_loss: 522.5249 - val_custom_mae: 8.0003\n",
      "Epoch 196/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 393.8077 - custom_mae: 7.2734\n",
      "Epoch 00196: val_custom_mae did not improve from 7.98937\n",
      "2500/2500 [==============================] - 273s 109ms/step - loss: 393.6640 - custom_mae: 7.2722 - val_loss: 522.6810 - val_custom_mae: 8.0028\n",
      "Epoch 197/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 390.3452 - custom_mae: 7.2705\n",
      "Epoch 00197: val_custom_mae improved from 7.98937 to 7.98756, saving model to ..\\fast_output\\SYNTH_Regression_MSE\\201019_2253_final_Angular_Top_1_Custom-MAE\\Synth_TD\\CNN_Base_32_Model_and_Weights_80000.hdf5\n",
      "2500/2500 [==============================] - 270s 108ms/step - loss: 390.2928 - custom_mae: 7.2704 - val_loss: 523.4299 - val_custom_mae: 7.9876\n",
      "Epoch 198/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 391.4099 - custom_mae: 7.2641\n",
      "Epoch 00198: val_custom_mae did not improve from 7.98756\n",
      "2500/2500 [==============================] - 268s 107ms/step - loss: 391.3696 - custom_mae: 7.2636 - val_loss: 523.3977 - val_custom_mae: 8.0033\n",
      "Epoch 199/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 391.6717 - custom_mae: 7.2849 - ETA: 27s - loss: 395\n",
      "Epoch 00199: val_custom_mae did not improve from 7.98756\n",
      "2500/2500 [==============================] - 265s 106ms/step - loss: 391.8740 - custom_mae: 7.2865 - val_loss: 523.2536 - val_custom_mae: 7.9888\n",
      "Epoch 200/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 388.1211 - custom_mae: 7.2466\n",
      "Epoch 00200: val_custom_mae improved from 7.98756 to 7.98618, saving model to ..\\fast_output\\SYNTH_Regression_MSE\\201019_2253_final_Angular_Top_1_Custom-MAE\\Synth_TD\\CNN_Base_32_Model_and_Weights_80000.hdf5\n",
      "2500/2500 [==============================] - 272s 109ms/step - loss: 388.1542 - custom_mae: 7.2464 - val_loss: 522.2778 - val_custom_mae: 7.9862\n",
      "Epoch 201/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 389.2321 - custom_mae: 7.2644\n",
      "Epoch 00201: val_custom_mae did not improve from 7.98618\n",
      "2500/2500 [==============================] - 291s 116ms/step - loss: 389.0956 - custom_mae: 7.2632 - val_loss: 522.5061 - val_custom_mae: 7.9962\n",
      "Epoch 202/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 389.1105 - custom_mae: 7.2530\n",
      "Epoch 00202: val_custom_mae did not improve from 7.98618\n",
      "2500/2500 [==============================] - 266s 106ms/step - loss: 389.0152 - custom_mae: 7.2526 - val_loss: 523.8585 - val_custom_mae: 8.0045\n",
      "Epoch 203/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 390.0447 - custom_mae: 7.2566 ETA: 1s - loss: 389.999 - ETA: 0s - loss: 389.8164 \n",
      "Epoch 00203: val_custom_mae did not improve from 7.98618\n",
      "2500/2500 [==============================] - 266s 107ms/step - loss: 390.0948 - custom_mae: 7.2565 - val_loss: 522.2741 - val_custom_mae: 7.9868\n",
      "Epoch 204/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 390.2498 - custom_mae: 7.2571\n",
      "Epoch 00204: val_custom_mae did not improve from 7.98618\n",
      "2500/2500 [==============================] - 266s 106ms/step - loss: 390.6376 - custom_mae: 7.2587 - val_loss: 523.4513 - val_custom_mae: 8.0043\n",
      "Epoch 205/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 393.5772 - custom_mae: 7.2419\n",
      "Epoch 00205: val_custom_mae did not improve from 7.98618\n",
      "2500/2500 [==============================] - 266s 106ms/step - loss: 393.5804 - custom_mae: 7.2417 - val_loss: 522.6746 - val_custom_mae: 7.9953\n",
      "Epoch 206/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 392.1156 - custom_mae: 7.2572\n",
      "Epoch 00206: val_custom_mae did not improve from 7.98618\n",
      "2500/2500 [==============================] - 267s 107ms/step - loss: 392.1005 - custom_mae: 7.2570 - val_loss: 521.7030 - val_custom_mae: 7.9863\n",
      "Epoch 207/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 388.5589 - custom_mae: 7.2516\n",
      "Epoch 00207: val_custom_mae improved from 7.98618 to 7.98325, saving model to ..\\fast_output\\SYNTH_Regression_MSE\\201019_2253_final_Angular_Top_1_Custom-MAE\\Synth_TD\\CNN_Base_32_Model_and_Weights_80000.hdf5\n",
      "2500/2500 [==============================] - 278s 111ms/step - loss: 388.5705 - custom_mae: 7.2518 - val_loss: 522.1297 - val_custom_mae: 7.9832\n",
      "Epoch 208/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 387.5170 - custom_mae: 7.2359\n",
      "Epoch 00208: val_custom_mae did not improve from 7.98325\n",
      "2500/2500 [==============================] - 329s 131ms/step - loss: 387.5486 - custom_mae: 7.2361 - val_loss: 521.6290 - val_custom_mae: 7.9844\n",
      "Epoch 209/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2499/2500 [============================>.] - ETA: 0s - loss: 391.1281 - custom_mae: 7.2518\n",
      "Epoch 00209: val_custom_mae did not improve from 7.98325\n",
      "2500/2500 [==============================] - 266s 106ms/step - loss: 391.0283 - custom_mae: 7.2511 - val_loss: 522.8449 - val_custom_mae: 7.9970\n",
      "Epoch 210/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 390.2911 - custom_mae: 7.24227- ET\n",
      "Epoch 00210: val_custom_mae did not improve from 7.98325\n",
      "2500/2500 [==============================] - 266s 106ms/step - loss: 390.2739 - custom_mae: 7.2423 - val_loss: 522.3976 - val_custom_mae: 7.9901\n",
      "Epoch 211/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 390.4426 - custom_mae: 7.2633 ETA: 1s\n",
      "Epoch 00211: val_custom_mae did not improve from 7.98325\n",
      "2500/2500 [==============================] - 266s 106ms/step - loss: 390.6369 - custom_mae: 7.2643 - val_loss: 522.7436 - val_custom_mae: 7.9883\n",
      "Epoch 212/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 390.8154 - custom_mae: 7.2579 ETA\n",
      "Epoch 00212: val_custom_mae did not improve from 7.98325\n",
      "2500/2500 [==============================] - 269s 108ms/step - loss: 390.6849 - custom_mae: 7.2570 - val_loss: 523.2561 - val_custom_mae: 8.0032\n",
      "Epoch 213/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 389.5190 - custom_mae: 7.2429\n",
      "Epoch 00213: val_custom_mae did not improve from 7.98325\n",
      "2500/2500 [==============================] - 268s 107ms/step - loss: 389.3843 - custom_mae: 7.2420 - val_loss: 522.5628 - val_custom_mae: 7.9917\n",
      "Epoch 214/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 391.3936 - custom_mae: 7.2614\n",
      "Epoch 00214: val_custom_mae did not improve from 7.98325\n",
      "2500/2500 [==============================] - 292s 117ms/step - loss: 391.3067 - custom_mae: 7.2612 - val_loss: 522.7553 - val_custom_mae: 7.9869\n",
      "Epoch 215/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 388.8876 - custom_mae: 7.2533 ETA: 4s - ETA: 0s - loss: 389.2547 - cust\n",
      "Epoch 00215: val_custom_mae improved from 7.98325 to 7.98047, saving model to ..\\fast_output\\SYNTH_Regression_MSE\\201019_2253_final_Angular_Top_1_Custom-MAE\\Synth_TD\\CNN_Base_32_Model_and_Weights_80000.hdf5\n",
      "2500/2500 [==============================] - 295s 118ms/step - loss: 388.7590 - custom_mae: 7.2527 - val_loss: 521.9600 - val_custom_mae: 7.9805\n",
      "Epoch 216/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 393.5082 - custom_mae: 7.2619\n",
      "Epoch 00216: val_custom_mae did not improve from 7.98047\n",
      "2500/2500 [==============================] - 275s 110ms/step - loss: 393.3641 - custom_mae: 7.2606 - val_loss: 522.1478 - val_custom_mae: 8.0052\n",
      "Epoch 217/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 392.0694 - custom_mae: 7.2656\n",
      "Epoch 00217: val_custom_mae did not improve from 7.98047\n",
      "2500/2500 [==============================] - 267s 107ms/step - loss: 392.0626 - custom_mae: 7.2656 - val_loss: 522.9618 - val_custom_mae: 7.9853\n",
      "Epoch 218/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 392.3682 - custom_mae: 7.2687\n",
      "Epoch 00218: val_custom_mae did not improve from 7.98047\n",
      "2500/2500 [==============================] - 267s 107ms/step - loss: 392.5145 - custom_mae: 7.2688 - val_loss: 523.5065 - val_custom_mae: 7.9963\n",
      "Epoch 219/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 388.4013 - custom_mae: 7.2352\n",
      "Epoch 00219: val_custom_mae did not improve from 7.98047\n",
      "2500/2500 [==============================] - 267s 107ms/step - loss: 388.6886 - custom_mae: 7.2361 - val_loss: 521.5653 - val_custom_mae: 7.9904\n",
      "Epoch 220/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 392.7141 - custom_mae: 7.2709\n",
      "Epoch 00220: val_custom_mae did not improve from 7.98047\n",
      "2500/2500 [==============================] - 268s 107ms/step - loss: 392.8725 - custom_mae: 7.2713 - val_loss: 521.8868 - val_custom_mae: 7.9874\n",
      "Epoch 221/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 392.4676 - custom_mae: 7.2504 - ETA: 58s - loss: - ETA: 55s - loss:\n",
      "Epoch 00221: val_custom_mae did not improve from 7.98047\n",
      "2500/2500 [==============================] - 269s 108ms/step - loss: 392.3289 - custom_mae: 7.2493 - val_loss: 521.9576 - val_custom_mae: 7.9876\n",
      "Epoch 222/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 386.6142 - custom_mae: 7.2416\n",
      "Epoch 00222: val_custom_mae did not improve from 7.98047\n",
      "2500/2500 [==============================] - 268s 107ms/step - loss: 386.5137 - custom_mae: 7.2409 - val_loss: 522.7362 - val_custom_mae: 7.9876\n",
      "Epoch 223/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 386.5044 - custom_mae: 7.2212\n",
      "Epoch 00223: val_custom_mae improved from 7.98047 to 7.98045, saving model to ..\\fast_output\\SYNTH_Regression_MSE\\201019_2253_final_Angular_Top_1_Custom-MAE\\Synth_TD\\CNN_Base_32_Model_and_Weights_80000.hdf5\n",
      "2500/2500 [==============================] - 274s 109ms/step - loss: 386.3711 - custom_mae: 7.2204 - val_loss: 522.9573 - val_custom_mae: 7.9805\n",
      "Epoch 224/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 390.6330 - custom_mae: 7.2581 - ETA: 49s - loss: 392.7634 - cu\n",
      "Epoch 00224: val_custom_mae did not improve from 7.98045\n",
      "2500/2500 [==============================] - 268s 107ms/step - loss: 390.8369 - custom_mae: 7.2596 - val_loss: 522.1629 - val_custom_mae: 7.9915\n",
      "Epoch 225/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 388.7776 - custom_mae: 7.2431\n",
      "Epoch 00225: val_custom_mae improved from 7.98045 to 7.98009, saving model to ..\\fast_output\\SYNTH_Regression_MSE\\201019_2253_final_Angular_Top_1_Custom-MAE\\Synth_TD\\CNN_Base_32_Model_and_Weights_80000.hdf5\n",
      "2500/2500 [==============================] - 273s 109ms/step - loss: 388.6513 - custom_mae: 7.2423 - val_loss: 522.2873 - val_custom_mae: 7.9801\n",
      "Epoch 226/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 387.0172 - custom_mae: 7.2312 - ETA: 43s - ETA: 31s - loss: 386.5164 - custom_mae:  - ETA: - ETA: 0s - loss: 387.1724 - cust\n",
      "Epoch 00226: val_custom_mae improved from 7.98009 to 7.97866, saving model to ..\\fast_output\\SYNTH_Regression_MSE\\201019_2253_final_Angular_Top_1_Custom-MAE\\Synth_TD\\CNN_Base_32_Model_and_Weights_80000.hdf5\n",
      "2500/2500 [==============================] - 273s 109ms/step - loss: 386.9540 - custom_mae: 7.2312 - val_loss: 522.1000 - val_custom_mae: 7.9787\n",
      "Epoch 227/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 390.1840 - custom_mae: 7.2689 ETA: 5s - los\n",
      "Epoch 00227: val_custom_mae did not improve from 7.97866\n",
      "2500/2500 [==============================] - 267s 107ms/step - loss: 390.1193 - custom_mae: 7.2686 - val_loss: 522.7287 - val_custom_mae: 7.9899\n",
      "Epoch 228/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 389.1236 - custom_mae: 7.2492\n",
      "Epoch 00228: val_custom_mae improved from 7.97866 to 7.97077, saving model to ..\\fast_output\\SYNTH_Regression_MSE\\201019_2253_final_Angular_Top_1_Custom-MAE\\Synth_TD\\CNN_Base_32_Model_and_Weights_80000.hdf5\n",
      "2500/2500 [==============================] - 273s 109ms/step - loss: 389.4528 - custom_mae: 7.2513 - val_loss: 522.4328 - val_custom_mae: 7.9708\n",
      "Epoch 229/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 388.5365 - custom_mae: 7.2667\n",
      "Epoch 00229: val_custom_mae did not improve from 7.97077\n",
      "2500/2500 [==============================] - 269s 107ms/step - loss: 388.3926 - custom_mae: 7.2653 - val_loss: 521.7192 - val_custom_mae: 7.9827\n",
      "Epoch 230/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 392.1350 - custom_mae: 7.2526\n",
      "Epoch 00230: val_custom_mae did not improve from 7.97077\n",
      "2500/2500 [==============================] - 268s 107ms/step - loss: 392.1129 - custom_mae: 7.2528 - val_loss: 523.1023 - val_custom_mae: 8.0057\n",
      "Epoch 231/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 384.9122 - custom_mae: 7.2219\n",
      "Epoch 00231: val_custom_mae did not improve from 7.97077\n",
      "2500/2500 [==============================] - 268s 107ms/step - loss: 384.9048 - custom_mae: 7.2221 - val_loss: 522.2553 - val_custom_mae: 7.9900\n",
      "Epoch 232/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2499/2500 [============================>.] - ETA: 0s - loss: 388.6390 - custom_mae: 7.2492\n",
      "Epoch 00232: val_custom_mae did not improve from 7.97077\n",
      "\n",
      "Epoch 00232: ReduceLROnPlateau reducing learning rate to 5.000000000000002e-09.\n",
      "2500/2500 [==============================] - 268s 107ms/step - loss: 388.5047 - custom_mae: 7.2481 - val_loss: 521.9771 - val_custom_mae: 7.9760\n",
      "Epoch 233/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 392.6370 - custom_mae: 7.2548\n",
      "Epoch 00233: val_custom_mae did not improve from 7.97077\n",
      "2500/2500 [==============================] - 269s 108ms/step - loss: 392.7461 - custom_mae: 7.2553 - val_loss: 522.1611 - val_custom_mae: 7.9798\n",
      "Epoch 234/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 392.4205 - custom_mae: 7.2457 ETA: 2s - loss: 392 - ETA: 1s - loss: 392\n",
      "Epoch 00234: val_custom_mae did not improve from 7.97077\n",
      "2500/2500 [==============================] - 268s 107ms/step - loss: 392.5798 - custom_mae: 7.2468 - val_loss: 522.2039 - val_custom_mae: 7.9799\n",
      "Epoch 235/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 387.9332 - custom_mae: 7.2483\n",
      "Epoch 00235: val_custom_mae did not improve from 7.97077\n",
      "2500/2500 [==============================] - 268s 107ms/step - loss: 388.2025 - custom_mae: 7.2502 - val_loss: 522.1424 - val_custom_mae: 7.9782\n",
      "Epoch 236/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 388.4165 - custom_mae: 7.2403\n",
      "Epoch 00236: val_custom_mae did not improve from 7.97077\n",
      "2500/2500 [==============================] - 268s 107ms/step - loss: 388.3580 - custom_mae: 7.2398 - val_loss: 522.0985 - val_custom_mae: 7.9794\n",
      "Epoch 237/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 388.3411 - custom_mae: 7.2425\n",
      "Epoch 00237: val_custom_mae did not improve from 7.97077\n",
      "2500/2500 [==============================] - 268s 107ms/step - loss: 388.2882 - custom_mae: 7.2419 - val_loss: 522.1513 - val_custom_mae: 7.9776\n",
      "Epoch 238/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 387.7321 - custom_mae: 7.2346\n",
      "Epoch 00238: val_custom_mae did not improve from 7.97077\n",
      "2500/2500 [==============================] - 270s 108ms/step - loss: 387.9860 - custom_mae: 7.2359 - val_loss: 522.3180 - val_custom_mae: 7.9797\n",
      "Epoch 239/400\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 389.8456 - custom_mae: 7.2431 ETA: 1s - loss: 389.8229 \n",
      "Epoch 00239: val_custom_mae did not improve from 7.97077\n",
      "Restoring model weights from the end of the best epoch.\n",
      "2500/2500 [==============================] - 270s 108ms/step - loss: 390.0703 - custom_mae: 7.2440 - val_loss: 522.4808 - val_custom_mae: 7.9831\n",
      "Epoch 00239: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1/1 [17:40:35<00:00, 63635.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 17:40:35.438400\n",
      "Writing Device File\n"
     ]
    },
    {
     "ename": "EmptyDataError",
     "evalue": "No columns to parse from file",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEmptyDataError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-f36a7c751a0a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[0mdevice_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Trained Model: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_MODEL_TO_LOAD\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m         \u001b[0mdf_experiment_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_TMP_DIR\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'\\\\'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_TMP_DIR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m         \u001b[0mdf_experiment_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Base'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_experiment_results\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\tf_ks\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    684\u001b[0m     )\n\u001b[0;32m    685\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 686\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\tf_ks\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 452\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    453\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    454\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\tf_ks\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    934\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 936\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    937\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    938\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\tf_ks\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1166\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1167\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1168\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1169\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1170\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\tf_ks\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1996\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1997\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1998\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1999\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2000\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mEmptyDataError\u001b[0m: No columns to parse from file"
     ]
    }
   ],
   "source": [
    "dummy_x = np.empty((1, 2, 3, 224, 224))\n",
    "dummy_y = np.empty((1, 2))\n",
    "\n",
    "with tf.device('/device:GPU:0'):\n",
    "    #for top_results_index in range(3):\n",
    "    for top_results_index in [0, 1]:\n",
    "        #top_results_index = 0\n",
    "        _MODEL_TO_LOAD_INDEX = df.iloc[top_results_index].name\n",
    "        _MODEL_TO_LOAD = 'Best_Weights_FC_{}.hdf5'.format(_MODEL_TO_LOAD_INDEX)\n",
    "\n",
    "        _TMP_DIR = '..\\\\TMP_TALOS_{}'.format(_DEVICE)\n",
    "        _CSV_RESULTS = _LOG_DIR + 'Talos_Results_Fine_Idx{}.csv'.format(_MODEL_TO_LOAD_INDEX)\n",
    "\n",
    "        startTime = datetime.now()\n",
    "        \n",
    "        parameters = get_params(top_results_index)\n",
<<<<<<< HEAD
    "\n",
=======
    "        \n",
>>>>>>> d4842eed0e44dd7c9fb77866165dc0258555a0ee
    "        t = ta.Scan(\n",
    "            x = dummy_x,\n",
    "            y = dummy_y,\n",
    "            model = grid_model_fine,\n",
    "            params = parameters,\n",
    "            experiment_name = _TMP_DIR,\n",
    "            #shuffle=False,\n",
    "            reduction_metric = parameters['reduction_metric'][0],\n",
    "            disable_progress_bar = False,\n",
    "            print_params = True,\n",
    "            clear_session = 'tf'\n",
    "        )\n",
    "\n",
    "        print(\"Time taken:\", datetime.now() - startTime)\n",
    "        \n",
    "        print('Writing Device File')\n",
    "        device_file.write('Trained Model: {}'.format(_MODEL_TO_LOAD))\n",
    "\n",
    "        df_experiment_results = pd.read_csv(_TMP_DIR + '\\\\' + os.listdir(_TMP_DIR)[0])\n",
    "        df_experiment_results['Base'] = None\n",
    "        for i in range(df_experiment_results.shape[0]):\n",
    "            df_experiment_results['Base'][i] = _MODEL_TO_LOAD_INDEX\n",
    "\n",
    "        if os.path.isfile(_CSV_RESULTS):\n",
    "            df_experiment_results.to_csv(_CSV_RESULTS, mode = 'a', index = False, header = False)\n",
    "        else:\n",
    "            df_experiment_results.to_csv(_CSV_RESULTS, index = False)\n",
    "\n",
    "        shutil.rmtree(_TMP_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copy Results to NAS if SSD Directory was selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_directory(src, dst, symlinks = False, ignore = None):\n",
    "    maxLen = 0\n",
    "    message = ''        \n",
    "    \n",
    "    if not os.path.exists(dst):\n",
    "        \n",
    "        message = 'Creating Path: {}'.format(src)\n",
    "        maxLen = max(maxLen, len(message))\n",
    "        print(message + ' ' * (maxLen - len(message)), end = '\\r')\n",
    "        \n",
    "        os.makedirs(dst)\n",
    "        \n",
    "    for item in os.listdir(src):\n",
    "        \n",
    "        s = os.path.join(src, item)\n",
    "        d = os.path.join(dst, item)\n",
    "        \n",
    "        if os.path.isdir(s):\n",
    "            \n",
    "            message = 'Copying Directory: {}'.format(s)\n",
    "            maxLen = max(maxLen, len(message))\n",
    "            print(message + ' ' * (maxLen - len(message)), end = '\\r')\n",
    "            \n",
    "            shutil.copytree(s, d, symlinks, ignore)\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            if not os.path.exists(d): #or os.stat(s).st_mtime - os.stat(d).st_mtime > 1:\n",
    "                \n",
    "                message = 'Copying File: {}'.format(s)\n",
    "                maxLen = max(maxLen, len(message))\n",
    "                print(message + ' ' * (maxLen - len(message)), end = '\\r')\n",
    "                \n",
    "                shutil.copy2(s, d)\n",
    "        \n",
    "        time.sleep(.5)\n",
    "     \n",
    "    message = 'Coyping... Done'\n",
    "    maxLen = max(maxLen, len(message))\n",
    "    print(message + ' ' * (maxLen - len(message)), end = '\\n')\n",
    "\n",
    "def delete_directory(src, terminator = '\\n'):\n",
    "    message = ''\n",
    "    maxLen = 0\n",
    "    \n",
    "    try:\n",
    "        message = 'Deleting {}'.format(src)\n",
    "        maxLen = max(maxLen, len(message))\n",
    "        print(message + ' ' * (maxLen - len(message)), end = '\\r')\n",
    "        \n",
    "        shutil.rmtree(src)\n",
    "        \n",
    "    except OSError as e:\n",
    "        message = 'Error: {} : {}'.format(src, e.strerror)\n",
    "        maxLen = max(maxLen, len(message))\n",
    "        print(message + ' ' * (maxLen - len(message)), end = '\\n')\n",
    "        return\n",
    "    \n",
    "    message = 'Deleting... Done'\n",
    "    maxLen = max(maxLen, len(message))\n",
    "    print(message + ' ' * (maxLen - len(message)), end = terminator)\n",
    "\n",
    "    \n",
    "def copy_fine_training(src, dst):\n",
    "    copy_directory(src, dst)\n",
    "    delete_directory(src, terminator = '\\r')\n",
    "    delete_directory(src + '..\\\\', terminator = '\\r')\n",
    "    if not os.listdir(src + '..\\\\..\\\\'):\n",
    "        delete_directory(src + '..\\\\..\\\\', terminator = '\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(storage == OutputDirectory.SSD):\n",
    "    _COPY_DIR = '..\\\\output\\\\{}'.format(_NET_DIR)\n",
    "    copy_fine_training(_LOG_DIR, _COPY_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name = \"CMSE.Mixed\"></a><a href = #Top>Up</a></p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
