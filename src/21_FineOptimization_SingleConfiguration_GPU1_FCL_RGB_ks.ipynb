{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Training on GPU 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick Links <a name = \"Top\"></a>\n",
    "\n",
    "<ol>\n",
    "<li><a href = #setup>Begin Training</a></li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Conda Environment: tf_ks\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]='0'\n",
    "\n",
    "print('Current Conda Environment: {}'.format(os.environ['CONDA_DEFAULT_ENV']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The installed version of TensorFlow 2.1.0 includes GPU support.\n",
      "\n",
      "Num GPUs Available:  2 \n",
      "\n",
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 7927081293181516921\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 9105744200\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 14523180126670585795\n",
      "physical_device_desc: \"device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:17:00.0, compute capability: 7.5\"\n",
      ", name: \"/device:GPU:1\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 9104897474\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 16042835619553350581\n",
      "physical_device_desc: \"device: 1, name: GeForce RTX 2080 Ti, pci bus id: 0000:65:00.0, compute capability: 7.5\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import talos as ta\n",
    "from talos.model import lr_normalizer, early_stopper, hidden_layers\n",
    "\n",
    "import tensorflow as tf\n",
    "  \n",
    "available_gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "built_with_cuda = tf.test.is_built_with_cuda()\n",
    "\n",
    "if not (not available_gpus) & built_with_cuda:\n",
    "    print(\"The installed version of TensorFlow {} includes GPU support.\\n\".format(tf.__version__))\n",
    "    print(\"Num GPUs Available: \", len(available_gpus), \"\\n\")\n",
    "else:\n",
    "    print(\"The installed version of TensorFlow {} does not include GPU support.\\n\".format(tf.__version__))\n",
    "    \n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "from tensorflow.compat.v1.keras import callbacks, backend as K\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.utils import multi_gpu_model\n",
    "from tensorflow.keras.initializers import glorot_uniform\n",
    "from tensorflow.keras.optimizers import Adam, Nadam, RMSprop, SGD, Adagrad\n",
    "from tensorflow.keras.layers import ReLU, LeakyReLU\n",
    "\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "import time\n",
    "\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "tf.random.set_seed(1)\n",
    "\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.99\n",
    "sess = tf.compat.v1.Session(config = config)\n",
    "\n",
    "#with tf.compat.v1.Session() as sess: \n",
    "#    sess.run()\n",
    "#with tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(gpu_options.allow_growth=True,\n",
    "#                                                   per_process_gpu_memory_fraction = 0.99)) as sess:\n",
    "#    sess.run()\n",
    "#with tf.compat.v1.Session(config=config) as sess: \n",
    "    #sess.run()\n",
    "    \n",
    "\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hilfsfunktionen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enum für Training-Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class TrainingSet(Enum):\n",
    "    SYNTHETIC = 1\n",
    "    REAL = 2\n",
    "    MIXED = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Directory\n",
    "\n",
    "* <i>SSD</i>, falls genug Speicher auf SSD im SymLink <i>fast_output</i> verfügbar ist\n",
    "* <i>HDD</i>, falls möglicherweise zu wenig SSD-Speicher verfügbar ist $\\rightarrow$ <i>output</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import IntEnum\n",
    "\n",
    "class OutputDirectory(IntEnum):\n",
    "    HDD = 0\n",
    "    SSD = 1\n",
    "    \n",
    "output_path = ['output', 'fast_output']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benutzerdefinierte Kostenfunktion & Metrik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def circular_mse(y_true, y_pred):\n",
    "    max_error = tf.constant(360, dtype='float32')\n",
    "    return K.mean(K.square(K.minimum(K.abs(y_pred - y_true), max_error - K.abs(y_pred - y_true))), axis = -1)\n",
    "\n",
    "def circular_mae(y_true, y_pred):\n",
    "    max_error = tf.constant(360, dtype='float32')\n",
    "    return K.mean(K.minimum(K.abs(y_pred - y_true), K.abs(max_error - K.abs(y_pred - y_true))), axis = -1)\n",
    "\n",
    "def custom_mae(y_true, y_pred):\n",
    "    return K.mean(K.abs(y_pred - y_true), axis = -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Label_Type into suitable label names.\n",
    "$\\Rightarrow$ Angular / Normalized $\\rightarrow$ ['Elevation', 'Azimuth']\n",
    "\n",
    "$\\Rightarrow$ Stereographic $\\rightarrow$ ['S_x', 'S_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Label_Names(label_type):\n",
    "    if label_type == 'Angular' or label_type == 'Normalized':\n",
    "        return ['Elevation', 'Azimuth']\n",
    "    elif label_type == 'Stereographic':\n",
    "        return ['S_x', 'S_y']\n",
    "    else:\n",
    "        assert(True, 'LabelType Invalid')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert String into Reduction Metric Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Reduction_Metric(metric):\n",
    "    \n",
    "    if metric == 'custom_mae':\n",
    "        return [custom_mae]\n",
    "    elif metric == 'tf.keras.metrics.MeanAbsoluteError()':\n",
    "        return [tf.keras.metrics.MeanAbsoluteError()]\n",
    "    elif metric == 'circular_mae':\n",
    "        return [circular_mae]\n",
    "    elif metric == 'mean_squared_error':\n",
    "        return ['mean_squared_error']\n",
    "    else:\n",
    "        assert(False, 'Metric yet unknown - Please modify get_Reduction_Metric to meet your requirements')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatische Optimizer Generierung aus String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_optimizer(optimizer):\n",
    "    # [Adam, Nadam, Adagrad, RMSprop]\n",
    "    if optimizer == \"<class 'keras.optimizers.Adam'>\":\n",
    "        return Adam\n",
    "    elif optimizer == \"<class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>\":\n",
    "        return Adam\n",
    "    elif optimizer == \"<class 'keras.optimizers.Nadam'>\":\n",
    "        return Nadam\n",
    "    elif optimizer == \"<class 'keras.optimizers.Adagard'>\":\n",
    "        return Adagard\n",
    "    elif optimizer == \"<class 'keras.optimizers.RMSprop'>\":\n",
    "        return RMSprop\n",
    "    else:\n",
    "        print('ERROR::: Unspecified Optimizer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainingsset-Typ nach String Converter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainingset_to_string(ts):\n",
    "    if ts == TrainingSet.SYNTHETIC:\n",
    "        return 'Synth'\n",
    "    elif ts == TrainingSet.REAL:\n",
    "        return 'Real'\n",
    "    elif ts == TrainingSet.MIXED:\n",
    "        return 'Mixed'\n",
    "    else:\n",
    "        print('Unknown TrainingSet')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generierung Datenpipeline (Angepasst für Talos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data(batch_size, num_samples, label_type):\n",
    "    # if Block für synthetische Daten, um nur auf realen Daten zu trainieren _USE_SYNTHETIC_TRAIN_DATA\n",
    "    # 1. lege df_train und df_valid als leere Liste an\n",
    "    # 2. If-block um Zeile df = ... bis df_valid\n",
    "    \n",
    "    if trainingset == TrainingSet.SYNTHETIC:\n",
    "        df = pd.read_csv(_CSV_FILE)\n",
    "        df_shuffled = df.sample(frac = 1, random_state = 1)\n",
    "        df_train = df_shuffled[0 : int(num_samples * 0.8 // batch_size * batch_size)]\n",
    "        df_valid = df_shuffled.drop(df_shuffled.index[0 : df_train.shape[0]])[0 : int(num_samples * 0.2 // batch_size * batch_size)]\n",
    "        \n",
    "    elif trainingset == TrainingSet.MIXED:\n",
    "        df = pd.read_csv(_CSV_FILE)\n",
    "        df_shuffled = df.sample(frac = 1, random_state = 1)\n",
    "        df_train = df_shuffled[0 : int(num_samples * 0.8 // batch_size * batch_size)]\n",
    "        df_valid = df_shuffled.drop(df_shuffled.index[0 : df_train.shape[0]])[0 : int(num_samples * 0.2 // batch_size * batch_size)]\n",
    "        \n",
    "        df_real = pd.read_csv(_CSV_FILE_REAL)\n",
    "        df_shuffled_real = df_real.sample(frac = 1, random_state = 1)\n",
    "        df_shuffled_real = df_shuffled_real.drop(df_shuffled_real.index[(df_shuffled_real.shape[0] - 61) : df_shuffled_real.shape[0]])\n",
    "        df_train_real = df_shuffled_real[0: int(df_shuffled_real.shape[0] * 0.8 // batch_size * batch_size)]   \n",
    "        df_valid_real = df_shuffled_real.drop(df_shuffled_real.index[0 : df_train_real.shape[0]])\n",
    "        df_train = df_train.drop(df_train.index[df_train.shape[0] - df_train_real.shape[0] : df_train.shape[0]])\n",
    "        df_valid = df_valid.drop(df_valid.index[df_valid.shape[0] - df_valid_real.shape[0] : df_valid.shape[0]])\n",
    "        df_train = df_train.append(df_train_real)\n",
    "        df_valid= df_valid.append(df_valid_real)\n",
    "    \n",
    "    elif trainingset == TrainingSet.REAL: # Add check for num_samples, once the real dataset increases\n",
    "        df_real = pd.read_csv(_CSV_FILE_REAL)\n",
    "        df_shuffled_real = df_real.sample(frac = 1, random_state = 1)\n",
    "        df_shuffled_real = df_shuffled_real.drop(df_shuffled_real.index[(df_shuffled_real.shape[0] - 61) : df_shuffled_real.shape[0]])\n",
    "        df_train = df_shuffled_real[0 : int(df_shuffled_real.shape[0] * 0.8 // batch_size * batch_size)]   \n",
    "        df_valid = df_shuffled_real.drop(df_shuffled_real.index[0 : df_train.shape[0]])\n",
    "        \n",
    "    else:\n",
    "        print('Create_Data :: should not have reached here')\n",
    "        \n",
    "\n",
    "        \n",
    "    if _USE_DATA_AUGMENTATION:\n",
    "        train_data_generator = ImageDataGenerator(\n",
    "            rescale = 1./255,\n",
    "            width_shift_range = 0.1,\n",
    "            height_shift_range = 0.1,\n",
    "            zoom_range = 0.1,\n",
    "            brightness_range = (0.25, 0.75),\n",
    "            fill_mode = 'nearest'\n",
    "        )\n",
    "    else:\n",
    "        train_data_generator = ImageDataGenerator(\n",
    "            rescale = 1./255\n",
    "        )\n",
    "        \n",
    "    print('Y-Col: {}'.format(get_Label_Names(label_type)))\n",
    "    print('Train Data Generator: ', end = '')\n",
    "    \n",
    "    train_generator = train_data_generator.flow_from_dataframe(\n",
    "        dataframe = df_train,\n",
    "        directory = _IMAGE_DIR,\n",
    "        x_col = 'Filename RGB',\n",
    "        y_col = get_Label_Names(label_type),\n",
    "        class_mode = 'raw',\n",
    "        target_size = (224, 224),\n",
    "        color_mode = 'rgb',\n",
    "        shuffle = True,\n",
    "        seed = 77,\n",
    "        batch_size = batch_size\n",
    "    )\n",
    "    \n",
    "    valid_data_generator = ImageDataGenerator(\n",
    "        rescale = 1./255\n",
    "    )\n",
    "    \n",
    "    print('Validation Data Generator: ', end = '')\n",
    "    \n",
    "    valid_generator = valid_data_generator.flow_from_dataframe(\n",
    "        dataframe = df_valid,\n",
    "        directory = _IMAGE_DIR,\n",
    "        x_col = 'Filename RGB',\n",
    "        y_col = get_Label_Names(label_type),\n",
    "        class_mode = 'raw',\n",
    "        target_size = (224, 224),\n",
    "        color_mode = 'rgb',\n",
    "        shuffle = False,\n",
    "        seed = 77,\n",
    "        batch_size = batch_size\n",
    "    )\n",
    "    \n",
    "    return train_generator, valid_generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generierung Modell (Angepasst für Talos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_model_fine(x, y, x_val, y_val, params):\n",
    "    print('==========================Params:')\n",
    "    print(params)\n",
    "    print('==========================')\n",
    "    \n",
    "    K.clear_session()\n",
    "    \n",
    "    train_generator, valid_generator = create_data(params['batch_size'], params['samples'], params['label_type'])\n",
    "    tg_steps_per_epoch = train_generator.n // train_generator.batch_size\n",
    "    vg_validation_steps = valid_generator.n // valid_generator.batch_size\n",
    "    print('Steps per Epoch: {}, Validation Steps: {}'.format(tg_steps_per_epoch, vg_validation_steps))\n",
    "    \n",
    "    dropout_rate = params['dropout']\n",
    "    first_neuron = params['first_neuron']\n",
    "    \n",
    "    if params['activation'] == 'leakyrelu':\n",
    "        activation_layer = LeakyReLU(alpha = params['leaky_alpha'])\n",
    "    elif params['activation'] == 'relu':\n",
    "        activation_layer = ReLU()\n",
    "    \n",
    "    model = Sequential()\n",
    "    cnn = VGG16(weights = 'imagenet', include_top = False, input_shape = (224, 224, 3))\n",
    "    \n",
    "    for layer in cnn.layers[:15]:\n",
    "        layer.trainable = False\n",
    "        #print(layer.name, layer.trainable)\n",
    "        \n",
    "    print('_________________________________________________________________')\n",
    "    print('{:>16} {:>16}'.format('Network Layer', 'Trainable'))\n",
    "    print('=================================================================')\n",
    "    for layer in cnn.layers:\n",
    "        print('{:>16} {:>16}'.format(layer.name, layer.trainable))\n",
    "    print('_________________________________________________________________\\n')\n",
    "    \n",
    "    model.add(cnn)\n",
    "    \n",
    "    fc = Sequential()\n",
    "    fc.add(Flatten(input_shape = model.output_shape[1:])) # (7, 7, 512)\n",
    "    \n",
    "    fc.add(Dense(units = first_neuron, kernel_initializer = glorot_uniform(seed = 1)))\n",
    "    fc.add(activation_layer)\n",
    "    if dropout_rate > 0.0:\n",
    "        fc.add(Dropout(rate = dropout_rate))\n",
    "    \n",
    "    print('Number Hidden Layers {}'.format(params['hidden_layers']))\n",
    "    hidden_neuron_fraction = first_neuron\n",
    "    for i in range(params['hidden_layers']):\n",
    "        hidden_neuron_fraction = hidden_neuron_fraction // 2\n",
    "        fc.add(Dense(units = hidden_neuron_fraction, kernel_initializer = glorot_uniform(seed = 1)))\n",
    "        fc.add(activation_layer)\n",
    "        if dropout_rate > 0.0:\n",
    "            fc.add(Dropout(rate = dropout_rate))\n",
    "    \n",
    "    fc.add(Dense(units = 2, kernel_initializer = glorot_uniform(seed = 1)))\n",
    "    fc.load_weights(_MODEL_DIR + _MODEL_TO_LOAD)\n",
    "    model.add(fc)\n",
    "    print('Fully Connected Layers added to Base Network')\n",
    "    \n",
    "    print('Using Loss: {} \\nand Reduction Metric: {}'.format(\n",
    "        params['loss_function'], \n",
    "        get_Reduction_Metric(params['reduction_metric'])))\n",
    "    \n",
    "    model.compile(\n",
    "        #optimizer=params['optimizer'](lr=lr_normalizer(params['lr'], params['optimizer'])*1e-2),\n",
    "        optimizer = params['optimizer'](lr = lr_normalizer(params['lr'], params['optimizer']) * 1e-3),\n",
    "        loss = params['loss_function'],\n",
    "        metrics = get_Reduction_Metric(params['reduction_metric'])\n",
    "    )\n",
    "    print('Model was compiled')\n",
    "    print(model.summary())\n",
    "    print('_________________________________________________________________')\n",
    "    \n",
    "    checkpointer = callbacks.ModelCheckpoint(\n",
    "        filepath = _LOG_DIR + 'CNN_Base_{}_Model_and_Weights_{}.hdf5'.format(_MODEL_TO_LOAD_INDEX, train_generator.n),\n",
    "        monitor =  params['monitor_value'],\n",
    "        verbose = 1,\n",
    "        save_weights_only = False,\n",
    "        save_best_only = True,\n",
    "        mode = 'min'\n",
    "    )\n",
    "    print('Checkpointer was created')\n",
    "    \n",
    "    csv_logger = callbacks.CSVLogger(\n",
    "        filename = _LOG_DIR + 'CNN_Base_{}_Logger_{}.csv'.format(_MODEL_TO_LOAD_INDEX, train_generator.n),\n",
    "        separator = ',',\n",
    "        append = False\n",
    "    )\n",
    "    print('CSV Logger was created')\n",
    "\n",
    "    lr_reducer = callbacks.ReduceLROnPlateau(\n",
    "        monitor = 'val_loss',\n",
    "        factor = 0.1,\n",
    "        patience = 13,\n",
    "        verbose = 1,\n",
    "        mode = 'min',\n",
    "        min_delta = 0.0001\n",
    "    )\n",
    "    print('Learning Rate Reducer was created')\n",
    "    \n",
    "    early_stopper = callbacks.EarlyStopping(\n",
    "        monitor = 'val_loss',\n",
    "        min_delta = 0,\n",
    "        #patience = 15,\n",
    "        patience = 20,\n",
    "        verbose = 1,\n",
    "        mode = 'min',\n",
    "        restore_best_weights = True\n",
    "    )\n",
    "    print('Early Stopper was created')\n",
    "    \n",
    "    out = model.fit(\n",
    "        x = train_generator,\n",
    "        steps_per_epoch = tg_steps_per_epoch,\n",
    "        validation_data = valid_generator,\n",
    "        validation_steps = vg_validation_steps,\n",
    "        callbacks = [checkpointer, csv_logger, lr_reducer, early_stopper],\n",
    "        epochs = params['epochs'],\n",
    "        workers = 8\n",
    "    )\n",
    "    \n",
    "    return out, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feinoptimierung <a name = \"setup\"></a><a href = #Top>Up</a></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyper Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     Adam = RMSprop + Momentum (lr=0.001)\n",
    "#     Nadam = Adam RMSprop + Nesterov-Momentum (lr=0.002)\n",
    "#     RMSprop = (lr=0.001)\n",
    "#     SGD = (lr=0.01)\n",
    "#     Adagrad\n",
    "\n",
    "global_hyper_parameter = {\n",
    "    'samples': None,\n",
    "    'epochs': None,\n",
    "    'batch_size': None,\n",
    "    'optimizer': None,\n",
    "    'lr': None,\n",
    "    'first_neuron': None,\n",
    "    'dropout': None,\n",
    "    'activation': None,\n",
    "    'leaky_alpha': None,\n",
    "    'hidden_layers': None,\n",
    "    # beginning from here, Values should only contain one single entry:\n",
    "    # ===============================================================\n",
    "    'label_type': ['Angular'], # Stereographic, Angular, Normalized\n",
    "    'loss_function': None,\n",
    "    'reduction_metric': None,\n",
    "    'monitor_value': None\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "_RUN = 'SYNTH'\n",
    "_LOSS = 'MSE'\n",
    "_DATASET_NAME = '201019_2253_final'#'2020-05-28'\n",
    "_DEVICE = 'GeForce_RTX_2080_Ti'#'TITAN_GPU1'\n",
    "\n",
    "storage = OutputDirectory.SSD # 'fast_output' if ssd storage may suffice, 'output' otherwise\n",
    "\n",
    "if global_hyper_parameter['label_type'][0] == 'Stereographic':\n",
    "    _CSV_SYNTH_FILE_NAME = 'images_synthetisch_stereographic.csv'\n",
    "    _CSV_REAL_FILE_NAME = 'images_real_stereographic.csv'\n",
    "    \n",
    "elif global_hyper_parameter['label_type'][0] == 'Angular':\n",
    "    _CSV_SYNTH_FILE_NAME = 'labels_ks_RGB.csv'\n",
    "    _CSV_REAL_FILE_NAME = 'images_real.csv'\n",
    "    \n",
    "elif global_hyper_parameter['label_type'][0] == 'Normalized':\n",
    "    _CSV_SYNTH_FILE_NAME = 'images_synthetisch_normalized.csv'\n",
    "    _CSV_REAL_FILE_NAME = 'images_real_normalized.csv'\n",
    "    \n",
    "else:\n",
    "    assert(True, 'Label Type Invalid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingset = TrainingSet.SYNTHETIC\n",
    "_USE_DATA_AUGMENTATION = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory >>| ..\\fast_output\\SYNTH_Regression_MSE\\201019_2253_final_Angular_Top_1_Custom-MAE\\Synth_TD\\ |<< existiert bereits. Fortsetzen auf eigene Gefahr! (Weiter mit Enter)\n"
     ]
    }
   ],
   "source": [
    "_IMAGE_DIR = '..\\\\..\\\\data_generation\\\\dataset\\\\{}\\\\'.format(_DATASET_NAME)\n",
    "_CSV_FILE = _IMAGE_DIR + _CSV_SYNTH_FILE_NAME\n",
    "_CSV_FILE_REAL = _IMAGE_DIR + _CSV_REAL_FILE_NAME\n",
    "\n",
    "_note = '_Custom-MAE'\n",
    "\n",
    "_MODEL_DIR = '..\\\\output\\\\{}_Regression_{}\\\\{}_{}_Base{}\\\\'.format(_RUN, _LOSS, _DATASET_NAME, global_hyper_parameter['label_type'][0], _note)\n",
    "_NET_DIR = '{}_Regression_{}\\\\{}_{}_Top_1{}\\\\{}_TD\\\\'.format(_RUN, _LOSS, _DATASET_NAME, global_hyper_parameter['label_type'][0], _note, trainingset_to_string(trainingset))\n",
    "_LOG_DIR = '..\\\\{}\\\\{}'.format(output_path[storage], _NET_DIR)\n",
    "\n",
    "if(not os.path.exists(_LOG_DIR)):\n",
    "    os.makedirs(_LOG_DIR)\n",
    "else:\n",
    "    input('Directory >>| {} |<< existiert bereits. Fortsetzen auf eigene Gefahr! (Weiter mit Enter)'.format(_LOG_DIR))\n",
    "\n",
    "device_file = open(_LOG_DIR + '{}.txt'.format(_DEVICE), \"a+\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 3 FC-Gewichte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying: ..\\output\\SYNTH_Regression_MSE\\201019_2253_final_Angular_Base_Custom-MAE\\..\\201019_2253_final_Angular_Base_Custom-MAE_Results.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>duration</th>\n",
       "      <th>loss</th>\n",
       "      <th>custom_mae</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_custom_mae</th>\n",
       "      <th>activation</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>dropout</th>\n",
       "      <th>first_neuron</th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th>label_type</th>\n",
       "      <th>loss_function</th>\n",
       "      <th>lr</th>\n",
       "      <th>monitor_value</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>reduction_metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>10/22/20-210538</td>\n",
       "      <td>10/22/20-210553</td>\n",
       "      <td>14.862882</td>\n",
       "      <td>4383.826411</td>\n",
       "      <td>40.741211</td>\n",
       "      <td>2547.475186</td>\n",
       "      <td>28.446991</td>\n",
       "      <td>leakyrelu</td>\n",
       "      <td>32</td>\n",
       "      <td>0.25</td>\n",
       "      <td>4096</td>\n",
       "      <td>0</td>\n",
       "      <td>Angular</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>5</td>\n",
       "      <td>val_custom_mae</td>\n",
       "      <td>&lt;class 'tensorflow.python.keras.optimizer_v2.a...</td>\n",
       "      <td>custom_mae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>123</td>\n",
       "      <td>10/22/20-212354</td>\n",
       "      <td>10/22/20-212407</td>\n",
       "      <td>12.900292</td>\n",
       "      <td>4370.115269</td>\n",
       "      <td>41.885189</td>\n",
       "      <td>2500.798960</td>\n",
       "      <td>28.509195</td>\n",
       "      <td>leakyrelu</td>\n",
       "      <td>64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>4096</td>\n",
       "      <td>1</td>\n",
       "      <td>Angular</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>1</td>\n",
       "      <td>val_custom_mae</td>\n",
       "      <td>&lt;class 'tensorflow.python.keras.optimizer_v2.a...</td>\n",
       "      <td>custom_mae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>10/22/20-210249</td>\n",
       "      <td>10/22/20-210259</td>\n",
       "      <td>9.804774</td>\n",
       "      <td>4001.966997</td>\n",
       "      <td>39.212330</td>\n",
       "      <td>2567.742597</td>\n",
       "      <td>28.672417</td>\n",
       "      <td>leakyrelu</td>\n",
       "      <td>32</td>\n",
       "      <td>0.25</td>\n",
       "      <td>2048</td>\n",
       "      <td>0</td>\n",
       "      <td>Angular</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>5</td>\n",
       "      <td>val_custom_mae</td>\n",
       "      <td>&lt;class 'tensorflow.python.keras.optimizer_v2.a...</td>\n",
       "      <td>custom_mae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>10/22/20-210657</td>\n",
       "      <td>10/22/20-210713</td>\n",
       "      <td>16.076730</td>\n",
       "      <td>5342.255862</td>\n",
       "      <td>44.598431</td>\n",
       "      <td>2508.385596</td>\n",
       "      <td>29.009453</td>\n",
       "      <td>leakyrelu</td>\n",
       "      <td>32</td>\n",
       "      <td>0.25</td>\n",
       "      <td>4096</td>\n",
       "      <td>2</td>\n",
       "      <td>Angular</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>2</td>\n",
       "      <td>val_custom_mae</td>\n",
       "      <td>&lt;class 'tensorflow.python.keras.optimizer_v2.a...</td>\n",
       "      <td>custom_mae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>126</td>\n",
       "      <td>10/22/20-212434</td>\n",
       "      <td>10/22/20-212447</td>\n",
       "      <td>12.947577</td>\n",
       "      <td>4892.983958</td>\n",
       "      <td>44.019562</td>\n",
       "      <td>2545.006084</td>\n",
       "      <td>29.102833</td>\n",
       "      <td>leakyrelu</td>\n",
       "      <td>64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>4096</td>\n",
       "      <td>2</td>\n",
       "      <td>Angular</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>1</td>\n",
       "      <td>val_custom_mae</td>\n",
       "      <td>&lt;class 'tensorflow.python.keras.optimizer_v2.a...</td>\n",
       "      <td>custom_mae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>109</td>\n",
       "      <td>10/22/20-212138</td>\n",
       "      <td>10/22/20-212146</td>\n",
       "      <td>8.363558</td>\n",
       "      <td>4502.218566</td>\n",
       "      <td>42.888409</td>\n",
       "      <td>2549.238323</td>\n",
       "      <td>29.138407</td>\n",
       "      <td>leakyrelu</td>\n",
       "      <td>64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>2048</td>\n",
       "      <td>1</td>\n",
       "      <td>Angular</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>2</td>\n",
       "      <td>val_custom_mae</td>\n",
       "      <td>&lt;class 'tensorflow.python.keras.optimizer_v2.a...</td>\n",
       "      <td>custom_mae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>10/22/20-210641</td>\n",
       "      <td>10/22/20-210657</td>\n",
       "      <td>15.954672</td>\n",
       "      <td>4115.395587</td>\n",
       "      <td>41.639866</td>\n",
       "      <td>2575.603947</td>\n",
       "      <td>29.298376</td>\n",
       "      <td>leakyrelu</td>\n",
       "      <td>32</td>\n",
       "      <td>0.25</td>\n",
       "      <td>4096</td>\n",
       "      <td>2</td>\n",
       "      <td>Angular</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>1</td>\n",
       "      <td>val_custom_mae</td>\n",
       "      <td>&lt;class 'tensorflow.python.keras.optimizer_v2.a...</td>\n",
       "      <td>custom_mae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>108</td>\n",
       "      <td>10/22/20-212129</td>\n",
       "      <td>10/22/20-212137</td>\n",
       "      <td>8.271264</td>\n",
       "      <td>3881.180195</td>\n",
       "      <td>40.146988</td>\n",
       "      <td>2558.554630</td>\n",
       "      <td>29.299927</td>\n",
       "      <td>leakyrelu</td>\n",
       "      <td>64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>2048</td>\n",
       "      <td>1</td>\n",
       "      <td>Angular</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>1</td>\n",
       "      <td>val_custom_mae</td>\n",
       "      <td>&lt;class 'tensorflow.python.keras.optimizer_v2.a...</td>\n",
       "      <td>custom_mae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>10/22/20-210300</td>\n",
       "      <td>10/22/20-210310</td>\n",
       "      <td>10.109706</td>\n",
       "      <td>3871.796719</td>\n",
       "      <td>39.797153</td>\n",
       "      <td>2617.595140</td>\n",
       "      <td>29.322357</td>\n",
       "      <td>leakyrelu</td>\n",
       "      <td>32</td>\n",
       "      <td>0.25</td>\n",
       "      <td>2048</td>\n",
       "      <td>1</td>\n",
       "      <td>Angular</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>1</td>\n",
       "      <td>val_custom_mae</td>\n",
       "      <td>&lt;class 'tensorflow.python.keras.optimizer_v2.a...</td>\n",
       "      <td>custom_mae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>10/22/20-210403</td>\n",
       "      <td>10/22/20-210413</td>\n",
       "      <td>10.425704</td>\n",
       "      <td>4304.128398</td>\n",
       "      <td>43.794651</td>\n",
       "      <td>2461.137874</td>\n",
       "      <td>29.322683</td>\n",
       "      <td>leakyrelu</td>\n",
       "      <td>32</td>\n",
       "      <td>0.25</td>\n",
       "      <td>2048</td>\n",
       "      <td>3</td>\n",
       "      <td>Angular</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>1</td>\n",
       "      <td>val_custom_mae</td>\n",
       "      <td>&lt;class 'tensorflow.python.keras.optimizer_v2.a...</td>\n",
       "      <td>custom_mae</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0            start              end   duration         loss  \\\n",
       "32           32  10/22/20-210538  10/22/20-210553  14.862882  4383.826411   \n",
       "123         123  10/22/20-212354  10/22/20-212407  12.900292  4370.115269   \n",
       "17           17  10/22/20-210249  10/22/20-210259   9.804774  4001.966997   \n",
       "37           37  10/22/20-210657  10/22/20-210713  16.076730  5342.255862   \n",
       "126         126  10/22/20-212434  10/22/20-212447  12.947577  4892.983958   \n",
       "109         109  10/22/20-212138  10/22/20-212146   8.363558  4502.218566   \n",
       "36           36  10/22/20-210641  10/22/20-210657  15.954672  4115.395587   \n",
       "108         108  10/22/20-212129  10/22/20-212137   8.271264  3881.180195   \n",
       "18           18  10/22/20-210300  10/22/20-210310  10.109706  3871.796719   \n",
       "24           24  10/22/20-210403  10/22/20-210413  10.425704  4304.128398   \n",
       "\n",
       "     custom_mae     val_loss  val_custom_mae activation  batch_size  dropout  \\\n",
       "32    40.741211  2547.475186       28.446991  leakyrelu          32     0.25   \n",
       "123   41.885189  2500.798960       28.509195  leakyrelu          64     0.25   \n",
       "17    39.212330  2567.742597       28.672417  leakyrelu          32     0.25   \n",
       "37    44.598431  2508.385596       29.009453  leakyrelu          32     0.25   \n",
       "126   44.019562  2545.006084       29.102833  leakyrelu          64     0.25   \n",
       "109   42.888409  2549.238323       29.138407  leakyrelu          64     0.25   \n",
       "36    41.639866  2575.603947       29.298376  leakyrelu          32     0.25   \n",
       "108   40.146988  2558.554630       29.299927  leakyrelu          64     0.25   \n",
       "18    39.797153  2617.595140       29.322357  leakyrelu          32     0.25   \n",
       "24    43.794651  2461.137874       29.322683  leakyrelu          32     0.25   \n",
       "\n",
       "     first_neuron  hidden_layers label_type       loss_function  lr  \\\n",
       "32           4096              0    Angular  mean_squared_error   5   \n",
       "123          4096              1    Angular  mean_squared_error   1   \n",
       "17           2048              0    Angular  mean_squared_error   5   \n",
       "37           4096              2    Angular  mean_squared_error   2   \n",
       "126          4096              2    Angular  mean_squared_error   1   \n",
       "109          2048              1    Angular  mean_squared_error   2   \n",
       "36           4096              2    Angular  mean_squared_error   1   \n",
       "108          2048              1    Angular  mean_squared_error   1   \n",
       "18           2048              1    Angular  mean_squared_error   1   \n",
       "24           2048              3    Angular  mean_squared_error   1   \n",
       "\n",
       "      monitor_value                                          optimizer  \\\n",
       "32   val_custom_mae  <class 'tensorflow.python.keras.optimizer_v2.a...   \n",
       "123  val_custom_mae  <class 'tensorflow.python.keras.optimizer_v2.a...   \n",
       "17   val_custom_mae  <class 'tensorflow.python.keras.optimizer_v2.a...   \n",
       "37   val_custom_mae  <class 'tensorflow.python.keras.optimizer_v2.a...   \n",
       "126  val_custom_mae  <class 'tensorflow.python.keras.optimizer_v2.a...   \n",
       "109  val_custom_mae  <class 'tensorflow.python.keras.optimizer_v2.a...   \n",
       "36   val_custom_mae  <class 'tensorflow.python.keras.optimizer_v2.a...   \n",
       "108  val_custom_mae  <class 'tensorflow.python.keras.optimizer_v2.a...   \n",
       "18   val_custom_mae  <class 'tensorflow.python.keras.optimizer_v2.a...   \n",
       "24   val_custom_mae  <class 'tensorflow.python.keras.optimizer_v2.a...   \n",
       "\n",
       "    reduction_metric  \n",
       "32        custom_mae  \n",
       "123       custom_mae  \n",
       "17        custom_mae  \n",
       "37        custom_mae  \n",
       "126       custom_mae  \n",
       "109       custom_mae  \n",
       "36        custom_mae  \n",
       "108       custom_mae  \n",
       "18        custom_mae  \n",
       "24        custom_mae  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_results = _MODEL_DIR + '..\\\\{}_{}_Base{}_Results.csv'.format(_DATASET_NAME, global_hyper_parameter['label_type'][0], _note)\n",
    "df = pd.read_csv(base_results).drop(columns = ['round_epochs', 'samples', 'epochs'], axis = 0)\n",
    "sort_value = df['monitor_value'][0]\n",
    "df = df.sort_values(sort_value, axis = 0, ascending = True, inplace = False, kind = 'quicksort', na_position = 'last')\n",
    "print('Displaying: {}'.format(base_results))\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSerach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_params(top_results_index):\n",
    "    \n",
    "    #     Adam = RMSprop + Momentum (lr=0.001)\n",
    "    #     Nadam = Adam RMSprop + Nesterov-Momentum (lr=0.002)\n",
    "    #     RMSprop = (lr=0.001)\n",
    "    #     SGD = (lr=0.01)\n",
    "    #     Adagrad\n",
    "\n",
    "    hyper_parameter = global_hyper_parameter\n",
    "\n",
    "    hyper_parameter['samples'] = [100000] \n",
    "    hyper_parameter['epochs'] = [400]\n",
    "    hyper_parameter['batch_size'] = [df.iloc[top_results_index]['batch_size']]\n",
    "    hyper_parameter['optimizer'] = [make_optimizer(df.loc[top_results_index]['optimizer'])]\n",
    "    hyper_parameter['lr'] = [df.iloc[top_results_index]['lr']]\n",
    "    hyper_parameter['first_neuron'] = [df.iloc[top_results_index]['first_neuron']]\n",
    "    hyper_parameter['dropout'] = [df.iloc[top_results_index]['dropout']]\n",
    "    hyper_parameter['activation'] = [df.iloc[top_results_index]['activation']]\n",
    "    hyper_parameter['leaky_alpha'] = [0.1] #Default bei LeakyReLU, sonst PReLU\n",
    "    hyper_parameter['hidden_layers'] = [df.iloc[top_results_index]['hidden_layers']]\n",
    "    \n",
    "    hyper_parameter['loss_function'] = [df.iloc[top_results_index]['loss_function']]\n",
    "    hyper_parameter['reduction_metric'] = [df.iloc[top_results_index]['reduction_metric']]\n",
    "    hyper_parameter['monitor_value'] = [df.iloc[top_results_index]['monitor_value']]\n",
    "\n",
    "    return hyper_parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\\..\\data_generation\\dataset\\201019_2253_final\\labels_ks_RGB.csv\n",
      "buddha/rgb/buddha00000000-0-5-0-5.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "print(_CSV_FILE)\n",
    "df = pd.read_csv(_CSV_FILE)\n",
    "df.head()\n",
    "print(df.iloc[0]['Filename RGB'])\n",
    "#Image(df.iloc[0]['Filename RGB'])\n",
    "#Image('../buddha00000001-0-5-0-10.png')\n",
    "#Image('../../data_generation/dataset/201019_2253_final/buddha/rgb/buddha00000000-0-5-0-5.png')\n",
    "Image('..\\\\..\\\\data_generation\\\\dataset\\\\201019_2253_final\\\\buddha\\\\rgb\\\\buddha00000000-0-5-0-5.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Talos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'batch_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mD:\\anaconda\\envs\\tf_ks\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2888\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2889\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2890\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'batch_size'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-90-f33b64b82aa0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mstartTime\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mparameters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtop_results_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;31m#with tf.compat.v1.Session() as sess:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-88-3be740d46dee>\u001b[0m in \u001b[0;36mget_params\u001b[1;34m(top_results_index)\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mhyper_parameter\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'samples'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m100000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mhyper_parameter\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'epochs'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m400\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mhyper_parameter\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'batch_size'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtop_results_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'batch_size'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[0mhyper_parameter\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'optimizer'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mmake_optimizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtop_results_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'optimizer'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mhyper_parameter\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lr'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtop_results_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lr'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\tf_ks\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    880\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    881\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 882\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m         if (\n",
      "\u001b[1;32mD:\\anaconda\\envs\\tf_ks\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m    989\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    990\u001b[0m         \u001b[1;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 991\u001b[1;33m         \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    992\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    993\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\tf_ks\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2889\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2890\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2891\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2892\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2893\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'batch_size'"
     ]
    }
   ],
   "source": [
    "dummy_x = np.empty((1, 2, 3, 224, 224))\n",
    "dummy_y = np.empty((1, 2))\n",
    "\n",
    "with tf.device('/device:GPU:1'):\n",
    "    #for top_results_index in range(3):\n",
    "    #for top_results_index in [0, 1]:\n",
    "        top_results_index = 0\n",
    "        _MODEL_TO_LOAD_INDEX = df.iloc[top_results_index].name\n",
    "        _MODEL_TO_LOAD = 'Best_Weights_FC_{}.hdf5'.format(_MODEL_TO_LOAD_INDEX)\n",
    "\n",
    "        _TMP_DIR = '..\\\\TMP_TALOS_{}'.format(_DEVICE)\n",
    "        _CSV_RESULTS = _LOG_DIR + 'Talos_Results_Fine_Idx{}.csv'.format(_MODEL_TO_LOAD_INDEX)\n",
    "\n",
    "        startTime = datetime.now()\n",
    "        \n",
    "        parameters = get_params(top_results_index)\n",
    "        \n",
    "        t = ta.Scan(\n",
    "            x = dummy_x,\n",
    "            y = dummy_y,\n",
    "            model = grid_model_fine,\n",
    "            params = parameters,\n",
    "            experiment_name = _TMP_DIR,\n",
    "            #shuffle=False,\n",
    "            reduction_metric = parameters['reduction_metric'][0],\n",
    "            disable_progress_bar = False,\n",
    "            print_params = True,\n",
    "            clear_session = True\n",
    "        )\n",
    "\n",
    "        print(\"Time taken:\", datetime.now() - startTime)\n",
    "        \n",
    "        print('Writing Device File')\n",
    "        device_file.write('Trained Model: {}'.format(_MODEL_TO_LOAD))\n",
    "\n",
    "        df_experiment_results = pd.read_csv(_TMP_DIR + '\\\\' + os.listdir(_TMP_DIR)[0])\n",
    "        df_experiment_results['Base'] = None\n",
    "        for i in range(df_experiment_results.shape[0]):\n",
    "            df_experiment_results['Base'][i] = _MODEL_TO_LOAD_INDEX\n",
    "\n",
    "        if os.path.isfile(_CSV_RESULTS):\n",
    "            df_experiment_results.to_csv(_CSV_RESULTS, mode = 'a', index = False, header = False)\n",
    "        else:\n",
    "            df_experiment_results.to_csv(_CSV_RESULTS, index = False)\n",
    "\n",
    "        shutil.rmtree(_TMP_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copy Results to NAS if SSD Directory was selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_directory(src, dst, symlinks = False, ignore = None):\n",
    "    maxLen = 0\n",
    "    message = ''        \n",
    "    \n",
    "    if not os.path.exists(dst):\n",
    "        \n",
    "        message = 'Creating Path: {}'.format(src)\n",
    "        maxLen = max(maxLen, len(message))\n",
    "        print(message + ' ' * (maxLen - len(message)), end = '\\r')\n",
    "        \n",
    "        os.makedirs(dst)\n",
    "        \n",
    "    for item in os.listdir(src):\n",
    "        \n",
    "        s = os.path.join(src, item)\n",
    "        d = os.path.join(dst, item)\n",
    "        \n",
    "        if os.path.isdir(s):\n",
    "            \n",
    "            message = 'Copying Directory: {}'.format(s)\n",
    "            maxLen = max(maxLen, len(message))\n",
    "            print(message + ' ' * (maxLen - len(message)), end = '\\r')\n",
    "            \n",
    "            shutil.copytree(s, d, symlinks, ignore)\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            if not os.path.exists(d): #or os.stat(s).st_mtime - os.stat(d).st_mtime > 1:\n",
    "                \n",
    "                message = 'Copying File: {}'.format(s)\n",
    "                maxLen = max(maxLen, len(message))\n",
    "                print(message + ' ' * (maxLen - len(message)), end = '\\r')\n",
    "                \n",
    "                shutil.copy2(s, d)\n",
    "        \n",
    "        time.sleep(.5)\n",
    "     \n",
    "    message = 'Coyping... Done'\n",
    "    maxLen = max(maxLen, len(message))\n",
    "    print(message + ' ' * (maxLen - len(message)), end = '\\n')\n",
    "\n",
    "def delete_directory(src, terminator = '\\n'):\n",
    "    message = ''\n",
    "    maxLen = 0\n",
    "    \n",
    "    try:\n",
    "        message = 'Deleting {}'.format(src)\n",
    "        maxLen = max(maxLen, len(message))\n",
    "        print(message + ' ' * (maxLen - len(message)), end = '\\r')\n",
    "        \n",
    "        shutil.rmtree(src)\n",
    "        \n",
    "    except OSError as e:\n",
    "        message = 'Error: {} : {}'.format(src, e.strerror)\n",
    "        maxLen = max(maxLen, len(message))\n",
    "        print(message + ' ' * (maxLen - len(message)), end = '\\n')\n",
    "        return\n",
    "    \n",
    "    message = 'Deleting... Done'\n",
    "    maxLen = max(maxLen, len(message))\n",
    "    print(message + ' ' * (maxLen - len(message)), end = terminator)\n",
    "\n",
    "    \n",
    "def copy_fine_training(src, dst):\n",
    "    copy_directory(src, dst)\n",
    "    delete_directory(src, terminator = '\\r')\n",
    "    delete_directory(src + '..\\\\', terminator = '\\r')\n",
    "    if not os.listdir(src + '..\\\\..\\\\'):\n",
    "        delete_directory(src + '..\\\\..\\\\', terminator = '\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(storage == OutputDirectory.SSD):\n",
    "    _COPY_DIR = '..\\\\output\\\\{}'.format(_NET_DIR)\n",
    "    copy_fine_training(_LOG_DIR, _COPY_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name = \"CMSE.Mixed\"></a><a href = #Top>Up</a></p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
