{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation <a name = \"Top\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick Links\n",
    "\n",
    "<ol>\n",
    "    <li><a href = #setup>Setup</a></li>\n",
    "    <li><a href = #plots>Plots</a></li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil\n",
    "\n",
    "from enum import Enum\n",
    "\n",
    "from numpy import array\n",
    "\n",
    "import ntpath\n",
    "\n",
    "import copy\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hilfsfunktionen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enum für Trainingsset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingSet(Enum):\n",
    "    SYNTHETIC = 1\n",
    "    REAL = 2\n",
    "    MIXED = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enum für Label-Typ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelType(Enum):\n",
    "    ANGULAR = 1\n",
    "    STEREOGRAPHIC = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainingsset-Typ nach String Converter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainingset_to_string(ts):\n",
    "    if ts == TrainingSet.SYNTHETIC:\n",
    "        return 'Synth'\n",
    "    elif ts == TrainingSet.REAL:\n",
    "        return 'Real'\n",
    "    elif ts == TrainingSet.MIXED:\n",
    "        return 'Mixed'\n",
    "    else:\n",
    "        print('Unknown TrainingSet')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LabelType nach String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labeltype_to_string(lt):\n",
    "    if lt == LabelType.ANGULAR:\n",
    "        return 'Angular'\n",
    "    if lt == LabelType.STEREOGRAPHIC:\n",
    "        return 'Stereographic'\n",
    "    else:\n",
    "        print('Unknown LabelType')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Required format of parameters parameter for _model_predict_ (...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = {\n",
    "    'dataset_to_use':[],\n",
    "    'model_to_load':[],\n",
    "    'dataset_name':'combined_dataset',\n",
    "    'activation_function':[],\n",
    "    'leaky_ReLU_alpha':[],\n",
    "    'first_neuron':[],\n",
    "    'dropout_rate':[],\n",
    "    'hidden_layers':[],\n",
    "    'optimizer':[],\n",
    "    'learning_rate':[],\n",
    "    'loss_function':[],\n",
    "    'label_type':[]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hilfsfunktionen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Konvertierung ($S_x$, $S_y$) $\\rightarrow$ ($\\phi$, $\\theta$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_from_stereographic(sx, sy, r = 1):\n",
    "    \n",
    "    l = np.sqrt(sx * sx + sy * sy)\n",
    "    theta = 90 - 2 * np.degrees(np.arctan(l / 2))\n",
    "    \n",
    "    if sx < 0:\n",
    "        phi = 180 - np.degrees(np.arcsin(sy / l))\n",
    "        \n",
    "    elif sx >= 0:\n",
    "        if sy > 0:\n",
    "            phi = np.degrees(np.arcsin(sy / l))\n",
    "        elif sy < 0:\n",
    "            phi = 360 + np.degrees(np.arcsin(sy / l))\n",
    "        else:\n",
    "            #phi1 = np.NaN\n",
    "            phi = 0\n",
    "    else:\n",
    "        print('sx and sy undefined. should not have reached here')\n",
    "\n",
    "    return phi, theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Konvertierung ($\\phi$, $\\theta$) $\\rightarrow$ ($S_x$, $S_y$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_from_spheric(phi, theta, r = 1):\n",
    "    m = 2 * r * np.tan(np.radians((90 - theta) / 2))\n",
    "    sy = m * np.sin(np.radians(phi))\n",
    "    sx = m * np.cos(np.radians(phi))\n",
    "    return sx, sy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Radians $\\rightarrow$ Degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_degree(angle_in_rad):\n",
    "    return angle_in_rad * 180 / np.pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Degree $\\rightarrow$ Radians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_radians(angle_in_deg):\n",
    "    return angle_in_deg * np.pi / 180"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sphärische $\\rightarrow$ Karthesische Koordinaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spheric_cartesian_polar(phi_d, theta_d):\n",
    "    x = np.sin(np.radians(90.0 - theta_d)) * np.cos(np.radians(phi_d))\n",
    "    y = np.sin(np.radians(90.0 - theta_d)) * np.sin(np.radians(phi_d))\n",
    "    z = np.cos(np.radians(90.0 - theta_d))\n",
    "    return array([x, y, z])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spheric_cartesian_elevation(phi_d, theta_d):\n",
    "    x = np.cos(np.radians(theta_d)) * np.cos(np.radians(phi_d))\n",
    "    y = np.cos(np.radians(theta_d)) * np.sin(np.radians(phi_d))\n",
    "    z = np.sin(np.radians(theta_d))\n",
    "    return array([x, y, z])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Length of Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorlength(vector):\n",
    "    return np.linalg.norm(vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculated Angular Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_angular_error(deg_e_phi, deg_e_theta):\n",
    "    return np.degrees(np.arccos(np.cos(np.radians(deg_e_phi)) * np.cos(np.radians(deg_e_theta))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skalarprodukt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myDot(a, b):\n",
    "    dot = 0;\n",
    "    it = np.nditer(a, flags=['f_index'])\n",
    "    for x in it:\n",
    "        dot = dot + (x * b[it.index])\n",
    "        \n",
    "    return dot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dot Angular Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot_angular_error_elevation(predicted_deg_vector, true_deg_vector):    \n",
    "    c_predicted = spheric_cartesian_elevation(predicted_deg_vector[0], predicted_deg_vector[1])\n",
    "    c_true = spheric_cartesian_elevation(true_deg_vector[0], true_deg_vector[1])\n",
    "    \n",
    "    len_prediction = vectorlength(c_predicted)\n",
    "    len_true = vectorlength(c_true)\n",
    "    \n",
    "    cos_angle = np.dot(c_true, c_predicted) / len_prediction / len_true\n",
    "    \n",
    "    return abs(np.degrees(np.arccos(cos_angle)))\n",
    "\n",
    "def dot_angular_error_polar(predicted_deg_vector, true_deg_vector):\n",
    "    c_predicted = spheric_cartesian_polar(predicted_deg_vector[0], predicted_deg_vector[1])\n",
    "    c_true = spheric_cartesian_polar(true_deg_vector[0], true_deg_vector[1])\n",
    "    \n",
    "    len_prediction = vectorlength(c_predicted)\n",
    "    len_true = vectorlength(c_true)\n",
    "    \n",
    "    cos_angle = np.dot(c_true, c_predicted) / len_prediction / len_true\n",
    "    \n",
    "    return abs(np.degrees(np.arccos(cos_angle)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normierte sphärische Koordinaten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normierte $\\rightarrow$ Sphärische"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized_to_spheric(n_phi, n_theta):\n",
    "    phi = n_phi * 180 + 180\n",
    "    theta = n_theta * 45 + 45\n",
    "    \n",
    "    return phi, theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation <a name = \"setup\"></a>\n",
    "<p><a href = #Top>Up</a>\n",
    "<p><a href = #plots>Plots</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = 'SYNTH'\n",
    "loss = 'MSE'\n",
    "dataset_name = '2020-05-28'\n",
    "net_index = [99, 204, 195]\n",
    "APPENDIX = ['Angular', 'Normalized', 'Stereographic']\n",
    "_note = ['', '', '_Custom-MAE']\n",
    "\n",
    "eval_dir = '..\\\\output\\\\{}_Regression_{}\\\\Graphical_Evaluation\\\\'.format(run, loss)\n",
    "\n",
    "if(not os.path.exists(eval_dir)):\n",
    "    os.makedirs(eval_dir)\n",
    "else:\n",
    "    input('Directory >>| {} |<< existiert bereits. Fortsetzen auf eigene Gefahr! (Weiter mit Enter)'.format(eval_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "net_results = [None, None, None]\n",
    "\n",
    "for i in range(3):\n",
    "    with open(eval_dir + '{}_Net{}_{}{}_Results.pickle'.format(dataset_name, net_index[i], APPENDIX[i], _note[i]), \"rb\") as fp:   # Unpickling\n",
    "        net_results[i] = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    print(net_results[i])\n",
    "    print()\n",
    "    print()\n",
    "    print('---------------------------------------------------------------------')\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.text as text\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "from matplotlib import cm\n",
    "\n",
    "import tikzplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "Enable_Plotting = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots <a name = \"plots\">\n",
    "<p></a><a href = #Top>Up</a>\n",
    "<p><a href = #setup>Setup</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if Enable_Plotting:\n",
    "    #interesting_cases = [0, 3, 4, 5]\n",
    "    interesting_cases = [0, 5]\n",
    "    interesting_cases = [0, 5]\n",
    "    \n",
    "    net_len = len(net_results)\n",
    "    net_len = 3\n",
    "    \n",
    "    net_df = [[], [], []]\n",
    "    \n",
    "    for net_idx in range(net_len):\n",
    "        net = net_results[net_idx]\n",
    "        for run_idx in interesting_cases:\n",
    "            df = net[run_idx][1]\n",
    "            net_df[net_idx].append(df)\n",
    "            #print(df)\n",
    "    print(net_df[2][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(net_df[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Elevation-Dependent Angular Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_dependent_angular_error(dataframe, eval_path, eval_file, store_to_file = False):\n",
    "    model_depenent_angular_error =  pd.DataFrame(data=None, index=None, columns=['model', 'angular_error', 'number_images'])\n",
    "    \n",
    "    operation_df = dataframe\n",
    "    \n",
    "    dictionary = {}\n",
    "    \n",
    "    for index, row in operation_df.iterrows():\n",
    "        filename = row['Filename']\n",
    "        if 'bunny' in filename:\n",
    "            key = 'Bunny'\n",
    "        elif 'buddha' in filename:\n",
    "            key = 'Buddha'\n",
    "        elif 'box' in filename:\n",
    "            key = 'Box'\n",
    "        elif 'cone' in filename:\n",
    "            key = 'Cone'\n",
    "        elif 'sphere' in filename:\n",
    "            key = 'Sphere'\n",
    "        elif 'ball' in filename:\n",
    "            key = 'Sphere'\n",
    "        else:\n",
    "            print('No proper String: ', filename)\n",
    "            return\n",
    "        \n",
    "        if key not in dictionary.keys():\n",
    "            e = row['dot_angular_err_elevation']\n",
    "            a = 1\n",
    "            dictionary[key] = [e, a]\n",
    "            \n",
    "        else:\n",
    "            e = dictionary[key][0]\n",
    "            a = dictionary[key][1]\n",
    "            e = e + row['dot_angular_err_elevation']\n",
    "            a = a + 1\n",
    "            dictionary[key] = [e, a]\n",
    "            \n",
    "    for key, value in dictionary.items():\n",
    "        avg_error = value[0] / value[1]\n",
    "        model_depenent_angular_error = model_depenent_angular_error.append(pd.DataFrame(\n",
    "            data = [[key, avg_error, value[1]]], \n",
    "            index = None, \n",
    "            columns = ['model', 'angular_error', 'number_images']))\n",
    "\n",
    "    model_depenent_angular_error = model_depenent_angular_error.sort_values(by=['model'])\n",
    "\n",
    "    if(store_to_file):\n",
    "        model_depenent_angular_error.to_csv(eval_path + eval_file, index = False)\n",
    "    \n",
    "    return model_depenent_angular_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dependent_angular_error(net_df[0][0], eval_dir, 'model_angular_99_train-synth_test-synth.csv', store_to_file = True)\n",
    "model_dependent_angular_error(net_df[1][0], eval_dir, 'model_angular_204_train-synth_test-synth.csv', store_to_file = True)\n",
    "model_dependent_angular_error(net_df[2][0], eval_dir, 'model_angular_195_train-synth_test-synth.csv', store_to_file = True)\n",
    "\n",
    "model_dependent_angular_error(net_df[0][1], eval_dir, 'model_angular_99_train-mixed_test-real.csv', store_to_file = True)\n",
    "model_dependent_angular_error(net_df[1][1], eval_dir, 'model_angular_204_train-mixed_test-real.csv', store_to_file = True)\n",
    "model_dependent_angular_error(net_df[2][1], eval_dir, 'model_angular_195_train-mixed_test-real.csv', store_to_file = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_Plot(eval_file, save = True):\n",
    "    #fig, ax = plt.subplots(nrows = 1, ncols = 2, figsize = (30,10))\n",
    "    fig, ax = plt.subplots(figsize = (10,5))\n",
    "    \n",
    "    synt1 = model_dependent_angular_error(net_df[0][0], None, None) # Net 99 Tr syn Te syn\n",
    "    synt2 = model_dependent_angular_error(net_df[1][0], None, None) # Net 204 Tr syn Te syn\n",
    "    synt3 = model_dependent_angular_error(net_df[2][0], None, None) # Net 195 Tr syn Te syn\n",
    "    \n",
    "    real1 = model_dependent_angular_error(net_df[0][1], None, None) # Net 99 Tr syn Te syn\n",
    "    real2 = model_dependent_angular_error(net_df[1][1], None, None) # Net 204 Tr syn Te syn\n",
    "    real3 = model_dependent_angular_error(net_df[2][1], None, None) # Net 195 Tr syn Te syn\n",
    "\n",
    "    \n",
    "    synt_dfs = [synt1[['model', 'angular_error']], synt2['angular_error'], synt3['angular_error']]\n",
    "    real_dfs = [real1[['model', 'angular_error']], real2['angular_error'], real3['angular_error']]\n",
    "    \n",
    "    synt_plot = pd.concat(synt_dfs, join = 'outer', axis = 1)\n",
    "    synt_plot.reset_index(drop = True, inplace = True)\n",
    "    \n",
    "    real_plot = pd.concat(real_dfs, join = 'outer', axis = 1)\n",
    "    real_plot.reset_index(drop = True, inplace = True)\n",
    "    \n",
    "        \n",
    "    #synt_plot.plot(x = 'model', kind = 'bar', ax = ax)\n",
    "    real_plot.plot(x = 'model', kind = 'bar', ax = ax)\n",
    "\n",
    "\n",
    "    ax.grid(True, ls = '--', axis = 'y')\n",
    "    \n",
    "    ax.set_ylabel('Mean Angular Error')\n",
    "    #ax.set_title('Model-dependent angular error on synth. test data using synth. training data')\n",
    "    ax.set_title('Model-dependent angular error on real test data using mixed training data')\n",
    "    \n",
    "    ax.set_xlabel('Model')\n",
    "    \n",
    "    ax.legend(['Net_p,t', 'Net_|p,t|', 'Net_sx,sy'])\n",
    "    \n",
    "    for o in fig.findobj(text.Text):\n",
    "        o.set_fontstyle('italic')\n",
    "    \n",
    "    if(save):\n",
    "        tikzplotlib.save('{}.tex'.format(eval_file))\n",
    "        plt.savefig('{}.png'.format(eval_file), format = 'png', bbox_inches = \"tight\", dpi = 300)\n",
    "\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if Enable_Plotting:\n",
    "    tsts_plot = do_Plot(eval_dir + 'Model-Dep-Angular')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf_test]",
   "language": "python",
   "name": "conda-env-tf_test-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
