{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-traind CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errro: Not in virtual environment\n",
      "The installed version of TensorFlow 2.1.0 includes GPU support.\n",
      "\n",
      "Num GPUs Available:  1 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "if(sys.prefix != sys.base_prefix):\n",
    "    print('Current Conda Environment: {}'.format(os.environ['CONDA_DEFAULT_ENV']))\n",
    "else:\n",
    "    print('Errro: Not in virtual environment')\n",
    "    \n",
    "available_gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "built_with_cuda = tf.test.is_built_with_cuda()\n",
    "if not (not available_gpus) & built_with_cuda:\n",
    "    print(\"The installed version of TensorFlow {} includes GPU support.\\n\".format(tf.__version__))\n",
    "    print(\"Num GPUs Available: \", len(available_gpus), \"\\n\")\n",
    "else:\n",
    "    print(\"The installed version of TensorFlow {} does not include GPU support.\\n\".format(tf.__version__))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor Flow Version: 2.1.0\n",
      "numpy Version: 1.18.5\n"
     ]
    }
   ],
   "source": [
    "# import necessary package\n",
    "from tensorflow.compat.v1.keras import callbacks, backend as K\n",
    "from tensorflow.keras.optimizers import Adam, Nadam, RMSprop, SGD, Adagrad\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from tensorflow.keras.layers import ReLU, LeakyReLU\n",
    "from tensorflow.keras.initializers import glorot_uniform\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import pathlib\n",
    "import datetime\n",
    "\n",
    "# printout versions\n",
    "print(f\"Tensor Flow Version: {tf.__version__}\")\n",
    "print(f\"numpy Version: {np.version.version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enum für Training-Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class TrainingSet(Enum):\n",
    "    SYNTHETIC = 1\n",
    "    REAL = 2\n",
    "    MIXED = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Directory\n",
    "\n",
    "* <i>SSD</i>, falls genug Speicher auf SSD im SymLink <i>fast_output</i> verfügbar ist\n",
    "* <i>HDD</i>, falls möglicherweise zu wenig SSD-Speicher verfügbar ist $\\rightarrow$ <i>output</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import IntEnum\n",
    "\n",
    "class OutputDirectory(IntEnum):\n",
    "    HDD = 0\n",
    "    SSD = 1\n",
    "    \n",
    "output_path = ['output', 'fast_output']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Label_Type into suitable label names.\n",
    "$\\Rightarrow$ Angular / Normalized $\\rightarrow$ ['Elevation', 'Azimuth']\n",
    "\n",
    "$\\Rightarrow$ Stereographic $\\rightarrow$ ['S_x', 'S_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Label_Names(label_type):\n",
    "    if label_type == 'Angular' or label_type == 'Normalized' or label_type == 'Proto':\n",
    "        return ['Elevation', 'Azimuth']\n",
    "    elif label_type == 'Stereographic':\n",
    "        return ['S_x', 'S_y']\n",
    "    else:\n",
    "        assert(True, 'LabelType Invalid')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benutzerdefinierte Kostenfunktion & Metrik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def circular_mse(y_true, y_pred):\n",
    "    max_error = tf.constant(360, dtype = 'float32')\n",
    "    return K.mean(K.square(K.minimum(K.abs(y_pred - y_true), max_error - K.abs(y_pred - y_true))), axis = -1)\n",
    "\n",
    "def circular_mae(y_true, y_pred):\n",
    "    max_error = tf.constant(360, dtype = 'float32')\n",
    "    return K.mean(K.minimum(K.abs(y_pred - y_true), K.abs(max_error - K.abs(y_pred - y_true))), axis = -1)\n",
    "\n",
    "def custom_mae(y_true, y_pred):\n",
    "    return K.mean(K.abs(y_pred - y_true), axis = -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert String into Reduction Metric Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Reduction_Metric(metric):\n",
    "    \n",
    "    if metric == 'custom_mae':\n",
    "        return [custom_mae]\n",
    "    elif metric == 'tf.keras.metrics.MeanAbsoluteError()':\n",
    "        return [tf.keras.metrics.MeanAbsoluteError()]\n",
    "    elif metric == 'circular_mae':\n",
    "        return [circular_mae]\n",
    "    elif metric == 'mean_squared_error':\n",
    "        return ['mean_squared_error']\n",
    "    else:\n",
    "        assert(False, 'Metric yet unknown - Please modify get_Reduction_Metric to meet your requirements')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainingsset-Typ nach String Converter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainingset_to_string(ts):\n",
    "    if ts == TrainingSet.SYNTHETIC:\n",
    "        return 'Synth'\n",
    "    elif ts == TrainingSet.REAL:\n",
    "        return 'Real'\n",
    "    elif ts == TrainingSet.MIXED:\n",
    "        return 'Mixed'\n",
    "    else:\n",
    "        print('Unknown TrainingSet')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AlexNet with batch normalization in Keras \n",
    "def alexnet(activation='relu', input_shape=(224,224,3)):\n",
    "    #model = Sequential()\n",
    "    #model.add(Conv2D(96, (11, 11), stride=(4, 4), padding='valid', input_shape=input_shape))\n",
    "    #model.add(BatchNormalization())\n",
    "    #model.add(Activation(activation))\n",
    "    #model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "#\n",
    "    #model.add(Conv2D(256, (5, 5), padding='valid'))\n",
    "    #model.add(BatchNormalization())\n",
    "    #model.add(Activation(activation))\n",
    "    #model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "#\n",
    "    #model.add(Conv2D(384, (3, 3), padding='valid'))\n",
    "    ##model.add(BatchNormalization())\n",
    "    ##model.add(Activation(activation))\n",
    "    ##model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "#\n",
    "    #model.add(Conv2D(384, (3, 3), padding='valid'))\n",
    "    ##model.add(BatchNormalization())\n",
    "    ##model.add(Activation(activation))\n",
    "    ##model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "#\n",
    "    #model.add(Conv2D(256, (3, 3), padding='valid'))\n",
    "    ##model.add(BatchNormalization())\n",
    "    ##model.add(Activation(activation))\n",
    "    ##model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "    #\n",
    "    ##model.add(Flatten())\n",
    "    ##model.add(Dense(4096))\n",
    "    ##model.add(BatchNormalization())\n",
    "    ##model.add(Activation(activation))\n",
    "    ##model.add(Dense(4096))\n",
    "    ##model.add(BatchNormalization())\n",
    "    ##model.add(Activation(activation))\n",
    "    ##model.add(Dense(1000))\n",
    "    ##model.add(BatchNormalization())\n",
    "    ##model.add(Activation('softmax'))\n",
    "    \n",
    "    model = Sequential([\n",
    "    Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=input_shape)),\n",
    "    BatchNormalization(),\n",
    "    MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "    Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    BatchNormalization(),\n",
    "    MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "    Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(filters=384, kernel_size=(1,1), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(filters=256, kernel_size=(1,1), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    BatchNormalization(),\n",
    "    MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "    Flatten(),\n",
    "    Dense(4096, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(4096, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(units = 2, activation='relu')\n",
    "    \n",
    "    #keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alexnetK2(activation='relu', input_shape=(224,224,3)):\n",
    "    image_input = Input(input_shape)\n",
    "    vector_input = Input((12,))\n",
    "    \n",
    "    image_model = Conv2D(32,(8,8), strides=(4,4))(image_input)\n",
    "    image_model = Activation(activation)(image_model)\n",
    "    image_model = Conv2D(64,(4,4), strides=(2,2))(image_model)\n",
    "    image_model = Activation(activation)(image_model)\n",
    "    image_model = Conv2D(64,(3,3), strides=(1,1))(image_model)\n",
    "    image_model = Activation(activation)(image_model)\n",
    "    image_model = Flatten()(image_model)\n",
    "    image_model = Dense(512)(image_model)\n",
    "    image_model = Activation(activation)(image_model)\n",
    "\n",
    "    value_model = Dense(16)(vector_input)\n",
    "    value_model = Activation(activation)(value_model)\n",
    "    value_model = Dense(16)(value_model)\n",
    "    value_model = Activation(activation)(value_model)\n",
    "    value_model = Dense(16)(value_model)\n",
    "    value_model = Activation(activation)(value_model)\n",
    "\n",
    "    merged = concatenate([image_model, value_model])\n",
    "\n",
    "    output = Dense(1, activation='sigmoid')(merged)\n",
    "\n",
    "    model = Model(inputs=[image_input, vector_input], outputs=output)\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg16():\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Block 1\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same')(img_input))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same')(x))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x))\n",
    "\n",
    "    # Block 2\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same')(x))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same')(x))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x))\n",
    "\n",
    "    # Block 3\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same')(x))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same')(x))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same')(x))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x))\n",
    "             \n",
    "    # Block 4\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same')(x))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same')(x))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same')(x))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x))\n",
    "             \n",
    "    #Block 5\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same')(x))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same')(x))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same')(x))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg6():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), strides = 1, padding = \"same\", activation = \"relu\", input_shape = (32, 32, 3)))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Conv2D(32, (3, 3), strides = 1, padding = \"same\", activation = \"relu\"))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(64, (3, 3), strides = 1, padding = \"same\", activation = \"relu\"))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Conv2D(64, (3, 3), strides = 1, padding = \"same\", activation = \"relu\"))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(128, (3, 3), strides = 1, padding = \"same\", activation = \"relu\"))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Conv2D(128, (3, 3), strides = 1, padding = \"same\", activation = \"relu\"))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingset = TrainingSet.SYNTHETIC\n",
    "_USE_DATA_AUGMENTATION = True\n",
    "\n",
    "_BATCH_SIZE = 32 #64\n",
    "_IMG_HEIGHT = 224\n",
    "_SAMPLES = 64\n",
    "_EPOCHS = 1\n",
    "_OPTIMIZER = Adam\n",
    "_LR = 1 #2, 5\n",
    "_FIRST_NEURON = 1024 #2048, 4096\n",
    "_DROP_OUT = 0.25 # 0.5\n",
    "_ACTIVATION = 'relu' # leakyrelu\n",
    "_HIDDEN_LAYERS = 0 #1, 2, 3, 4\n",
    "\n",
    "_RUN = 'SYNTH'\n",
    "_LOSS = 'mean_squared_error'\n",
    "_DATASET_NAME = '201019_2253_final'\n",
    "_DEVICE = 'GeForce_RTX_2070'\n",
    "storage = OutputDirectory.SSD\n",
    "\n",
    "_REDUCTION_METRIC = 'custom_mae'\n",
    "_MONITOR_VALUE = 'val_custom_mae'\n",
    "_LABLE_TYPE = 'Proto' # Stereographic, Angular, Normalized\n",
    "_DEVICE = 'RTX_2070_GPU0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#storage = OutputDirectory.SSD # 'fast_output' if ssd storage may suffice, 'output' otherwise\n",
    "\n",
    "#APPENDIX = 'Stereographic'\n",
    "\n",
    "#FUNCTION_OVERRIDE = ['mean_squared_error', [custom_mae], 'val_custom_mae'] # None, or e. g. ['mean_squared_error', [circular_mae], 'val_circular_mae']\n",
    "\n",
    "if _LABLE_TYPE == 'Stereographic':\n",
    "    _CSV_FILE_NAME = 'images_synthetisch_stereographic.csv'\n",
    "    _IMAGE_TYPE_NAME = ''\n",
    "    _COLOR_MODE = 'rgb'\n",
    "    _COLOR_CHANNELS = 3\n",
    "    _STEREOGRAPHIC = True\n",
    "elif _LABLE_TYPE == 'Angular':\n",
    "    _CSV_FILE_NAME = 'labels_ks_rgb.csv'\n",
    "    _IMAGE_TYPE_NAME = 'rgb'\n",
    "    _COLOR_MODE = 'rgb'\n",
    "    _COLOR_CHANNELS = 3\n",
    "    _STEREOGRAPHIC = False\n",
    "elif _LABLE_TYPE == 'Angular_RGBD':\n",
    "    _CSV_FILE_NAME = 'labels_ks_rgbd.csv'\n",
    "    _IMAGE_TYPE_NAME = 'rgbd'\n",
    "    _COLOR_MODE = 'rgba'\n",
    "    _COLOR_CHANNELS = 4\n",
    "    _STEREOGRAPHIC = False\n",
    "elif _LABLE_TYPE == 'Proto':\n",
    "    _CSV_FILE_NAME = 'lables_ks_proto.csv'\n",
    "    _IMAGE_TYPE_NAME = 'rgb_proto'\n",
    "    _COLOR_MODE = 'rgb'\n",
    "    _COLOR_CHANNELS = 3\n",
    "    _STEREOGRAPHIC = False\n",
    "elif _LABLE_TYPE == 'Normalized':\n",
    "    _CSV_FILE_NAME = 'images_synthetisch_normalized.csv'\n",
    "    _IMAGE_TYPE_NAME = ''\n",
    "    _COLOR_MODE = 'rgb'\n",
    "    _COLOR_CHANNELS = 3\n",
    "    _STEREOGRAPHIC = False\n",
    "else:\n",
    "    assert(True, 'LabelType Invalid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data_generation/dataset/201019_2253_final/rgb_proto/lables_ks_proto.csv\n",
      "Directory >>| ..\\fast_output\\SYNTH_Regression_mean_squared_error\\201019_2253_final_Proto_Top_1_Custom-MAE\\Synth_TD\\ |<< existiert bereits. Fortsetzen auf eigene Gefahr! (Weiter mit Enter)\n"
     ]
    }
   ],
   "source": [
    "_IMAGE_DIR = '../../data_generation/dataset/{}/{}/'.format(_DATASET_NAME, _IMAGE_TYPE_NAME)\n",
    "#_IMAGE_DIR = '../../data_generation/'\n",
    "_CSV_FILE = _IMAGE_DIR + _CSV_FILE_NAME\n",
    "print(_CSV_FILE)\n",
    "data_dir = pathlib.Path(_IMAGE_DIR)\n",
    "_IMAGE_COUNT = len(list(data_dir.glob('*.png')))\n",
    "_STEPS_PER_EPOCH = np.ceil(_IMAGE_COUNT/_BATCH_SIZE)\n",
    "\n",
    "_note = '_Custom-MAE'\n",
    "\n",
    "_MODEL_DIR = '..\\\\output\\\\{}_Regression_{}\\\\{}_{}_Base{}\\\\'.format(_RUN, _LOSS, _DATASET_NAME, _LABLE_TYPE, _note)\n",
    "_NET_DIR = '{}_Regression_{}\\\\{}_{}_Top_1{}\\\\{}_TD\\\\'.format(_RUN, _LOSS, _DATASET_NAME, _LABLE_TYPE, _note, trainingset_to_string(trainingset))\n",
    "_LOG_DIR = '..\\\\{}\\\\{}'.format(output_path[storage], _NET_DIR)\n",
    "\n",
    "if(not os.path.exists(_LOG_DIR)):\n",
    "    os.makedirs(_LOG_DIR)\n",
    "else:\n",
    "    input('Directory >>| {} |<< existiert bereits. Fortsetzen auf eigene Gefahr! (Weiter mit Enter)'.format(_LOG_DIR))\n",
    "\n",
    "device_file = open(_LOG_DIR + '{}.txt'.format(_DEVICE), \"a+\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test to see if csv and images can be found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102\n",
      "../../data_generation/dataset/201019_2253_final/rgb_proto/lables_ks_proto.csv\n",
      "                  Filename  Azimuth  Elevation\n",
      "0   1-bunny-0-1-290-35.png      290         35\n",
      "1  2-bunny-0-30-290-35.png      290         35\n",
      "2  3-bunny-0-60-290-35.png      290         35\n",
      "3  4-bunny-0-90-290-35.png      290         35\n",
      "4  5-bunny-45-1-290-35.png      290         35\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(_IMAGE_COUNT)\n",
    "\n",
    "from IPython.display import Image\n",
    "print(_CSV_FILE)\n",
    "df2 = pd.read_csv(_CSV_FILE)\n",
    "print(df2.head(5))\n",
    "_IMAGE_NAME = df2.iloc[0]['Filename']\n",
    "#Image( \"../../data_generation/dataset/201019_2253_final/rgb_proto/1-bunny-0-1-290-35.png\")\n",
    "Image(_IMAGE_DIR + _IMAGE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generierung Datenpipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data():\n",
    "    # if Block für synthetische Daten, um nur auf realen Daten zu trainieren _USE_SYNTHETIC_TRAIN_DATA\n",
    "    # 1. lege df_train und df_valid als leere Liste an\n",
    "    # 2. If-block um Zeile df = ... bis df_valid\n",
    "    \n",
    "    if trainingset == TrainingSet.SYNTHETIC:\n",
    "        df = pd.read_csv(_CSV_FILE)\n",
    "        df_shuffled = df.sample(frac = 1, random_state = 1)\n",
    "        df_train = df_shuffled[0 : int(_SAMPLES * 0.8)]\n",
    "        df_valid = df_shuffled.drop(df_shuffled.index[0 : df_train.shape[0]])[0 : int(_SAMPLES * 0.2)]\n",
    "        \n",
    "    elif trainingset == TrainingSet.MIXED:\n",
    "        df = pd.read_csv(_CSV_FILE)\n",
    "        df_shuffled = df.sample(frac = 1, random_state = 1)\n",
    "        df_train = df_shuffled[0 : int(_SAMPLES * 0.8 // _BATCH_SIZE * _BATCH_SIZE)]\n",
    "        df_valid = df_shuffled.drop(df_shuffled.index[0 : df_train.shape[0]])[0 : int(_SAMPLES * 0.2 // _BATCH_SIZE * _BATCH_SIZE)]\n",
    "        \n",
    "        df_real = pd.read_csv(_CSV_FILE_REAL)\n",
    "        df_shuffled_real = df_real.sample(frac = 1, random_state = 1)\n",
    "        df_shuffled_real = df_shuffled_real.drop(df_shuffled_real.index[(df_shuffled_real.shape[0] - 61) : df_shuffled_real.shape[0]])\n",
    "        df_train_real = df_shuffled_real[0: int(df_shuffled_real.shape[0] * 0.8 // _BATCH_SIZE * _BATCH_SIZE)]   \n",
    "        df_valid_real = df_shuffled_real.drop(df_shuffled_real.index[0 : df_train_real.shape[0]])\n",
    "        df_train = df_train.drop(df_train.index[df_train.shape[0] - df_train_real.shape[0] : df_train.shape[0]])\n",
    "        df_valid = df_valid.drop(df_valid.index[df_valid.shape[0] - df_valid_real.shape[0] : df_valid.shape[0]])\n",
    "        df_train = df_train.append(df_train_real)\n",
    "        df_valid= df_valid.append(df_valid_real)\n",
    "    \n",
    "    elif trainingset == TrainingSet.REAL: # Add check for _SAMPLES, once the real dataset increases\n",
    "        df_real = pd.read_csv(_CSV_FILE_REAL)\n",
    "        df_shuffled_real = df_real.sample(frac = 1, random_state = 1)\n",
    "        df_shuffled_real = df_shuffled_real.drop(df_shuffled_real.index[(df_shuffled_real.shape[0] - 61) : df_shuffled_real.shape[0]])\n",
    "        df_train = df_shuffled_real[0 : int(df_shuffled_real.shape[0] * 0.8 // _BATCH_SIZE * _BATCH_SIZE)]   \n",
    "        df_valid = df_shuffled_real.drop(df_shuffled_real.index[0 : df_train.shape[0]])\n",
    "        \n",
    "    else:\n",
    "        print('Create_Data :: should not have reached here')\n",
    "       \n",
    "\n",
    "    if _USE_DATA_AUGMENTATION:\n",
    "        train_data_generator = ImageDataGenerator(\n",
    "            rescale = 1./255, \n",
    "            width_shift_range = 0.1,\n",
    "            height_shift_range = 0.1, \n",
    "            zoom_range = 0.1,\n",
    "            brightness_range = (0.25, 0.75),\n",
    "            fill_mode = 'nearest'\n",
    "        )\n",
    "    else:\n",
    "        train_data_generator = ImageDataGenerator(\n",
    "            rescale = 1./255\n",
    "        )\n",
    "    \n",
    "    print('Y-Col: {}'.format(get_Label_Names(_LABLE_TYPE)))\n",
    "    print('Train Data Generator: ', end = '')\n",
    "\n",
    "    train_generator = train_data_generator.flow_from_dataframe(\n",
    "        dataframe = df_train,\n",
    "        directory = _IMAGE_DIR,\n",
    "        x_col = 'Filename',\n",
    "        y_col = get_Label_Names(_LABLE_TYPE),\n",
    "        class_mode = 'raw',\n",
    "        target_size = (_IMG_HEIGHT, _IMG_HEIGHT),\n",
    "        color_mode = _COLOR_MODE,\n",
    "        shuffle = True,\n",
    "        seed = 1,\n",
    "        batch_size = _BATCH_SIZE\n",
    "    )\n",
    "                \n",
    "    valid_data_generator = ImageDataGenerator(\n",
    "        rescale = 1./255\n",
    "    )\n",
    "    print('Validation Data Generator: ', end = '')\n",
    "\n",
    "    valid_generator = valid_data_generator.flow_from_dataframe(\n",
    "        dataframe = df_valid,\n",
    "        directory = _IMAGE_DIR,\n",
    "        x_col = 'Filename',\n",
    "        y_col = get_Label_Names(_LABLE_TYPE),\n",
    "        class_mode = 'raw',\n",
    "        target_size = (_IMG_HEIGHT,_IMG_HEIGHT),\n",
    "        color_mode = _COLOR_MODE,\n",
    "        shuffle = False,\n",
    "        seed = 1,\n",
    "        batch_size = _BATCH_SIZE\n",
    "    )\n",
    "                                                        \n",
    "    return train_generator, valid_generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generierung Modell "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_run():#x, y, x_val, y_val):\n",
    "    K.clear_session()\n",
    "    \n",
    "    train_generator, valid_generator = create_data()\n",
    "    tg_steps_per_epoch = train_generator.n // train_generator.batch_size\n",
    "    vg_validation_steps = valid_generator.n // valid_generator.batch_size\n",
    "    print('Steps per Epoch: {}, Validation Steps: {}'.format(tg_steps_per_epoch, vg_validation_steps))\n",
    "    \n",
    "    dropout_rate = _DROP_OUT\n",
    "    first_neuron = _FIRST_NEURON\n",
    "    \n",
    "    if _ACTIVATION == 'leakyrelu':\n",
    "        activation_layer = LeakyReLU(alpha = params['leaky_alpha'])\n",
    "    elif _ACTIVATION == 'relu':\n",
    "        activation_layer = ReLU()\n",
    "    \n",
    "    model = Sequential()\n",
    "    cnn = alexnet(input_shape=(_IMG_HEIGHT,_IMG_HEIGHT,_COLOR_CHANNELS))\n",
    "      \n",
    "    print('_________________________________________________________________')\n",
    "    print('{:>16} {:>16}'.format('Network Layer', 'Trainable'))\n",
    "    print('=================================================================')\n",
    "    for layer in cnn.layers:\n",
    "        print('{:>16} {:>16}'.format(layer.name, layer.trainable))\n",
    "    print('_________________________________________________________________\\n')\n",
    "    \n",
    "    model.add(cnn)\n",
    "    \n",
    "    #fc = Sequential()\n",
    "    #fc.add(Flatten(input_shape = model.output_shape[1:])) # (7, 7, 512)\n",
    "    #\n",
    "    #fc.add(Dense(units = first_neuron, kernel_initializer = glorot_uniform(seed = 1)))\n",
    "    #fc.add(activation_layer)\n",
    "    #if dropout_rate > 0.0:\n",
    "    #    fc.add(Dropout(rate = dropout_rate))\n",
    "    #\n",
    "    #print('Number Hidden Layers {}'.format(_HIDDEN_LAYERS))\n",
    "    #hidden_neuron_fraction = first_neuron\n",
    "    #for i in range(_HIDDEN_LAYERS):\n",
    "    #    hidden_neuron_fraction = hidden_neuron_fraction // 2\n",
    "    #    fc.add(Dense(units = hidden_neuron_fraction, kernel_initializer = glorot_uniform(seed = 1)))\n",
    "    #    fc.add(activation_layer)\n",
    "    #    if dropout_rate > 0.0:\n",
    "    #        fc.add(Dropout(rate = dropout_rate))\n",
    "    #\n",
    "    #fc.add(Dense(units = 2, kernel_initializer = glorot_uniform(seed = 1)))\n",
    "    #model.add(fc)\n",
    "    \n",
    "    print('Fully Connected Layers added to Base Network')\n",
    "    \n",
    "    print('Using Loss: {} \\nand Reduction Metric: {}'.format(\n",
    "        _LOSS, \n",
    "        get_Reduction_Metric(_REDUCTION_METRIC)))\n",
    "    \n",
    "    model.compile(\n",
    "        #optimizer=params['optimizer'](lr=lr_normalizer(params['lr'], params['optimizer'])*1e-2),\n",
    "        optimizer = _OPTIMIZER(lr = lr_normalizer(_LR, _OPTIMIZER) * 1e-3),\n",
    "        loss = _LOSS,\n",
    "        metrics = get_Reduction_Metric(_REDUCTION_METRIC)\n",
    "    )\n",
    "    print('Model was compiled')\n",
    "    print(model.summary())\n",
    "    print('_________________________________________________________________')\n",
    "    \n",
    "    checkpointer = callbacks.ModelCheckpoint(\n",
    "        #filepath = _LOG_DIR + 'CNN_Base_{}_Model_and_Weights_{}.hdf5'.format(_MODEL_TO_LOAD_INDEX, train_generator.n),\n",
    "        filepath = _LOG_DIR + 'CNN_Base_Model_and_Weights_AlexNet.hdf5',\n",
    "        monitor =  _MONITOR_VALUE,\n",
    "        verbose = 1,\n",
    "        save_weights_only = False,\n",
    "        save_best_only = True,\n",
    "        mode = 'min'\n",
    "    )\n",
    "    print('Checkpointer was created')\n",
    "    \n",
    "    csv_logger = callbacks.CSVLogger(\n",
    "        #filename = _LOG_DIR + 'CNN_Base_{}_Logger_{}.csv'.format(_MODEL_TO_LOAD_INDEX, train_generator.n),\n",
    "        filename = _LOG_DIR + 'CNN_Base_Logger_AlexNet.csv',\n",
    "        separator = ',',\n",
    "        append = False\n",
    "    )\n",
    "    print('CSV Logger was created')\n",
    "\n",
    "    lr_reducer = callbacks.ReduceLROnPlateau(\n",
    "        monitor = 'val_loss',\n",
    "        factor = 0.1,\n",
    "        patience = 13,\n",
    "        verbose = 1,\n",
    "        mode = 'min',\n",
    "        min_delta = 0.0001\n",
    "    )\n",
    "    print('Learning Rate Reducer was created')\n",
    "    \n",
    "    early_stopper = callbacks.EarlyStopping(\n",
    "        monitor = 'val_loss',\n",
    "        min_delta = 0,\n",
    "        #patience = 15,\n",
    "        patience = 20,\n",
    "        verbose = 1,\n",
    "        mode = 'min',\n",
    "        restore_best_weights = True\n",
    "    )\n",
    "    print('Early Stopper was created')\n",
    "    \n",
    "    out = model.fit(\n",
    "        x = train_generator,\n",
    "        steps_per_epoch = tg_steps_per_epoch,\n",
    "        validation_data = valid_generator,\n",
    "        validation_steps = vg_validation_steps,\n",
    "        callbacks = [checkpointer, csv_logger, lr_reducer, early_stopper],\n",
    "        epochs = _EPOCHS,\n",
    "        workers = 8\n",
    "    )\n",
    "    \n",
    "    return out, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y-Col: ['Elevation', 'Azimuth']\n",
      "Train Data Generator: Found 51 validated image filenames.\n",
      "Validation Data Generator: Found 12 validated image filenames.\n",
      "Steps per Epoch: 1, Validation Steps: 0\n",
      "_________________________________________________________________\n",
      "   Network Layer        Trainable\n",
      "=================================================================\n",
      "        conv2d_1                1\n",
      "batch_normalization_1                1\n",
      "    activation_1                1\n",
      " max_pooling2d_1                1\n",
      "        conv2d_2                1\n",
      "batch_normalization_2                1\n",
      "    activation_2                1\n",
      " max_pooling2d_2                1\n",
      "        conv2d_3                1\n",
      "batch_normalization_3                1\n",
      "    activation_3                1\n",
      " max_pooling2d_3                1\n",
      "        conv2d_4                1\n",
      "batch_normalization_4                1\n",
      "    activation_4                1\n",
      " max_pooling2d_4                1\n",
      "_________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Tensor-typed variable initializers must either be wrapped in an init_scope or callable (e.g., `tf.Variable(lambda : tf.truncated_normal([10, 40]))`) when building functions. Please file a feature request if this restriction inconveniences you.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-71-a3298b360be3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'AlexNet_Model/'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-70-9f4a9612984e>\u001b[0m in \u001b[0;36mmodel_run\u001b[1;34m()\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[0mfc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_initializer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mglorot_uniform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Fully Connected Layers added to Base Network'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_test\\lib\\site-packages\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36madd\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m    180\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_source_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m             \u001b[0moutput_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m                 raise TypeError('All layers in a Sequential model '\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_test\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36msymbolic_fn_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_SYMBOLIC_SCOPE\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mget_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_test\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[0;32m    461\u001b[0m                                          \u001b[1;34m'You can build it manually via: '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    462\u001b[0m                                          '`layer.build(batch_input_shape)`')\n\u001b[1;32m--> 463\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munpack_singleton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    464\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    465\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_test\\lib\\site-packages\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36mbuild\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m    220\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m                 \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    223\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_build_input_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_test\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36msymbolic_fn_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_SYMBOLIC_SCOPE\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mget_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_test\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[0;32m    461\u001b[0m                                          \u001b[1;34m'You can build it manually via: '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    462\u001b[0m                                          '`layer.build(batch_input_shape)`')\n\u001b[1;32m--> 463\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munpack_singleton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    464\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    465\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_test\\lib\\site-packages\\keras\\layers\\core.py\u001b[0m in \u001b[0;36mbuild\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m    893\u001b[0m                                       \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'kernel'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m                                       \u001b[0mregularizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel_regularizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m                                       constraint=self.kernel_constraint)\n\u001b[0m\u001b[0;32m    896\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m             self.bias = self.add_weight(shape=(self.units,),\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_test\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36madd_weight\u001b[1;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint)\u001b[0m\n\u001b[0;32m    280\u001b[0m                             \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    281\u001b[0m                             \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 282\u001b[1;33m                             constraint=constraint)\n\u001b[0m\u001b[0;32m    283\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mregularizer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    284\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'weight_regularizer'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_test\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mvariable\u001b[1;34m(value, dtype, name, constraint)\u001b[0m\n\u001b[0;32m    618\u001b[0m     \"\"\"\n\u001b[0;32m    619\u001b[0m     v = tf_keras_backend.variable(\n\u001b[1;32m--> 620\u001b[1;33m         value, dtype=dtype, name=name, constraint=constraint)\n\u001b[0m\u001b[0;32m    621\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'tocoo'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    622\u001b[0m         \u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_keras_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtocoo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_test\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36mvariable\u001b[1;34m(value, dtype, name, constraint)\u001b[0m\n\u001b[0;32m    812\u001b[0m       \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtypes_module\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m       \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 814\u001b[1;33m       constraint=constraint)\n\u001b[0m\u001b[0;32m    815\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    816\u001b[0m     \u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_keras_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_test\\lib\\site-packages\\tensorflow_core\\python\\ops\\variables.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    258\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variable_v1_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 260\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    261\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mVariableMetaclass\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_test\\lib\\site-packages\\tensorflow_core\\python\\ops\\variables.py\u001b[0m in \u001b[0;36m_variable_v2_call\u001b[1;34m(cls, initial_value, trainable, validate_shape, caching_device, name, variable_def, dtype, import_scope, constraint, synchronization, aggregation, shape)\u001b[0m\n\u001b[0;32m    252\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m         \u001b[0maggregation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 254\u001b[1;33m         shape=shape)\n\u001b[0m\u001b[0;32m    255\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_test\\lib\\site-packages\\tensorflow_core\\python\\ops\\variables.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(**kws)\u001b[0m\n\u001b[0;32m    233\u001b[0m                         shape=None):\n\u001b[0;32m    234\u001b[0m     \u001b[1;34m\"\"\"Call on Variable class. Useful to force the signature.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 235\u001b[1;33m     \u001b[0mprevious_getter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkws\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdefault_variable_creator_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkws\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    236\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgetter\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variable_creator_stack\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m       \u001b[0mprevious_getter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_make_getter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgetter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprevious_getter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_test\\lib\\site-packages\\tensorflow_core\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mdefault_variable_creator_v2\u001b[1;34m(next_creator, **kwargs)\u001b[0m\n\u001b[0;32m   2643\u001b[0m       \u001b[0msynchronization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2644\u001b[0m       \u001b[0maggregation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2645\u001b[1;33m       shape=shape)\n\u001b[0m\u001b[0;32m   2646\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2647\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_test\\lib\\site-packages\\tensorflow_core\\python\\ops\\variables.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    260\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mVariableMetaclass\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_test\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, variable_def, import_scope, constraint, distribute_strategy, synchronization, aggregation, shape)\u001b[0m\n\u001b[0;32m   1409\u001b[0m           \u001b[0maggregation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1410\u001b[0m           \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1411\u001b[1;33m           distribute_strategy=distribute_strategy)\n\u001b[0m\u001b[0;32m   1412\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1413\u001b[0m   def _init_from_args(self,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_test\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36m_init_from_args\u001b[1;34m(self, initial_value, trainable, collections, caching_device, name, dtype, constraint, synchronization, aggregation, distribute_strategy, shape)\u001b[0m\n\u001b[0;32m   1492\u001b[0m     if isinstance(initial_value, ops.Tensor) and hasattr(\n\u001b[0;32m   1493\u001b[0m         initial_value, \"graph\") and initial_value.graph.building_function:\n\u001b[1;32m-> 1494\u001b[1;33m       raise ValueError(\"Tensor-typed variable initializers must either be \"\n\u001b[0m\u001b[0;32m   1495\u001b[0m                        \u001b[1;34m\"wrapped in an init_scope or callable \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1496\u001b[0m                        \u001b[1;34m\"(e.g., `tf.Variable(lambda : \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Tensor-typed variable initializers must either be wrapped in an init_scope or callable (e.g., `tf.Variable(lambda : tf.truncated_normal([10, 40]))`) when building functions. Please file a feature request if this restriction inconveniences you."
     ]
    }
   ],
   "source": [
    "out, model = model_run()\n",
    "\n",
    "out.save('AlexNet_Model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
