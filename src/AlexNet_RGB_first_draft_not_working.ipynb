{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-traind CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errro: Not in virtual environment\n",
      "The installed version of TensorFlow 2.1.0 includes GPU support.\n",
      "\n",
      "Num GPUs Available:  1 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "if(sys.prefix != sys.base_prefix):\n",
    "    print('Current Conda Environment: {}'.format(os.environ['CONDA_DEFAULT_ENV']))\n",
    "else:\n",
    "    print('Errro: Not in virtual environment')\n",
    "    \n",
    "available_gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "built_with_cuda = tf.test.is_built_with_cuda()\n",
    "if not (not available_gpus) & built_with_cuda:\n",
    "    print(\"The installed version of TensorFlow {} includes GPU support.\\n\".format(tf.__version__))\n",
    "    print(\"Num GPUs Available: \", len(available_gpus), \"\\n\")\n",
    "else:\n",
    "    print(\"The installed version of TensorFlow {} does not include GPU support.\\n\".format(tf.__version__))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor Flow Version: 2.1.0\n",
      "numpy Version: 1.18.5\n",
      "Keras: 2.3.0\n"
     ]
    }
   ],
   "source": [
    "# import necessary package\n",
    "from tensorflow.compat.v1.keras import callbacks, backend as K\n",
    "from tensorflow.keras.optimizers import Adam, Nadam, RMSprop, SGD, Adagrad\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from tensorflow.keras.layers import ReLU, LeakyReLU\n",
    "from tensorflow.keras.initializers import glorot_uniform\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import pathlib\n",
    "import datetime\n",
    "import keras\n",
    "\n",
    "# printout versions\n",
    "print(f\"Tensor Flow Version: {tf.__version__}\")\n",
    "print(f\"numpy Version: {np.version.version}\")\n",
    "print(f\"Keras: {keras.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enum für Training-Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class TrainingSet(Enum):\n",
    "    SYNTHETIC = 1\n",
    "    REAL = 2\n",
    "    MIXED = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Directory\n",
    "\n",
    "* <i>SSD</i>, falls genug Speicher auf SSD im SymLink <i>fast_output</i> verfügbar ist\n",
    "* <i>HDD</i>, falls möglicherweise zu wenig SSD-Speicher verfügbar ist $\\rightarrow$ <i>output</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import IntEnum\n",
    "\n",
    "class OutputDirectory(IntEnum):\n",
    "    HDD = 0\n",
    "    SSD = 1\n",
    "    \n",
    "output_path = ['output', 'fast_output']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Label_Type into suitable label names.\n",
    "$\\Rightarrow$ Angular / Normalized $\\rightarrow$ ['Elevation', 'Azimuth']\n",
    "\n",
    "$\\Rightarrow$ Stereographic $\\rightarrow$ ['S_x', 'S_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Label_Names(label_type):\n",
    "    if label_type == 'Angular' or label_type == 'Normalized' or label_type == 'Proto':\n",
    "        return ['Elevation', 'Azimuth']\n",
    "    elif label_type == 'Stereographic':\n",
    "        return ['S_x', 'S_y']\n",
    "    else:\n",
    "        assert(True, 'LabelType Invalid')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benutzerdefinierte Kostenfunktion & Metrik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def circular_mse(y_true, y_pred):\n",
    "    max_error = tf.constant(360, dtype = 'float32')\n",
    "    return K.mean(K.square(K.minimum(K.abs(y_pred - y_true), max_error - K.abs(y_pred - y_true))), axis = -1)\n",
    "\n",
    "def circular_mae(y_true, y_pred):\n",
    "    max_error = tf.constant(360, dtype = 'float32')\n",
    "    return K.mean(K.minimum(K.abs(y_pred - y_true), K.abs(max_error - K.abs(y_pred - y_true))), axis = -1)\n",
    "\n",
    "def custom_mae(y_true, y_pred):\n",
    "    return K.mean(K.abs(y_pred - y_true), axis = -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert String into Reduction Metric Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Reduction_Metric(metric):\n",
    "    \n",
    "    if metric == 'custom_mae':\n",
    "        return [custom_mae]\n",
    "    elif metric == 'tf.keras.metrics.MeanAbsoluteError()':\n",
    "        return [tf.keras.metrics.MeanAbsoluteError()]\n",
    "    elif metric == 'circular_mae':\n",
    "        return [circular_mae]\n",
    "    elif metric == 'mean_squared_error':\n",
    "        return ['mean_squared_error']\n",
    "    else:\n",
    "        assert(False, 'Metric yet unknown - Please modify get_Reduction_Metric to meet your requirements')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainingsset-Typ nach String Converter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainingset_to_string(ts):\n",
    "    if ts == TrainingSet.SYNTHETIC:\n",
    "        return 'Synth'\n",
    "    elif ts == TrainingSet.REAL:\n",
    "        return 'Real'\n",
    "    elif ts == TrainingSet.MIXED:\n",
    "        return 'Mixed'\n",
    "    else:\n",
    "        print('Unknown TrainingSet')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AlexNet with batch normalization in Keras \n",
    "def alexnet(activation='relu', input_shape=(224,224,3)):\n",
    "    #model = Sequential()\n",
    "    #model.add(Conv2D(96, (11, 11), stride=(4, 4), padding='valid', input_shape=input_shape))\n",
    "    #model.add(BatchNormalization())\n",
    "    #model.add(Activation(activation))\n",
    "    #model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "#\n",
    "    #model.add(Conv2D(256, (5, 5), padding='valid'))\n",
    "    #model.add(BatchNormalization())\n",
    "    #model.add(Activation(activation))\n",
    "    #model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "#\n",
    "    #model.add(Conv2D(384, (3, 3), padding='valid'))\n",
    "    ##model.add(BatchNormalization())\n",
    "    ##model.add(Activation(activation))\n",
    "    ##model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "#\n",
    "    #model.add(Conv2D(384, (3, 3), padding='valid'))\n",
    "    ##model.add(BatchNormalization())\n",
    "    ##model.add(Activation(activation))\n",
    "    ##model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "#\n",
    "    #model.add(Conv2D(256, (3, 3), padding='valid'))\n",
    "    ##model.add(BatchNormalization())\n",
    "    ##model.add(Activation(activation))\n",
    "    ##model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "    #\n",
    "    ##model.add(Flatten())\n",
    "    ##model.add(Dense(4096))\n",
    "    ##model.add(BatchNormalization())\n",
    "    ##model.add(Activation(activation))\n",
    "    ##model.add(Dense(4096))\n",
    "    ##model.add(BatchNormalization())\n",
    "    ##model.add(Activation(activation))\n",
    "    ##model.add(Dense(1000))\n",
    "    ##model.add(BatchNormalization())\n",
    "    ##model.add(Activation('softmax'))\n",
    "    \n",
    "    model = Sequential([\n",
    "        Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=input_shape),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(3,3), strides=(2,2)),\n",
    "        Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(3,3), strides=(2,2)),\n",
    "        Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(filters=384, kernel_size=(1,1), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(filters=256, kernel_size=(1,1), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(3,3), strides=(2,2)),\n",
    "        Flatten(),\n",
    "        Dense(4096, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(4096, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(units = 2, activation='relu')\n",
    "\n",
    "        #keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alexnetK2(activation='relu', input_shape=(224,224,3)):\n",
    "    image_input = Input(input_shape)\n",
    "    vector_input = Input((12,))\n",
    "    \n",
    "    image_model = Conv2D(32,(8,8), strides=(4,4))(image_input)\n",
    "    image_model = Activation(activation)(image_model)\n",
    "    image_model = Conv2D(64,(4,4), strides=(2,2))(image_model)\n",
    "    image_model = Activation(activation)(image_model)\n",
    "    image_model = Conv2D(64,(3,3), strides=(1,1))(image_model)\n",
    "    image_model = Activation(activation)(image_model)\n",
    "    image_model = Flatten()(image_model)\n",
    "    image_model = Dense(512)(image_model)\n",
    "    image_model = Activation(activation)(image_model)\n",
    "\n",
    "    value_model = Dense(16)(vector_input)\n",
    "    value_model = Activation(activation)(value_model)\n",
    "    value_model = Dense(16)(value_model)\n",
    "    value_model = Activation(activation)(value_model)\n",
    "    value_model = Dense(16)(value_model)\n",
    "    value_model = Activation(activation)(value_model)\n",
    "\n",
    "    merged = concatenate([image_model, value_model])\n",
    "\n",
    "    output = Dense(1, activation='sigmoid')(merged)\n",
    "\n",
    "    model = Model(inputs=[image_input, vector_input], outputs=output)\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg16():\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Block 1\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same')(img_input))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same')(x))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x))\n",
    "\n",
    "    # Block 2\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same')(x))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same')(x))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x))\n",
    "\n",
    "    # Block 3\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same')(x))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same')(x))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same')(x))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x))\n",
    "             \n",
    "    # Block 4\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same')(x))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same')(x))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same')(x))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x))\n",
    "             \n",
    "    #Block 5\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same')(x))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same')(x))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same')(x))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg6():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), strides = 1, padding = \"same\", activation = \"relu\", input_shape = (32, 32, 3)))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Conv2D(32, (3, 3), strides = 1, padding = \"same\", activation = \"relu\"))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(64, (3, 3), strides = 1, padding = \"same\", activation = \"relu\"))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Conv2D(64, (3, 3), strides = 1, padding = \"same\", activation = \"relu\"))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(128, (3, 3), strides = 1, padding = \"same\", activation = \"relu\"))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Conv2D(128, (3, 3), strides = 1, padding = \"same\", activation = \"relu\"))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingset = TrainingSet.SYNTHETIC\n",
    "_USE_DATA_AUGMENTATION = True\n",
    "\n",
    "_BATCH_SIZE = 32 #64\n",
    "_IMG_HEIGHT = 224\n",
    "_SAMPLES = 64\n",
    "_EPOCHS = 1\n",
    "_OPTIMIZER = Adam\n",
    "_LR = 1 #2, 5\n",
    "_FIRST_NEURON = 1024 #2048, 4096\n",
    "_DROP_OUT = 0.25 # 0.5\n",
    "_ACTIVATION = 'relu' # leakyrelu\n",
    "_HIDDEN_LAYERS = 0 #1, 2, 3, 4\n",
    "\n",
    "_RUN = 'SYNTH'\n",
    "_LOSS = 'mean_squared_error'\n",
    "_DATASET_NAME = '201019_2253_final'\n",
    "_DEVICE = 'GeForce_RTX_2070'\n",
    "storage = OutputDirectory.SSD\n",
    "\n",
    "_REDUCTION_METRIC = 'custom_mae'\n",
    "_MONITOR_VALUE = 'val_custom_mae'\n",
    "_LABLE_TYPE = 'Proto' # Stereographic, Angular, Normalized\n",
    "_DEVICE = 'RTX_2070_GPU0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#storage = OutputDirectory.SSD # 'fast_output' if ssd storage may suffice, 'output' otherwise\n",
    "\n",
    "#APPENDIX = 'Stereographic'\n",
    "\n",
    "#FUNCTION_OVERRIDE = ['mean_squared_error', [custom_mae], 'val_custom_mae'] # None, or e. g. ['mean_squared_error', [circular_mae], 'val_circular_mae']\n",
    "\n",
    "if _LABLE_TYPE == 'Stereographic':\n",
    "    _CSV_FILE_NAME = 'images_synthetisch_stereographic.csv'\n",
    "    _IMAGE_TYPE_NAME = ''\n",
    "    _COLOR_MODE = 'rgb'\n",
    "    _COLOR_CHANNELS = 3\n",
    "    _STEREOGRAPHIC = True\n",
    "elif _LABLE_TYPE == 'Angular':\n",
    "    _CSV_FILE_NAME = 'labels_ks_rgb.csv'\n",
    "    _IMAGE_TYPE_NAME = 'rgb'\n",
    "    _COLOR_MODE = 'rgb'\n",
    "    _COLOR_CHANNELS = 3\n",
    "    _STEREOGRAPHIC = False\n",
    "elif _LABLE_TYPE == 'Angular_RGBD':\n",
    "    _CSV_FILE_NAME = 'labels_ks_rgbd.csv'\n",
    "    _IMAGE_TYPE_NAME = 'rgbd'\n",
    "    _COLOR_MODE = 'rgba'\n",
    "    _COLOR_CHANNELS = 4\n",
    "    _STEREOGRAPHIC = False\n",
    "elif _LABLE_TYPE == 'Proto':\n",
    "    _CSV_FILE_NAME = 'lables_ks_proto.csv'\n",
    "    _IMAGE_TYPE_NAME = 'rgb_proto'\n",
    "    _COLOR_MODE = 'rgb'\n",
    "    _COLOR_CHANNELS = 3\n",
    "    _STEREOGRAPHIC = False\n",
    "elif _LABLE_TYPE == 'Normalized':\n",
    "    _CSV_FILE_NAME = 'images_synthetisch_normalized.csv'\n",
    "    _IMAGE_TYPE_NAME = ''\n",
    "    _COLOR_MODE = 'rgb'\n",
    "    _COLOR_CHANNELS = 3\n",
    "    _STEREOGRAPHIC = False\n",
    "else:\n",
    "    assert(True, 'LabelType Invalid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data_generation/dataset/201019_2253_final/rgb_proto/lables_ks_proto.csv\n",
      "Directory >>| ..\\fast_output\\SYNTH_Regression_mean_squared_error\\201019_2253_final_Proto_Top_1_Custom-MAE\\Synth_TD\\ |<< existiert bereits. Fortsetzen auf eigene Gefahr! (Weiter mit Enter)\n"
     ]
    }
   ],
   "source": [
    "_IMAGE_DIR = '../../data_generation/dataset/{}/{}/'.format(_DATASET_NAME, _IMAGE_TYPE_NAME)\n",
    "#_IMAGE_DIR = '../../data_generation/'\n",
    "_CSV_FILE = _IMAGE_DIR + _CSV_FILE_NAME\n",
    "print(_CSV_FILE)\n",
    "data_dir = pathlib.Path(_IMAGE_DIR)\n",
    "_IMAGE_COUNT = len(list(data_dir.glob('*.png')))\n",
    "_STEPS_PER_EPOCH = np.ceil(_IMAGE_COUNT/_BATCH_SIZE)\n",
    "\n",
    "_note = '_Custom-MAE'\n",
    "\n",
    "_MODEL_DIR = '..\\\\output\\\\{}_Regression_{}\\\\{}_{}_Base{}\\\\'.format(_RUN, _LOSS, _DATASET_NAME, _LABLE_TYPE, _note)\n",
    "_NET_DIR = '{}_Regression_{}\\\\{}_{}_Top_1{}\\\\{}_TD\\\\'.format(_RUN, _LOSS, _DATASET_NAME, _LABLE_TYPE, _note, trainingset_to_string(trainingset))\n",
    "_LOG_DIR = '..\\\\{}\\\\{}'.format(output_path[storage], _NET_DIR)\n",
    "\n",
    "if(not os.path.exists(_LOG_DIR)):\n",
    "    os.makedirs(_LOG_DIR)\n",
    "else:\n",
    "    input('Directory >>| {} |<< existiert bereits. Fortsetzen auf eigene Gefahr! (Weiter mit Enter)'.format(_LOG_DIR))\n",
    "\n",
    "device_file = open(_LOG_DIR + '{}.txt'.format(_DEVICE), \"a+\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test to see if csv and images can be found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '_IMAGE_COUNT' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-49ed6292c300>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_IMAGE_COUNT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_CSV_FILE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdf2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_CSV_FILE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name '_IMAGE_COUNT' is not defined"
     ]
    }
   ],
   "source": [
    "print(_IMAGE_COUNT)\n",
    "\n",
    "from IPython.display import Image\n",
    "print(_CSV_FILE)\n",
    "df2 = pd.read_csv(_CSV_FILE)\n",
    "print(df2.head(5))\n",
    "_IMAGE_NAME = df2.iloc[0]['Filename']\n",
    "#Image( \"../../data_generation/dataset/201019_2253_final/rgb_proto/1-bunny-0-1-290-35.png\")\n",
    "Image(_IMAGE_DIR + _IMAGE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generierung Datenpipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data():\n",
    "    # if Block für synthetische Daten, um nur auf realen Daten zu trainieren _USE_SYNTHETIC_TRAIN_DATA\n",
    "    # 1. lege df_train und df_valid als leere Liste an\n",
    "    # 2. If-block um Zeile df = ... bis df_valid\n",
    "    \n",
    "    if trainingset == TrainingSet.SYNTHETIC:\n",
    "        df = pd.read_csv(_CSV_FILE)\n",
    "        df_shuffled = df.sample(frac = 1, random_state = 1)\n",
    "        df_train = df_shuffled[0 : int(_SAMPLES * 0.8)]\n",
    "        df_valid = df_shuffled.drop(df_shuffled.index[0 : df_train.shape[0]])[0 : int(_SAMPLES * 0.2)]\n",
    "        \n",
    "    elif trainingset == TrainingSet.MIXED:\n",
    "        df = pd.read_csv(_CSV_FILE)\n",
    "        df_shuffled = df.sample(frac = 1, random_state = 1)\n",
    "        df_train = df_shuffled[0 : int(_SAMPLES * 0.8 // _BATCH_SIZE * _BATCH_SIZE)]\n",
    "        df_valid = df_shuffled.drop(df_shuffled.index[0 : df_train.shape[0]])[0 : int(_SAMPLES * 0.2 // _BATCH_SIZE * _BATCH_SIZE)]\n",
    "        \n",
    "        df_real = pd.read_csv(_CSV_FILE_REAL)\n",
    "        df_shuffled_real = df_real.sample(frac = 1, random_state = 1)\n",
    "        df_shuffled_real = df_shuffled_real.drop(df_shuffled_real.index[(df_shuffled_real.shape[0] - 61) : df_shuffled_real.shape[0]])\n",
    "        df_train_real = df_shuffled_real[0: int(df_shuffled_real.shape[0] * 0.8 // _BATCH_SIZE * _BATCH_SIZE)]   \n",
    "        df_valid_real = df_shuffled_real.drop(df_shuffled_real.index[0 : df_train_real.shape[0]])\n",
    "        df_train = df_train.drop(df_train.index[df_train.shape[0] - df_train_real.shape[0] : df_train.shape[0]])\n",
    "        df_valid = df_valid.drop(df_valid.index[df_valid.shape[0] - df_valid_real.shape[0] : df_valid.shape[0]])\n",
    "        df_train = df_train.append(df_train_real)\n",
    "        df_valid= df_valid.append(df_valid_real)\n",
    "    \n",
    "    elif trainingset == TrainingSet.REAL: # Add check for _SAMPLES, once the real dataset increases\n",
    "        df_real = pd.read_csv(_CSV_FILE_REAL)\n",
    "        df_shuffled_real = df_real.sample(frac = 1, random_state = 1)\n",
    "        df_shuffled_real = df_shuffled_real.drop(df_shuffled_real.index[(df_shuffled_real.shape[0] - 61) : df_shuffled_real.shape[0]])\n",
    "        df_train = df_shuffled_real[0 : int(df_shuffled_real.shape[0] * 0.8 // _BATCH_SIZE * _BATCH_SIZE)]   \n",
    "        df_valid = df_shuffled_real.drop(df_shuffled_real.index[0 : df_train.shape[0]])\n",
    "        \n",
    "    else:\n",
    "        print('Create_Data :: should not have reached here')\n",
    "       \n",
    "\n",
    "    if _USE_DATA_AUGMENTATION:\n",
    "        train_data_generator = ImageDataGenerator(\n",
    "            rescale = 1./255, \n",
    "            width_shift_range = 0.1,\n",
    "            height_shift_range = 0.1, \n",
    "            zoom_range = 0.1,\n",
    "            brightness_range = (0.25, 0.75),\n",
    "            fill_mode = 'nearest'\n",
    "        )\n",
    "    else:\n",
    "        train_data_generator = ImageDataGenerator(\n",
    "            rescale = 1./255\n",
    "        )\n",
    "    \n",
    "    print('Y-Col: {}'.format(get_Label_Names(_LABLE_TYPE)))\n",
    "    print('Train Data Generator: ', end = '')\n",
    "\n",
    "    train_generator = train_data_generator.flow_from_dataframe(\n",
    "        dataframe = df_train,\n",
    "        directory = _IMAGE_DIR,\n",
    "        x_col = 'Filename',\n",
    "        y_col = get_Label_Names(_LABLE_TYPE),\n",
    "        class_mode = 'raw',\n",
    "        target_size = (_IMG_HEIGHT, _IMG_HEIGHT),\n",
    "        color_mode = _COLOR_MODE,\n",
    "        shuffle = True,\n",
    "        seed = 1,\n",
    "        batch_size = _BATCH_SIZE\n",
    "    )\n",
    "                \n",
    "    valid_data_generator = ImageDataGenerator(\n",
    "        rescale = 1./255\n",
    "    )\n",
    "    print('Validation Data Generator: ', end = '')\n",
    "\n",
    "    valid_generator = valid_data_generator.flow_from_dataframe(\n",
    "        dataframe = df_valid,\n",
    "        directory = _IMAGE_DIR,\n",
    "        x_col = 'Filename',\n",
    "        y_col = get_Label_Names(_LABLE_TYPE),\n",
    "        class_mode = 'raw',\n",
    "        target_size = (_IMG_HEIGHT,_IMG_HEIGHT),\n",
    "        color_mode = _COLOR_MODE,\n",
    "        shuffle = False,\n",
    "        seed = 1,\n",
    "        batch_size = _BATCH_SIZE\n",
    "    )\n",
    "                                                        \n",
    "    return train_generator, valid_generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generierung Modell "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_run():#x, y, x_val, y_val):\n",
    "    K.clear_session()\n",
    "    \n",
    "    train_generator, valid_generator = create_data()\n",
    "    tg_steps_per_epoch = train_generator.n // train_generator.batch_size\n",
    "    vg_validation_steps = valid_generator.n // valid_generator.batch_size\n",
    "    print('Steps per Epoch: {}, Validation Steps: {}'.format(tg_steps_per_epoch, vg_validation_steps))\n",
    "    \n",
    "    dropout_rate = _DROP_OUT\n",
    "    first_neuron = _FIRST_NEURON\n",
    "    \n",
    "    if _ACTIVATION == 'leakyrelu':\n",
    "        activation_layer = LeakyReLU(alpha = params['leaky_alpha'])\n",
    "    elif _ACTIVATION == 'relu':\n",
    "        activation_layer = ReLU()\n",
    "    \n",
    "    model = Sequential()\n",
    "    cnn = alexnet(input_shape=(_IMG_HEIGHT,_IMG_HEIGHT,_COLOR_CHANNELS))\n",
    "      \n",
    "    print('_________________________________________________________________')\n",
    "    print('{:>16} {:>16}'.format('Network Layer', 'Trainable'))\n",
    "    print('=================================================================')\n",
    "    for layer in cnn.layers:\n",
    "        print('{:>16} {:>16}'.format(layer.name, layer.trainable))\n",
    "    print('_________________________________________________________________\\n')\n",
    "    \n",
    "    model.add(cnn)\n",
    "    \n",
    "    #fc = Sequential()\n",
    "    #fc.add(Flatten(input_shape = model.output_shape[1:])) # (7, 7, 512)\n",
    "    #\n",
    "    #fc.add(Dense(units = first_neuron, kernel_initializer = glorot_uniform(seed = 1)))\n",
    "    #fc.add(activation_layer)\n",
    "    #if dropout_rate > 0.0:\n",
    "    #    fc.add(Dropout(rate = dropout_rate))\n",
    "    #\n",
    "    #print('Number Hidden Layers {}'.format(_HIDDEN_LAYERS))\n",
    "    #hidden_neuron_fraction = first_neuron\n",
    "    #for i in range(_HIDDEN_LAYERS):\n",
    "    #    hidden_neuron_fraction = hidden_neuron_fraction // 2\n",
    "    #    fc.add(Dense(units = hidden_neuron_fraction, kernel_initializer = glorot_uniform(seed = 1)))\n",
    "    #    fc.add(activation_layer)\n",
    "    #    if dropout_rate > 0.0:\n",
    "    #        fc.add(Dropout(rate = dropout_rate))\n",
    "    #\n",
    "    #fc.add(Dense(units = 2, kernel_initializer = glorot_uniform(seed = 1)))\n",
    "    #model.add(fc)\n",
    "    \n",
    "    print('Fully Connected Layers added to Base Network')\n",
    "    \n",
    "    print('Using Loss: {} \\nand Reduction Metric: {}'.format(\n",
    "        _LOSS, \n",
    "        get_Reduction_Metric(_REDUCTION_METRIC)))\n",
    "    \n",
    "    model.compile(\n",
    "        #optimizer=params['optimizer'](lr=lr_normalizer(params['lr'], params['optimizer'])*1e-2),\n",
    "        optimizer = _OPTIMIZER(lr = lr_normalizer(_LR, _OPTIMIZER) * 1e-3),\n",
    "        loss = _LOSS,\n",
    "        metrics = get_Reduction_Metric(_REDUCTION_METRIC)\n",
    "    )\n",
    "    print('Model was compiled')\n",
    "    print(model.summary())\n",
    "    print('_________________________________________________________________')\n",
    "    \n",
    "    checkpointer = callbacks.ModelCheckpoint(\n",
    "        #filepath = _LOG_DIR + 'CNN_Base_{}_Model_and_Weights_{}.hdf5'.format(_MODEL_TO_LOAD_INDEX, train_generator.n),\n",
    "        filepath = _LOG_DIR + 'CNN_Base_Model_and_Weights_AlexNet.hdf5',\n",
    "        monitor =  _MONITOR_VALUE,\n",
    "        verbose = 1,\n",
    "        save_weights_only = False,\n",
    "        save_best_only = True,\n",
    "        mode = 'min'\n",
    "    )\n",
    "    print('Checkpointer was created')\n",
    "    \n",
    "    csv_logger = callbacks.CSVLogger(\n",
    "        #filename = _LOG_DIR + 'CNN_Base_{}_Logger_{}.csv'.format(_MODEL_TO_LOAD_INDEX, train_generator.n),\n",
    "        filename = _LOG_DIR + 'CNN_Base_Logger_AlexNet.csv',\n",
    "        separator = ',',\n",
    "        append = False\n",
    "    )\n",
    "    print('CSV Logger was created')\n",
    "\n",
    "    lr_reducer = callbacks.ReduceLROnPlateau(\n",
    "        monitor = 'val_loss',\n",
    "        factor = 0.1,\n",
    "        patience = 13,\n",
    "        verbose = 1,\n",
    "        mode = 'min',\n",
    "        min_delta = 0.0001\n",
    "    )\n",
    "    print('Learning Rate Reducer was created')\n",
    "    \n",
    "    early_stopper = callbacks.EarlyStopping(\n",
    "        monitor = 'val_loss',\n",
    "        min_delta = 0,\n",
    "        #patience = 15,\n",
    "        patience = 20,\n",
    "        verbose = 1,\n",
    "        mode = 'min',\n",
    "        restore_best_weights = True\n",
    "    )\n",
    "    print('Early Stopper was created')\n",
    "    \n",
    "    out = model.fit(\n",
    "        x = train_generator,\n",
    "        steps_per_epoch = tg_steps_per_epoch,\n",
    "        validation_data = valid_generator,\n",
    "        validation_steps = vg_validation_steps,\n",
    "        callbacks = [checkpointer, csv_logger, lr_reducer, early_stopper],\n",
    "        epochs = _EPOCHS,\n",
    "        workers = 8\n",
    "    )\n",
    "    \n",
    "    return out, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y-Col: ['Elevation', 'Azimuth']\n",
      "Train Data Generator: Found 51 validated image filenames.\n",
      "Validation Data Generator: Found 12 validated image filenames.\n",
      "Steps per Epoch: 1, Validation Steps: 0\n",
      "_________________________________________________________________\n",
      "   Network Layer        Trainable\n",
      "=================================================================\n",
      "        conv2d_1                1\n",
      "batch_normalization_1                1\n",
      " max_pooling2d_1                1\n",
      "        conv2d_2                1\n",
      "batch_normalization_2                1\n",
      " max_pooling2d_2                1\n",
      "        conv2d_3                1\n",
      "batch_normalization_3                1\n",
      "        conv2d_4                1\n",
      "batch_normalization_4                1\n",
      "        conv2d_5                1\n",
      "batch_normalization_5                1\n",
      " max_pooling2d_3                1\n",
      "       flatten_1                1\n",
      "         dense_1                1\n",
      "       dropout_1                1\n",
      "         dense_2                1\n",
      "       dropout_2                1\n",
      "         dense_3                1\n",
      "_________________________________________________________________\n",
      "\n",
      "Fully Connected Layers added to Base Network\n",
      "Using Loss: mean_squared_error \n",
      "and Reduction Metric: [<function custom_mae at 0x000002456C532CA8>]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'lr_normalizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-96-a3298b360be3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'AlexNet_Model/'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-95-b96912937b5e>\u001b[0m in \u001b[0;36mmodel_run\u001b[1;34m()\u001b[0m\n\u001b[0;32m     55\u001b[0m     model.compile(\n\u001b[0;32m     56\u001b[0m         \u001b[1;31m#optimizer=params['optimizer'](lr=lr_normalizer(params['lr'], params['optimizer'])*1e-2),\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m         \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_OPTIMIZER\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlr_normalizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_LR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_OPTIMIZER\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m1e-3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_LOSS\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[0mmetrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_Reduction_Metric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_REDUCTION_METRIC\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'lr_normalizer' is not defined"
     ]
    }
   ],
   "source": [
    "out, model = model_run()\n",
    "\n",
    "out.save('AlexNet_Model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
