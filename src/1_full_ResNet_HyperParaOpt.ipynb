{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kristins Alex "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install -U git+https://github.com/keras-team/keras git+https://github.com/keras-team/keras-applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The installed version of TensorFlow 2.1.0 includes GPU support.\n",
      "\n",
      "Num GPUs Available:  1 \n",
      "\n",
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 4134175289849093038\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 20264236482\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 6192891619864284921\n",
      "physical_device_desc: \"device: 0, name: GeForce RTX 3090, pci bus id: 0000:65:00.0, compute capability: 8.6\"\n",
      "]\n",
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "from dataclasses import dataclass\n",
    "import warnings\n",
    "\n",
    "import talos as ta\n",
    "from talos.model import lr_normalizer\n",
    "import numpy as np\n",
    "from numpy.random import seed\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import random\n",
    "\n",
    "from tensorflow.compat.v1.keras import callbacks, backend as K\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, AveragePooling2D\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import ReLU, LeakyReLU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "available_gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "built_with_cuda = tf.test.is_built_with_cuda()\n",
    "\n",
    "if not (not available_gpus) & built_with_cuda:\n",
    "    print(\"The installed version of TensorFlow {} includes GPU support.\\n\".format(tf.__version__))\n",
    "    print(\"Num GPUs Available: \", len(available_gpus), \"\\n\")\n",
    "else:\n",
    "    print(\"The installed version of TensorFlow {} does not include GPU support.\\n\".format(tf.__version__))\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "tf.random.set_seed(1)\n",
    "\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.99\n",
    "sess = tf.compat.v1.Session(config = config)\n",
    "K.set_session(sess)\n",
    "\n",
    "#gpu_options = tf.GPUOptions(allow_growth=True)\n",
    "#session = tf.InteractiveSession(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PYTHONHASHSEED']='0'\n",
    "\n",
    "s = 23\n",
    "seed(s)\n",
    "tf.random.set_seed(s)\n",
    "random.seed(s)\n",
    "np.random.seed(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alexnet(activation, leaky_alpha, dropout):\n",
    "    \n",
    "    K.clear_session()\n",
    "        \n",
    "    if activation == 'leakyrelu':\n",
    "        activation_layer = LeakyReLU(alpha = leaky_alpha)\n",
    "    elif activation == 'relu':\n",
    "        activation_layer = ReLU()\n",
    "    \n",
    "    model = Sequential([\n",
    "        Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), activation=activation_layer, input_shape=(224,224,Global.num_image_channels)),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(3,3), strides=(2,2)),\n",
    "        Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation=activation_layer, padding=\"same\"),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(3,3), strides=(2,2)),\n",
    "        Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation=activation_layer, padding=\"same\"),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(filters=384, kernel_size=(1,1), strides=(1,1), activation=activation_layer, padding=\"same\"),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(filters=256, kernel_size=(1,1), strides=(1,1), activation=activation_layer, padding=\"same\"),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(3,3), strides=(2,2)),\n",
    "        Flatten(),\n",
    "        Dense(4096, activation=activation_layer),\n",
    "        Dropout(dropout),\n",
    "        Dense(4096, activation=activation_layer),\n",
    "        Dropout(dropout),\n",
    "        Dense(units = 2, activation=activation_layer)\n",
    "        #Dense(10, activation='softmax')\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg16_old(activation, leaky_alpha):\n",
    "        \n",
    "    if activation == 'leakyrelu':\n",
    "        activation_layer = LeakyReLU(alpha = leaky_alpha)\n",
    "    elif activation == 'relu':\n",
    "        activation_layer = ReLU()\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(input_shape=(224,224,Global.num_image_channels), filters = 64, kernel_size = (3,3), padding = \"same\", activation = activation_layer))\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3), padding = \"same\", activation = activation_layer))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2), strides = (2,2)))\n",
    "    \n",
    "    model.add(Conv2D(filters = 128, kernel_size = (3,3), padding = \"same\", activation = activation_layer))\n",
    "    model.add(Conv2D(filters = 128, kernel_size = (3,3), padding = \"same\", activation = activation_layer))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2), strides = (2,2)))\n",
    "\n",
    "    model.add(Conv2D(filters = 256, kernel_size = (3,3), padding = \"same\", activation = activation_layer))\n",
    "    model.add(Conv2D(filters = 256, kernel_size = (3,3), padding = \"same\", activation = activation_layer))\n",
    "    model.add(Conv2D(filters = 256, kernel_size = (3,3), padding = \"same\", activation = activation_layer))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2), strides = (2,2)))\n",
    "\n",
    "    model.add(Conv2D(filters = 512, kernel_size = (3,3), padding = \"same\", activation = activation_layer))\n",
    "    model.add(Conv2D(filters = 512, kernel_size = (3,3), padding = \"same\", activation = activation_layer))\n",
    "    model.add(Conv2D(filters = 512, kernel_size = (3,3), padding = \"same\", activation = activation_layer))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2), strides = (2,2)))\n",
    "\n",
    "    model.add(Conv2D(filters = 512, kernel_size = (3,3), padding = \"same\", activation = activation_layer))\n",
    "    model.add(Conv2D(filters = 512, kernel_size = (3,3), padding = \"same\", activation = activation_layer))\n",
    "    model.add(Conv2D(filters = 512, kernel_size = (3,3), padding = \"same\", activation = activation_layer))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2), strides = (2,2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units = 4096, activation = activation_layer))\n",
    "    model.add(Dense(units = 4096, activation = activation_layer))\n",
    "    #model.add(Dense(units = 2, activation = \"softmax\"))\n",
    "    model.add(Dense(units = 2, activation=activation_layer))\n",
    "\n",
    "    #opt = Adam(lr = 0.001)\n",
    "    #model.compile(optimizer = opt, loss= keras.losses.categorical_crossentropy, metrics = ['accuracy'])\n",
    "    #model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg16(activation, leaky_alpha):\n",
    "    \n",
    "    K.clear_session()\n",
    "        \n",
    "    if activation == 'leakyrelu':\n",
    "        activation_layer = LeakyReLU(alpha = leaky_alpha)\n",
    "    elif activation == 'relu':\n",
    "        activation_layer = ReLU()\n",
    "    \n",
    "    model = Sequential()\n",
    "    cnn = VGG16(include_top=False, weights=None, input_tensor=None, input_shape=(224, 224, Global.num_image_channels))\n",
    "    for layer in cnn.layers:\n",
    "        layer.trainable = True\n",
    "    x = cnn.output\n",
    "\n",
    "    x =  AveragePooling2D((7, 7), padding='same')(x)\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    x = Dense(units = 512, activation = activation_layer)(x)\n",
    "    x = Dense(units = 256, activation = activation_layer)(x)\n",
    "    x = Dense(units = 64, activation = activation_layer)(x)\n",
    "    x = Dense(units = 2, activation = activation_layer)(x)\n",
    "    model = Model(cnn.input, x)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet(activation, leaky_alpha):\n",
    "    \n",
    "    K.clear_session()\n",
    "         \n",
    "    activation_layer = ReLU()\n",
    "    if activation == 'leakyrelu':\n",
    "        activation_layer = LeakyReLU(alpha = leaky_alpha)\n",
    "    elif activation == 'relu':\n",
    "        activation_layer = ReLU()\n",
    "        \n",
    "    model = Sequential()\n",
    "    cnn = ResNet50(include_top=False, weights=None, input_tensor=None, input_shape=(224, 224, Global.num_image_channels))\n",
    "    for layer in cnn.layers:\n",
    "        layer.trainable = True\n",
    "    x = cnn.output\n",
    "\n",
    "    x =  AveragePooling2D((7, 7), padding='same')(x)\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    x = Dense(units = 512, activation = activation_layer)(x)\n",
    "    x = Dense(units = 256, activation = activation_layer)(x)\n",
    "    x = Dense(units = 64, activation = activation_layer)(x)\n",
    "    x = Dense(units = 2, activation = activation_layer)(x)\n",
    "    model = Model(cnn.input, x)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation of the DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_net(x_train, y_train, x_val, y_val, params):\n",
    "    \n",
    "    K.clear_session()\n",
    "    \n",
    "    train_generator, valid_generator = create_data_pipline(params['batch_size'], params['samples'])\n",
    "    tg_steps_per_epoch = train_generator.n // train_generator.batch_size\n",
    "    vg_validation_steps = valid_generator.n // valid_generator.batch_size\n",
    "    print('Steps per Epoch: {}, Validation Steps: {}'.format(tg_steps_per_epoch, vg_validation_steps))\n",
    "    \n",
    " \n",
    "    if(Global.net_architecture == 'ALEX'):\n",
    "        model = alexnet(params['activation'], params['leaky_alpha'], params['dropout'])\n",
    "    elif(Global.net_architecture =='VGG16'):\n",
    "        model = vgg16(params['activation'], params['leaky_alpha'])\n",
    "    elif(Global.net_architecture == 'RESNET'):\n",
    "        model = resnet(params['leaky_alpha'], params['leaky_alpha'])\n",
    "    else:\n",
    "        print('Wrong net architecture!')\n",
    "            \n",
    "    model.compile(\n",
    "        optimizer = params['optimizer'](lr = lr_normalizer(params['lr'], params['optimizer'])), \n",
    "        loss = Global.loss_function, \n",
    "        metrics = get_reduction_metric(Global.reduction_metric)\n",
    "    )\n",
    "    #print(model.summary())\n",
    "    print('_________________________________________________________________')\n",
    "    \n",
    "    startTime = datetime.now()\n",
    "    \n",
    "    out = model.fit(\n",
    "        x = train_generator,\n",
    "        epochs = params['epochs'],\n",
    "        validation_data = valid_generator,\n",
    "        steps_per_epoch = tg_steps_per_epoch,\n",
    "        validation_steps = vg_validation_steps,\n",
    "        workers = 8\n",
    "    )\n",
    "    print(\"Time taken:\", datetime.now() - startTime)\n",
    "\n",
    "    return out, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benutzerdefinierte Kostenfunktion & Metrik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolut_error(y_true, y_pred):\n",
    "    return K.mean(K.abs(y_pred - y_true), axis = -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hilfsfunktion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reduction_metric(metric):\n",
    "    \n",
    "    if metric == 'mean_absolut_error':\n",
    "        return [mean_absolut_error]\n",
    "    else:\n",
    "        assert(False, 'Metric yet unknown - Please modify get_Reduction_Metric to meet your requirements')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Struct for global parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class global_parameter:\n",
    "    loss_function: str = 'mean_squared_error'\n",
    "    reduction_metric: str = 'mean_absolut_error'\n",
    "    monitor_value: str = 'val_mean_absolut_error'\n",
    "        \n",
    "    net_architecture = 'VGG16' # 'ALEX' vs 'VGG16' vs 'RESNET'\n",
    "    \n",
    "    dataset: str = '201129_2031'\n",
    "    device: str = 'RTX_2080_Ti'\n",
    "    data_augmentation: bool = True\n",
    "    image_channels: str = 'rgb' # just change this, everything else will automaticlly adjusted\n",
    "    num_image_channels: int = 3\n",
    "    image_dir: str = '..\\\\..\\\\data_generation\\\\dataset\\\\{}\\\\'.format(dataset)\n",
    "    \n",
    "    csv_file_name: str = 'labels_ks_RGB.csv'\n",
    "    csv_file: str = image_dir + csv_file_name\n",
    "    target_dir: str = '..\\\\output\\\\{}_{}_{}\\\\'.format(net_architecture, dataset, image_channels)\n",
    "    results: str = '\\\\..\\\\{}_{}_Results.csv'.format(net_architecture, dataset)\n",
    "\n",
    "        \n",
    "Global = global_parameter\n",
    "\n",
    "if(Global.image_channels == 'rgba'):\n",
    "    Global.num_image_channels = 4\n",
    "    csv_file_name: str = 'lables_ks_RGBD.csv'\n",
    "    csv_file: str = image_dir + csv_file_name\n",
    "    target_dir: str = '..\\\\output\\\\{}_{}_{}\\\\'.format(net_architecture, dataset, image_channels)\n",
    "    results: str = '\\\\..\\\\{}_{}_Results.csv'.format(net_architecture, dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generierung Datenpipeline (Angepasst für Talos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_pipline(batch_size, num_samples):\n",
    "    \n",
    "    \n",
    "    df = pd.read_csv(Global.csv_file)\n",
    "    df_shuffled = df.sample(frac = 1, random_state = 1)\n",
    "    df_train = df_shuffled[0 : int(num_samples * 0.8 // batch_size * batch_size)]\n",
    "    df_valid = df_shuffled.drop(df_shuffled.index[0 : df_train.shape[0]])[0 : int(num_samples * 0.2 // batch_size * batch_size)]\n",
    "    \n",
    "    if Global.data_augmentation:\n",
    "        train_data_generator = ImageDataGenerator(\n",
    "            rescale = 1./255,\n",
    "            width_shift_range = 0.1,\n",
    "            height_shift_range = 0.1,\n",
    "            zoom_range = 0.1,\n",
    "            brightness_range = (0.5, 1.0), \n",
    "            fill_mode = 'nearest'\n",
    "        )\n",
    "    else:\n",
    "        train_data_generator = ImageDataGenerator(\n",
    "            rescale = 1./255\n",
    "        )\n",
    "        \n",
    "    train_generator = train_data_generator.flow_from_dataframe(\n",
    "        dataframe = df_train,\n",
    "        directory = Global.image_dir,\n",
    "        x_col = 'Filename',\n",
    "        y_col = ['Elevation', 'Azimuth'],\n",
    "        class_mode = 'raw',\n",
    "        target_size = (224, 224),\n",
    "        color_mode = Global.image_channels,\n",
    "        shuffle = True,\n",
    "        seed = 77,\n",
    "        batch_size = batch_size\n",
    "    )\n",
    "        \n",
    "    valid_data_generator = ImageDataGenerator(\n",
    "        rescale = 1./255\n",
    "    )\n",
    "    \n",
    "    valid_generator = valid_data_generator.flow_from_dataframe(\n",
    "        dataframe = df_valid,\n",
    "        directory = Global.image_dir,\n",
    "        x_col = 'Filename',\n",
    "        y_col = ['Elevation', 'Azimuth'],\n",
    "        class_mode = 'raw',\n",
    "        target_size = (224, 224),\n",
    "        color_mode = Global.image_channels,\n",
    "        shuffle = False,\n",
    "        seed = 77,\n",
    "        batch_size = batch_size\n",
    "    )\n",
    "    \n",
    "    return train_generator, valid_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if(not os.path.exists(Global.target_dir)):\n",
    "    os.makedirs(Global.target_dir)\n",
    "else:\n",
    "    input('Directory >>| {} |<< existiert bereits. Fortsetzen auf eigene Gefahr! (Weiter mit Enter)'.format(Global.target_dir))\n",
    "\n",
    "device_file = open(Global.target_dir + '{}.txt'.format(Global.device), \"a+\")\n",
    "device_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSerach Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     Adam = RMSprop + Momentum (lr=0.001)\n",
    "#     Nadam = Adam RMSprop + Nesterov-Momentum (lr=0.002)\n",
    "#     RMSprop = (lr=0.001)\n",
    "#     SGD = (lr=0.01)\n",
    "#     Adagrad\n",
    "#\n",
    "#hyper_parameter = {\n",
    "#    'samples': [20000],\n",
    "#    'epochs': [1],\n",
    "#    'batch_size': [32, 64],\n",
    "#    'optimizer': [Adam],\n",
    "#    'lr': [1, 2, 5],\n",
    "#    'first_neuron': [1024, 2048, 4096],\n",
    "#    'dropout': [0.25, 0.50],\n",
    "#    'activation': ['leakyrelu', 'relu'],\n",
    "#    'hidden_layers': [0, 1, 2, 3, 4],\n",
    "#    'leaky_alpha': [0.1] #Default bei LeakyReLU, sonst PReLU\n",
    "#}\n",
    "\n",
    "hyper_parameter = {\n",
    "    'samples': [20000],\n",
    "    'epochs': [1],\n",
    "    'batch_size': [64], #32],# 64],\n",
    "    'optimizer': [Adam],\n",
    "    'lr': [1], #1, 2, 5],\n",
    "    'first_neuron':  [1024, 2048, 4096],\n",
    "    'dropout': [0.25, 0.50],\n",
    "    'activation': ['relu', 'leakyrelu'],\n",
    "    'hidden_layers': [0, 1, 2, 3, 4],\n",
    "    'leaky_alpha': [0.1] #Default bei LeakyReLU, sonst PReLU\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Talos Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/60 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'relu', 'batch_size': 64, 'dropout': 0.25, 'epochs': 1, 'first_neuron': 1024, 'hidden_layers': 0, 'leaky_alpha': 0.1, 'lr': 1, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>, 'samples': 20000}\n",
      "Found 16000 validated image filenames.\n",
      "Found 3968 validated image filenames.\n",
      "Steps per Epoch: 250, Validation Steps: 62\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 250 steps, validate for 62 steps\n",
      "250/250 [==============================] - 1263s 5s/step - loss: 9720.2834 - mean_absolut_error: 69.7432 - val_loss: 7989.6884 - val_mean_absolut_error: 63.9244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|█▎                                                                            | 1/60 [21:06<20:45:18, 1266.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 0:21:04.663854\n",
      "{'activation': 'relu', 'batch_size': 64, 'dropout': 0.25, 'epochs': 1, 'first_neuron': 1024, 'hidden_layers': 1, 'leaky_alpha': 0.1, 'lr': 1, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>, 'samples': 20000}\n",
      "Found 16000 validated image filenames.\n",
      "Found 3968 validated image filenames.\n",
      "Steps per Epoch: 250, Validation Steps: 62\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 250 steps, validate for 62 steps\n",
      "250/250 [==============================] - 172s 687ms/step - loss: 10661.7422 - mean_absolut_error: 71.9648 - val_loss: 6828.0659 - val_mean_absolut_error: 59.9875\n",
      "Time taken: 0:02:53.501997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|██▋                                                                            | 2/60 [24:01<15:07:38, 938.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'relu', 'batch_size': 64, 'dropout': 0.25, 'epochs': 1, 'first_neuron': 1024, 'hidden_layers': 2, 'leaky_alpha': 0.1, 'lr': 1, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>, 'samples': 20000}\n",
      "Found 16000 validated image filenames.\n",
      "Found 3968 validated image filenames.\n",
      "Steps per Epoch: 250, Validation Steps: 62\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 250 steps, validate for 62 steps\n",
      "250/250 [==============================] - 171s 684ms/step - loss: 10781.9363 - mean_absolut_error: 72.9142 - val_loss: 7379.2315 - val_mean_absolut_error: 61.4724\n",
      "Time taken: 0:02:53.744998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|███▉                                                                           | 3/60 [26:56<11:14:20, 709.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'relu', 'batch_size': 64, 'dropout': 0.25, 'epochs': 1, 'first_neuron': 1024, 'hidden_layers': 3, 'leaky_alpha': 0.1, 'lr': 1, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>, 'samples': 20000}\n",
      "Found 16000 validated image filenames.\n",
      "Found 3968 validated image filenames.\n",
      "Steps per Epoch: 250, Validation Steps: 62\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 250 steps, validate for 62 steps\n",
      "250/250 [==============================] - 171s 686ms/step - loss: 11260.6693 - mean_absolut_error: 80.6568 - val_loss: 10271.2973 - val_mean_absolut_error: 78.2875\n",
      "Time taken: 0:02:53.341459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|█████▎                                                                          | 4/60 [29:51<8:32:42, 549.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'relu', 'batch_size': 64, 'dropout': 0.25, 'epochs': 1, 'first_neuron': 1024, 'hidden_layers': 4, 'leaky_alpha': 0.1, 'lr': 1, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>, 'samples': 20000}\n",
      "Found 16000 validated image filenames.\n",
      "Found 3968 validated image filenames.\n",
      "Steps per Epoch: 250, Validation Steps: 62\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 250 steps, validate for 62 steps\n",
      "250/250 [==============================] - 175s 699ms/step - loss: 9979.3464 - mean_absolut_error: 77.3634 - val_loss: 7537.9860 - val_mean_absolut_error: 70.7024\n",
      "Time taken: 0:02:55.885946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|██████▋                                                                         | 5/60 [32:48<6:41:16, 437.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'relu', 'batch_size': 64, 'dropout': 0.25, 'epochs': 1, 'first_neuron': 2048, 'hidden_layers': 0, 'leaky_alpha': 0.1, 'lr': 1, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>, 'samples': 20000}\n",
      "Found 16000 validated image filenames.\n",
      "Found 3968 validated image filenames.\n",
      "Steps per Epoch: 250, Validation Steps: 62\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 250 steps, validate for 62 steps\n",
      "250/250 [==============================] - 176s 704ms/step - loss: 22689.3359 - mean_absolut_error: 112.6963 - val_loss: 22694.0430 - val_mean_absolut_error: 112.6266\n",
      "Time taken: 0:02:57.392959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|████████                                                                        | 6/60 [35:47<5:24:06, 360.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'relu', 'batch_size': 64, 'dropout': 0.25, 'epochs': 1, 'first_neuron': 2048, 'hidden_layers': 1, 'leaky_alpha': 0.1, 'lr': 1, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>, 'samples': 20000}\n",
      "Found 16000 validated image filenames.\n",
      "Found 3968 validated image filenames.\n",
      "Steps per Epoch: 250, Validation Steps: 62\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 250 steps, validate for 62 steps\n",
      "250/250 [==============================] - 173s 691ms/step - loss: 10024.0218 - mean_absolut_error: 70.4362 - val_loss: 8591.6107 - val_mean_absolut_error: 66.1642\n",
      "Time taken: 0:02:53.901455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█████████▎                                                                      | 7/60 [38:43<4:29:09, 304.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'relu', 'batch_size': 64, 'dropout': 0.25, 'epochs': 1, 'first_neuron': 2048, 'hidden_layers': 2, 'leaky_alpha': 0.1, 'lr': 1, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>, 'samples': 20000}\n",
      "Found 16000 validated image filenames.\n",
      "Found 3968 validated image filenames.\n",
      "Steps per Epoch: 250, Validation Steps: 62\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 250 steps, validate for 62 steps\n",
      "250/250 [==============================] - 175s 699ms/step - loss: 16836.3646 - mean_absolut_error: 91.2198 - val_loss: 16961.5484 - val_mean_absolut_error: 93.1016\n",
      "Time taken: 0:02:57.191458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|██████████▋                                                                     | 8/60 [41:41<3:51:19, 266.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'relu', 'batch_size': 64, 'dropout': 0.25, 'epochs': 1, 'first_neuron': 2048, 'hidden_layers': 3, 'leaky_alpha': 0.1, 'lr': 1, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>, 'samples': 20000}\n",
      "Found 16000 validated image filenames.\n",
      "Found 3968 validated image filenames.\n",
      "Steps per Epoch: 250, Validation Steps: 62\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 250 steps, validate for 62 steps\n",
      "250/250 [==============================] - 171s 686ms/step - loss: 1745769691.5234 - mean_absolut_error: 1467.2300 - val_loss: 11343.1312 - val_mean_absolut_error: 74.9813\n",
      "Time taken: 0:02:53.419453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|████████████                                                                    | 9/60 [44:36<3:23:22, 239.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'relu', 'batch_size': 64, 'dropout': 0.25, 'epochs': 1, 'first_neuron': 2048, 'hidden_layers': 4, 'leaky_alpha': 0.1, 'lr': 1, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>, 'samples': 20000}\n",
      "Found 16000 validated image filenames.\n",
      "Found 3968 validated image filenames.\n",
      "Steps per Epoch: 250, Validation Steps: 62\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 250 steps, validate for 62 steps\n",
      "250/250 [==============================] - 172s 687ms/step - loss: 375754.1629 - mean_absolut_error: 114.4547 - val_loss: 18622.7021 - val_mean_absolut_error: 101.3894\n",
      "Time taken: 0:02:53.495502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█████████████▏                                                                 | 10/60 [47:31<3:03:18, 219.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'relu', 'batch_size': 64, 'dropout': 0.25, 'epochs': 1, 'first_neuron': 4096, 'hidden_layers': 0, 'leaky_alpha': 0.1, 'lr': 1, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>, 'samples': 20000}\n",
      "Found 16000 validated image filenames.\n",
      "Found 3968 validated image filenames.\n",
      "Steps per Epoch: 250, Validation Steps: 62\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 250 steps, validate for 62 steps\n",
      "250/250 [==============================] - 172s 687ms/step - loss: 20555.1202 - mean_absolut_error: 93.1012 - val_loss: 15204.2429 - val_mean_absolut_error: 87.8867\n",
      "Time taken: 0:02:54.124457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|██████████████▍                                                                | 11/60 [50:27<2:48:46, 206.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'relu', 'batch_size': 64, 'dropout': 0.25, 'epochs': 1, 'first_neuron': 4096, 'hidden_layers': 1, 'leaky_alpha': 0.1, 'lr': 1, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>, 'samples': 20000}\n",
      "Found 16000 validated image filenames.\n",
      "Found 3968 validated image filenames.\n",
      "Steps per Epoch: 250, Validation Steps: 62\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 250 steps, validate for 62 steps\n",
      "250/250 [==============================] - 174s 697ms/step - loss: 18568.5412 - mean_absolut_error: 88.7376 - val_loss: 15228.7676 - val_mean_absolut_error: 87.8345\n",
      "Time taken: 0:02:55.407959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|███████████████▊                                                               | 12/60 [53:24<2:38:10, 197.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'relu', 'batch_size': 64, 'dropout': 0.25, 'epochs': 1, 'first_neuron': 4096, 'hidden_layers': 2, 'leaky_alpha': 0.1, 'lr': 1, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>, 'samples': 20000}\n",
      "Found 16000 validated image filenames.\n",
      "Found 3968 validated image filenames.\n",
      "Steps per Epoch: 250, Validation Steps: 62\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 250 steps, validate for 62 steps\n",
      "250/250 [==============================] - 174s 695ms/step - loss: 17354.0934 - mean_absolut_error: 97.2244 - val_loss: 17432.8566 - val_mean_absolut_error: 98.0849\n",
      "Time taken: 0:02:55.767041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|█████████████████                                                              | 13/60 [56:21<2:30:05, 191.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'relu', 'batch_size': 64, 'dropout': 0.25, 'epochs': 1, 'first_neuron': 4096, 'hidden_layers': 3, 'leaky_alpha': 0.1, 'lr': 1, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>, 'samples': 20000}\n",
      "Found 16000 validated image filenames.\n",
      "Found 3968 validated image filenames.\n",
      "Steps per Epoch: 250, Validation Steps: 62\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 250 steps, validate for 62 steps\n",
      "250/250 [==============================] - 172s 689ms/step - loss: 15091.2648 - mean_absolut_error: 85.7222 - val_loss: 20888.3073 - val_mean_absolut_error: 106.7338\n",
      "Time taken: 0:02:54.135498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██████████████████▍                                                            | 14/60 [59:17<2:23:14, 186.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'relu', 'batch_size': 64, 'dropout': 0.25, 'epochs': 1, 'first_neuron': 4096, 'hidden_layers': 4, 'leaky_alpha': 0.1, 'lr': 1, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>, 'samples': 20000}\n",
      "Found 16000 validated image filenames.\n",
      "Found 3968 validated image filenames.\n",
      "Steps per Epoch: 250, Validation Steps: 62\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 250 steps, validate for 62 steps\n",
      "250/250 [==============================] - 172s 686ms/step - loss: 22689.3359 - mean_absolut_error: 112.6963 - val_loss: 22694.0430 - val_mean_absolut_error: 112.6266\n",
      "Time taken: 0:02:53.375959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|███████████████████▎                                                         | 15/60 [1:02:11<2:17:26, 183.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'relu', 'batch_size': 64, 'dropout': 0.5, 'epochs': 1, 'first_neuron': 1024, 'hidden_layers': 0, 'leaky_alpha': 0.1, 'lr': 1, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>, 'samples': 20000}\n",
      "Found 16000 validated image filenames.\n",
      "Found 3968 validated image filenames.\n",
      "Steps per Epoch: 250, Validation Steps: 62\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 250 steps, validate for 62 steps\n",
      "250/250 [==============================] - 174s 698ms/step - loss: 22689.3359 - mean_absolut_error: 112.6963 - val_loss: 22693.9098 - val_mean_absolut_error: 112.6262\n",
      "Time taken: 0:02:55.542958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|████████████████████▌                                                        | 16/60 [1:05:09<2:13:03, 181.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'relu', 'batch_size': 64, 'dropout': 0.5, 'epochs': 1, 'first_neuron': 1024, 'hidden_layers': 1, 'leaky_alpha': 0.1, 'lr': 1, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>, 'samples': 20000}\n",
      "Found 16000 validated image filenames.\n",
      "Found 3968 validated image filenames.\n",
      "Steps per Epoch: 250, Validation Steps: 62\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 250 steps, validate for 62 steps\n",
      "250/250 [==============================] - 174s 694ms/step - loss: 22689.3359 - mean_absolut_error: 112.6963 - val_loss: 22694.0367 - val_mean_absolut_error: 112.6266\n",
      "Time taken: 0:02:56.530959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|█████████████████████▊                                                       | 17/60 [1:08:07<2:09:18, 180.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'relu', 'batch_size': 64, 'dropout': 0.5, 'epochs': 1, 'first_neuron': 1024, 'hidden_layers': 2, 'leaky_alpha': 0.1, 'lr': 1, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>, 'samples': 20000}\n",
      "Found 16000 validated image filenames.\n",
      "Found 3968 validated image filenames.\n",
      "Steps per Epoch: 250, Validation Steps: 62\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 250 steps, validate for 62 steps\n",
      "250/250 [==============================] - 172s 686ms/step - loss: 22689.3359 - mean_absolut_error: 112.6963 - val_loss: 22694.0207 - val_mean_absolut_error: 112.6265\n",
      "Time taken: 0:02:53.710499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███████████████████████                                                      | 18/60 [1:11:02<2:05:11, 178.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'relu', 'batch_size': 64, 'dropout': 0.5, 'epochs': 1, 'first_neuron': 1024, 'hidden_layers': 3, 'leaky_alpha': 0.1, 'lr': 1, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>, 'samples': 20000}\n",
      "Found 16000 validated image filenames.\n",
      "Found 3968 validated image filenames.\n",
      "Steps per Epoch: 250, Validation Steps: 62\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 250 steps, validate for 62 steps\n",
      "250/250 [==============================] - 172s 687ms/step - loss: 18240.0658 - mean_absolut_error: 98.4716 - val_loss: 19302.8468 - val_mean_absolut_error: 103.2641\n",
      "Time taken: 0:02:53.361498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|████████████████████████▍                                                    | 19/60 [1:13:57<2:01:22, 177.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'relu', 'batch_size': 64, 'dropout': 0.5, 'epochs': 1, 'first_neuron': 1024, 'hidden_layers': 4, 'leaky_alpha': 0.1, 'lr': 1, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>, 'samples': 20000}\n",
      "Found 16000 validated image filenames.\n",
      "Found 3968 validated image filenames.\n",
      "Steps per Epoch: 250, Validation Steps: 62\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 250 steps, validate for 62 steps\n",
      "250/250 [==============================] - 172s 688ms/step - loss: 17770.3938 - mean_absolut_error: 90.7735 - val_loss: 20371.5785 - val_mean_absolut_error: 105.1819\n",
      "Time taken: 0:02:53.230001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|█████████████████████████▋                                                   | 20/60 [1:16:51<1:57:50, 176.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'relu', 'batch_size': 64, 'dropout': 0.5, 'epochs': 1, 'first_neuron': 2048, 'hidden_layers': 0, 'leaky_alpha': 0.1, 'lr': 1, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>, 'samples': 20000}\n",
      "Found 16000 validated image filenames.\n",
      "Found 3968 validated image filenames.\n",
      "Steps per Epoch: 250, Validation Steps: 62\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 250 steps, validate for 62 steps\n",
      "250/250 [==============================] - 174s 697ms/step - loss: 11694.7435 - mean_absolut_error: 81.3355 - val_loss: 10216.6737 - val_mean_absolut_error: 78.1484\n",
      "Time taken: 0:02:55.235456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|██████████████████████████▉                                                  | 21/60 [1:19:48<1:54:53, 176.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'relu', 'batch_size': 64, 'dropout': 0.5, 'epochs': 1, 'first_neuron': 2048, 'hidden_layers': 1, 'leaky_alpha': 0.1, 'lr': 1, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>, 'samples': 20000}\n",
      "Found 16000 validated image filenames.\n",
      "Found 3968 validated image filenames.\n",
      "Steps per Epoch: 250, Validation Steps: 62\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 250 steps, validate for 62 steps\n",
      "250/250 [==============================] - 174s 696ms/step - loss: 17125.9210 - mean_absolut_error: 93.1039 - val_loss: 15688.8490 - val_mean_absolut_error: 90.1941\n",
      "Time taken: 0:02:55.361458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|████████████████████████████▏                                                | 22/60 [1:22:45<1:51:59, 176.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'relu', 'batch_size': 64, 'dropout': 0.5, 'epochs': 1, 'first_neuron': 2048, 'hidden_layers': 2, 'leaky_alpha': 0.1, 'lr': 1, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>, 'samples': 20000}\n",
      "Found 16000 validated image filenames.\n",
      "Found 3968 validated image filenames.\n",
      "Steps per Epoch: 250, Validation Steps: 62\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 250 steps, validate for 62 steps\n",
      "250/250 [==============================] - 173s 690ms/step - loss: 17315.4969 - mean_absolut_error: 94.5851 - val_loss: 10834.2896 - val_mean_absolut_error: 72.9018\n",
      "Time taken: 0:02:54.051455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|█████████████████████████████▌                                               | 23/60 [1:25:41<1:48:48, 176.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'relu', 'batch_size': 64, 'dropout': 0.5, 'epochs': 1, 'first_neuron': 2048, 'hidden_layers': 3, 'leaky_alpha': 0.1, 'lr': 1, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>, 'samples': 20000}\n",
      "Found 16000 validated image filenames.\n",
      "Found 3968 validated image filenames.\n",
      "Steps per Epoch: 250, Validation Steps: 62\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 250 steps, validate for 62 steps\n",
      "250/250 [==============================] - 173s 692ms/step - loss: 9389.7279 - mean_absolut_error: 75.6620 - val_loss: 8710.5420 - val_mean_absolut_error: 73.7835\n",
      "Time taken: 0:02:54.399429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|██████████████████████████████▊                                              | 24/60 [1:28:37<1:45:46, 176.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'relu', 'batch_size': 64, 'dropout': 0.5, 'epochs': 1, 'first_neuron': 2048, 'hidden_layers': 4, 'leaky_alpha': 0.1, 'lr': 1, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>, 'samples': 20000}\n",
      "Found 16000 validated image filenames.\n",
      "Found 3968 validated image filenames.\n",
      "Steps per Epoch: 250, Validation Steps: 62\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 250 steps, validate for 62 steps\n",
      "250/250 [==============================] - 172s 690ms/step - loss: 9840.2573 - mean_absolut_error: 69.6671 - val_loss: 9382.8282 - val_mean_absolut_error: 68.5239\n",
      "Time taken: 0:02:54.201498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|████████████████████████████████                                             | 25/60 [1:31:32<1:42:43, 176.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'relu', 'batch_size': 64, 'dropout': 0.5, 'epochs': 1, 'first_neuron': 4096, 'hidden_layers': 0, 'leaky_alpha': 0.1, 'lr': 1, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>, 'samples': 20000}\n",
      "Found 16000 validated image filenames.\n",
      "Found 3968 validated image filenames.\n",
      "Steps per Epoch: 250, Validation Steps: 62\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 250 steps, validate for 62 steps\n",
      "250/250 [==============================] - 172s 688ms/step - loss: 16629.3568 - mean_absolut_error: 90.6451 - val_loss: 10894.3313 - val_mean_absolut_error: 73.6684\n",
      "Time taken: 0:02:54.809960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|█████████████████████████████████▎                                           | 26/60 [1:34:29<1:39:50, 176.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'relu', 'batch_size': 64, 'dropout': 0.5, 'epochs': 1, 'first_neuron': 4096, 'hidden_layers': 1, 'leaky_alpha': 0.1, 'lr': 1, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>, 'samples': 20000}\n",
      "Found 16000 validated image filenames.\n",
      "Found 3968 validated image filenames.\n",
      "Steps per Epoch: 250, Validation Steps: 62\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 250 steps, validate for 62 steps\n",
      "250/250 [==============================] - 171s 685ms/step - loss: 17314.4207 - mean_absolut_error: 94.5680 - val_loss: 11989.7503 - val_mean_absolut_error: 76.2527\n",
      "Time taken: 0:02:53.990495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|██████████████████████████████████▋                                          | 27/60 [1:37:24<1:36:47, 175.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'relu', 'batch_size': 64, 'dropout': 0.5, 'epochs': 1, 'first_neuron': 4096, 'hidden_layers': 2, 'leaky_alpha': 0.1, 'lr': 1, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>, 'samples': 20000}\n",
      "Found 16000 validated image filenames.\n",
      "Found 3968 validated image filenames.\n",
      "Steps per Epoch: 250, Validation Steps: 62\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 250 steps, validate for 62 steps\n",
      "250/250 [==============================] - 172s 690ms/step - loss: 17193.8985 - mean_absolut_error: 93.9324 - val_loss: 18519.1796 - val_mean_absolut_error: 98.6955\n",
      "Time taken: 0:02:53.781453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|███████████████████████████████████▉                                         | 28/60 [1:40:19<1:33:43, 175.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'relu', 'batch_size': 64, 'dropout': 0.5, 'epochs': 1, 'first_neuron': 4096, 'hidden_layers': 3, 'leaky_alpha': 0.1, 'lr': 1, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>, 'samples': 20000}\n",
      "Found 16000 validated image filenames.\n",
      "Found 3968 validated image filenames.\n",
      "Steps per Epoch: 250, Validation Steps: 62\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 250 steps, validate for 62 steps\n",
      "250/250 [==============================] - 171s 682ms/step - loss: 17823.8061 - mean_absolut_error: 97.3637 - val_loss: 17063.2782 - val_mean_absolut_error: 97.0536\n",
      "Time taken: 0:02:52.627501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|█████████████████████████████████████▏                                       | 29/60 [1:43:13<1:30:31, 175.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'relu', 'batch_size': 64, 'dropout': 0.5, 'epochs': 1, 'first_neuron': 4096, 'hidden_layers': 4, 'leaky_alpha': 0.1, 'lr': 1, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>, 'samples': 20000}\n",
      "Found 16000 validated image filenames.\n",
      "Found 3968 validated image filenames.\n",
      "Steps per Epoch: 250, Validation Steps: 62\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 250 steps, validate for 62 steps\n",
      "250/250 [==============================] - 172s 686ms/step - loss: 16270.5398 - mean_absolut_error: 89.1897 - val_loss: 9051.8846 - val_mean_absolut_error: 67.1196\n",
      "Time taken: 0:02:52.746498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|██████████████████████████████████████▌                                      | 30/60 [1:46:08<1:27:27, 174.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'leakyrelu', 'batch_size': 64, 'dropout': 0.25, 'epochs': 1, 'first_neuron': 1024, 'hidden_layers': 0, 'leaky_alpha': 0.1, 'lr': 1, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>, 'samples': 20000}\n",
      "Found 16000 validated image filenames.\n",
      "Found 3968 validated image filenames.\n",
      "Steps per Epoch: 250, Validation Steps: 62\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 250 steps, validate for 62 steps\n",
      "250/250 [==============================] - 172s 687ms/step - loss: 16592.3343 - mean_absolut_error: 91.4484 - val_loss: 16848.4109 - val_mean_absolut_error: 94.0219\n",
      "Time taken: 0:02:53.206501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|███████████████████████████████████████▊                                     | 31/60 [1:49:02<1:24:31, 174.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'leakyrelu', 'batch_size': 64, 'dropout': 0.25, 'epochs': 1, 'first_neuron': 1024, 'hidden_layers': 1, 'leaky_alpha': 0.1, 'lr': 1, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>, 'samples': 20000}\n",
      "Found 16000 validated image filenames.\n",
      "Found 3968 validated image filenames.\n",
      "Steps per Epoch: 250, Validation Steps: 62\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 250 steps, validate for 62 steps\n",
      "250/250 [==============================] - 171s 683ms/step - loss: 16047.7368 - mean_absolut_error: 89.9614 - val_loss: 16529.7346 - val_mean_absolut_error: 92.0500\n",
      "Time taken: 0:02:53.149000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|█████████████████████████████████████████                                    | 32/60 [1:51:57<1:21:34, 174.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'leakyrelu', 'batch_size': 64, 'dropout': 0.25, 'epochs': 1, 'first_neuron': 1024, 'hidden_layers': 2, 'leaky_alpha': 0.1, 'lr': 1, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>, 'samples': 20000}\n",
      "Found 16000 validated image filenames.\n",
      "Found 3968 validated image filenames.\n",
      "Steps per Epoch: 250, Validation Steps: 62\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 250 steps, validate for 62 steps\n",
      "250/250 [==============================] - 172s 687ms/step - loss: 8632.7263 - mean_absolut_error: 66.0148 - val_loss: 7468.9021 - val_mean_absolut_error: 61.6072\n",
      "Time taken: 0:02:53.088500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|██████████████████████████████████████████▎                                  | 33/60 [1:54:52<1:18:38, 174.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'leakyrelu', 'batch_size': 64, 'dropout': 0.25, 'epochs': 1, 'first_neuron': 1024, 'hidden_layers': 3, 'leaky_alpha': 0.1, 'lr': 1, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>, 'samples': 20000}\n",
      "Found 16000 validated image filenames.\n",
      "Found 3968 validated image filenames.\n",
      "Steps per Epoch: 250, Validation Steps: 62\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 250 steps, validate for 62 steps\n",
      "250/250 [==============================] - 172s 686ms/step - loss: 8672.7290 - mean_absolut_error: 66.1933 - val_loss: 5775.1574 - val_mean_absolut_error: 56.4886\n",
      "Time taken: 0:02:52.966990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|███████████████████████████████████████████▋                                 | 34/60 [1:57:46<1:15:41, 174.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'leakyrelu', 'batch_size': 64, 'dropout': 0.25, 'epochs': 1, 'first_neuron': 1024, 'hidden_layers': 4, 'leaky_alpha': 0.1, 'lr': 1, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>, 'samples': 20000}\n",
      "Found 16000 validated image filenames.\n",
      "Found 3968 validated image filenames.\n",
      "Steps per Epoch: 250, Validation Steps: 62\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 250 steps, validate for 62 steps\n",
      "250/250 [==============================] - 173s 693ms/step - loss: 8896.0608 - mean_absolut_error: 66.7077 - val_loss: 5757.2877 - val_mean_absolut_error: 56.4560\n",
      "Time taken: 0:02:54.750459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|████████████████████████████████████████████▉                                | 35/60 [2:00:42<1:12:58, 175.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'leakyrelu', 'batch_size': 64, 'dropout': 0.25, 'epochs': 1, 'first_neuron': 2048, 'hidden_layers': 0, 'leaky_alpha': 0.1, 'lr': 1, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>, 'samples': 20000}\n",
      "Found 16000 validated image filenames.\n",
      "Found 3968 validated image filenames.\n",
      "Steps per Epoch: 250, Validation Steps: 62\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 250 steps, validate for 62 steps\n",
      "250/250 [==============================] - 174s 698ms/step - loss: 8835.5992 - mean_absolut_error: 66.4910 - val_loss: 5757.7421 - val_mean_absolut_error: 56.4587\n",
      "Time taken: 0:02:55.775459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████████████████████████████████████████████▏                              | 36/60 [2:03:40<1:10:19, 175.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'leakyrelu', 'batch_size': 64, 'dropout': 0.25, 'epochs': 1, 'first_neuron': 2048, 'hidden_layers': 1, 'leaky_alpha': 0.1, 'lr': 1, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>, 'samples': 20000}\n",
      "Found 16000 validated image filenames.\n",
      "Found 3968 validated image filenames.\n",
      "Steps per Epoch: 250, Validation Steps: 62\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 250 steps, validate for 62 steps\n",
      "250/250 [==============================] - 173s 694ms/step - loss: 8925.6378 - mean_absolut_error: 67.0951 - val_loss: 5778.0403 - val_mean_absolut_error: 56.4914\n",
      "Time taken: 0:02:54.758455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|███████████████████████████████████████████████▍                             | 37/60 [2:06:36<1:07:27, 175.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'leakyrelu', 'batch_size': 64, 'dropout': 0.25, 'epochs': 1, 'first_neuron': 2048, 'hidden_layers': 2, 'leaky_alpha': 0.1, 'lr': 1, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>, 'samples': 20000}\n",
      "Found 16000 validated image filenames.\n",
      "Found 3968 validated image filenames.\n",
      "Steps per Epoch: 250, Validation Steps: 62\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 250 steps, validate for 62 steps\n",
      "250/250 [==============================] - 173s 694ms/step - loss: 8724.4753 - mean_absolut_error: 66.3061 - val_loss: 5756.0456 - val_mean_absolut_error: 56.4482\n",
      "Time taken: 0:02:54.820501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|████████████████████████████████████████████████▊                            | 38/60 [2:09:33<1:04:34, 176.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'leakyrelu', 'batch_size': 64, 'dropout': 0.25, 'epochs': 1, 'first_neuron': 2048, 'hidden_layers': 3, 'leaky_alpha': 0.1, 'lr': 1, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>, 'samples': 20000}\n",
      "Found 16000 validated image filenames.\n",
      "Found 3968 validated image filenames.\n",
      "Steps per Epoch: 250, Validation Steps: 62\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 250 steps, validate for 62 steps\n",
      "250/250 [==============================] - 173s 692ms/step - loss: 16273.5849 - mean_absolut_error: 90.9051 - val_loss: 18809.0983 - val_mean_absolut_error: 100.3077\n",
      "Time taken: 0:02:55.007500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|██████████████████████████████████████████████████                           | 39/60 [2:12:29<1:01:40, 176.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'leakyrelu', 'batch_size': 64, 'dropout': 0.25, 'epochs': 1, 'first_neuron': 2048, 'hidden_layers': 4, 'leaky_alpha': 0.1, 'lr': 1, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>, 'samples': 20000}\n",
      "Found 16000 validated image filenames.\n",
      "Found 3968 validated image filenames.\n",
      "Steps per Epoch: 250, Validation Steps: 62\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 250 steps, validate for 62 steps\n",
      "250/250 [==============================] - 172s 688ms/step - loss: 15627.0597 - mean_absolut_error: 89.5027 - val_loss: 21118.6890 - val_mean_absolut_error: 107.2689\n",
      "Time taken: 0:02:53.222000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|████████████████████████████████████████████████████▋                          | 40/60 [2:15:24<58:35, 175.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'leakyrelu', 'batch_size': 64, 'dropout': 0.25, 'epochs': 1, 'first_neuron': 4096, 'hidden_layers': 0, 'leaky_alpha': 0.1, 'lr': 1, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>, 'samples': 20000}\n",
      "Found 16000 validated image filenames.\n",
      "Found 3968 validated image filenames.\n",
      "Steps per Epoch: 250, Validation Steps: 62\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 250 steps, validate for 62 steps\n",
      "250/250 [==============================] - 172s 690ms/step - loss: 15264.7987 - mean_absolut_error: 88.3788 - val_loss: 21237.9318 - val_mean_absolut_error: 107.6972\n",
      "Time taken: 0:02:55.114460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|█████████████████████████████████████████████████████▉                         | 41/60 [2:18:20<55:44, 176.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'leakyrelu', 'batch_size': 64, 'dropout': 0.25, 'epochs': 1, 'first_neuron': 4096, 'hidden_layers': 1, 'leaky_alpha': 0.1, 'lr': 1, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>, 'samples': 20000}\n",
      "Found 16000 validated image filenames.\n",
      "Found 3968 validated image filenames.\n",
      "Steps per Epoch: 250, Validation Steps: 62\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 250 steps, validate for 62 steps\n",
      "250/250 [==============================] - 172s 689ms/step - loss: 17212.7139 - mean_absolut_error: 93.8405 - val_loss: 15303.5967 - val_mean_absolut_error: 88.1349\n",
      "Time taken: 0:02:53.747499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████████████████████████████████████████████████████▎                       | 42/60 [2:21:16<52:44, 175.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'leakyrelu', 'batch_size': 64, 'dropout': 0.25, 'epochs': 1, 'first_neuron': 4096, 'hidden_layers': 2, 'leaky_alpha': 0.1, 'lr': 1, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>, 'samples': 20000}\n",
      "Found 16000 validated image filenames.\n",
      "Found 3968 validated image filenames.\n",
      "Steps per Epoch: 250, Validation Steps: 62\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 250 steps, validate for 62 steps\n",
      "250/250 [==============================] - 172s 689ms/step - loss: 17168.6600 - mean_absolut_error: 93.8234 - val_loss: 18029.5739 - val_mean_absolut_error: 96.8084\n",
      "Time taken: 0:02:53.613499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|████████████████████████████████████████████████████████▌                      | 43/60 [2:24:11<49:45, 175.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'leakyrelu', 'batch_size': 64, 'dropout': 0.25, 'epochs': 1, 'first_neuron': 4096, 'hidden_layers': 3, 'leaky_alpha': 0.1, 'lr': 1, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>, 'samples': 20000}\n",
      "Found 16000 validated image filenames.\n",
      "Found 3968 validated image filenames.\n",
      "Steps per Epoch: 250, Validation Steps: 62\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 250 steps, validate for 62 steps\n",
      "250/250 [==============================] - 173s 693ms/step - loss: 16337.1885 - mean_absolut_error: 90.9399 - val_loss: 13194.5592 - val_mean_absolut_error: 81.1948\n",
      "Time taken: 0:02:55.411958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|█████████████████████████████████████████████████████████▉                     | 44/60 [2:27:08<46:56, 176.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'leakyrelu', 'batch_size': 64, 'dropout': 0.25, 'epochs': 1, 'first_neuron': 4096, 'hidden_layers': 4, 'leaky_alpha': 0.1, 'lr': 1, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>, 'samples': 20000}\n",
      "Found 16000 validated image filenames.\n",
      "Found 3968 validated image filenames.\n",
      "Steps per Epoch: 250, Validation Steps: 62\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 250 steps, validate for 62 steps\n",
      "250/250 [==============================] - 173s 690ms/step - loss: 14907.0905 - mean_absolut_error: 86.0871 - val_loss: 9096.7557 - val_mean_absolut_error: 67.2981\n",
      "Time taken: 0:02:53.588956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████████████████████████████████████████████████████████▎                   | 45/60 [2:30:03<43:56, 175.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'leakyrelu', 'batch_size': 64, 'dropout': 0.5, 'epochs': 1, 'first_neuron': 1024, 'hidden_layers': 0, 'leaky_alpha': 0.1, 'lr': 1, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>, 'samples': 20000}\n",
      "Found 16000 validated image filenames.\n",
      "Found 3968 validated image filenames.\n",
      "Steps per Epoch: 250, Validation Steps: 62\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 250 steps, validate for 62 steps\n",
      "250/250 [==============================] - 172s 689ms/step - loss: 19503.8106 - mean_absolut_error: 95.1938 - val_loss: 20151.7849 - val_mean_absolut_error: 104.4995\n",
      "Time taken: 0:02:54.123997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|████████████████████████████████████████████████████████████▌                  | 46/60 [2:32:59<41:00, 175.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'leakyrelu', 'batch_size': 64, 'dropout': 0.5, 'epochs': 1, 'first_neuron': 1024, 'hidden_layers': 1, 'leaky_alpha': 0.1, 'lr': 1, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>, 'samples': 20000}\n",
      "Found 16000 validated image filenames.\n",
      "Found 3968 validated image filenames.\n",
      "Steps per Epoch: 250, Validation Steps: 62\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 250 steps, validate for 62 steps\n",
      "250/250 [==============================] - 172s 687ms/step - loss: 16013.6354 - mean_absolut_error: 86.1542 - val_loss: 17664.8226 - val_mean_absolut_error: 95.8931\n",
      "Time taken: 0:02:53.456498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|█████████████████████████████████████████████████████████████▉                 | 47/60 [2:35:54<38:01, 175.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'leakyrelu', 'batch_size': 64, 'dropout': 0.5, 'epochs': 1, 'first_neuron': 1024, 'hidden_layers': 2, 'leaky_alpha': 0.1, 'lr': 1, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>, 'samples': 20000}\n",
      "Found 16000 validated image filenames.\n",
      "Found 3968 validated image filenames.\n",
      "Steps per Epoch: 250, Validation Steps: 62\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 250 steps, validate for 62 steps\n",
      "250/250 [==============================] - 172s 687ms/step - loss: 17075.1473 - mean_absolut_error: 93.2104 - val_loss: 20742.8408 - val_mean_absolut_error: 105.7638\n",
      "Time taken: 0:02:54.689457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|███████████████████████████████████████████████████████████████▏               | 48/60 [2:38:50<35:08, 175.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'leakyrelu', 'batch_size': 64, 'dropout': 0.5, 'epochs': 1, 'first_neuron': 1024, 'hidden_layers': 3, 'leaky_alpha': 0.1, 'lr': 1, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>, 'samples': 20000}\n",
      "Found 16000 validated image filenames.\n",
      "Found 3968 validated image filenames.\n",
      "Steps per Epoch: 250, Validation Steps: 62\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 250 steps, validate for 62 steps\n",
      "250/250 [==============================] - 174s 697ms/step - loss: 7672.2442 - mean_absolut_error: 62.6342 - val_loss: 6024.8438 - val_mean_absolut_error: 57.4144\n",
      "Time taken: 0:02:55.498537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|████████████████████████████████████████████████████████████████▌              | 49/60 [2:41:47<32:17, 176.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'leakyrelu', 'batch_size': 64, 'dropout': 0.5, 'epochs': 1, 'first_neuron': 1024, 'hidden_layers': 4, 'leaky_alpha': 0.1, 'lr': 1, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>, 'samples': 20000}\n",
      "Found 16000 validated image filenames.\n",
      "Found 3968 validated image filenames.\n",
      "Steps per Epoch: 250, Validation Steps: 62\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 250 steps, validate for 62 steps\n",
      "250/250 [==============================] - 176s 705ms/step - loss: 17031.8169 - mean_absolut_error: 93.8877 - val_loss: 20033.6817 - val_mean_absolut_error: 104.3911\n",
      "Time taken: 0:02:57.794551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|█████████████████████████████████████████████████████████████████▊             | 50/60 [2:44:46<29:31, 177.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'leakyrelu', 'batch_size': 64, 'dropout': 0.5, 'epochs': 1, 'first_neuron': 2048, 'hidden_layers': 0, 'leaky_alpha': 0.1, 'lr': 1, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>, 'samples': 20000}\n",
      "Found 16000 validated image filenames.\n",
      "Found 3968 validated image filenames.\n",
      "Steps per Epoch: 250, Validation Steps: 62\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 250 steps, validate for 62 steps\n",
      "250/250 [==============================] - 173s 694ms/step - loss: 16474.4141 - mean_absolut_error: 91.6518\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "2 root error(s) found.\n  (0) Resource exhausted:  MemoryError: Unable to allocate 36.8 MiB for an array with shape (64, 224, 224, 3) and data type float32\nTraceback (most recent call last):\n\n  File \"D:\\anaconda\\envs\\tf_ks\\lib\\site-packages\\tensorflow_core\\python\\ops\\script_ops.py\", line 236, in __call__\n    ret = func(*args)\n\n  File \"D:\\anaconda\\envs\\tf_ks\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\dataset_ops.py\", line 789, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"D:\\anaconda\\envs\\tf_ks\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\data_adapter.py\", line 975, in generator_fn\n    yield x[i]\n\n  File \"D:\\anaconda\\envs\\tf_ks\\lib\\site-packages\\keras_preprocessing\\image\\iterator.py\", line 65, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n\n  File \"D:\\anaconda\\envs\\tf_ks\\lib\\site-packages\\keras_preprocessing\\image\\iterator.py\", line 222, in _get_batches_of_transformed_samples\n    batch_x = np.zeros((len(index_array),) + self.image_shape, dtype=self.dtype)\n\nMemoryError: Unable to allocate 36.8 MiB for an array with shape (64, 224, 224, 3) and data type float32\n\n\n\t [[{{node PyFunc}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[IteratorGetNext]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[IteratorGetNext/_4]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n  (1) Resource exhausted:  MemoryError: Unable to allocate 36.8 MiB for an array with shape (64, 224, 224, 3) and data type float32\nTraceback (most recent call last):\n\n  File \"D:\\anaconda\\envs\\tf_ks\\lib\\site-packages\\tensorflow_core\\python\\ops\\script_ops.py\", line 236, in __call__\n    ret = func(*args)\n\n  File \"D:\\anaconda\\envs\\tf_ks\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\dataset_ops.py\", line 789, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"D:\\anaconda\\envs\\tf_ks\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\data_adapter.py\", line 975, in generator_fn\n    yield x[i]\n\n  File \"D:\\anaconda\\envs\\tf_ks\\lib\\site-packages\\keras_preprocessing\\image\\iterator.py\", line 65, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n\n  File \"D:\\anaconda\\envs\\tf_ks\\lib\\site-packages\\keras_preprocessing\\image\\iterator.py\", line 222, in _get_batches_of_transformed_samples\n    batch_x = np.zeros((len(index_array),) + self.image_shape, dtype=self.dtype)\n\nMemoryError: Unable to allocate 36.8 MiB for an array with shape (64, 224, 224, 3) and data type float32\n\n\n\t [[{{node PyFunc}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[IteratorGetNext]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n0 successful operations.\n0 derived errors ignored. [Op:__inference_distributed_function_163163]\n\nFunction call stack:\ndistributed_function -> distributed_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-2b3979b4234f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m                 \u001b[0mprint_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m                 \u001b[0mclear_session\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m                 \u001b[0msave_weights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m             )\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\tf_ks\\lib\\site-packages\\talos\\scan\\Scan.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, params, model, experiment_name, x_val, y_val, val_split, random_method, seed, performance_target, fraction_limit, round_limit, time_limit, boolean_limit, reduction_method, reduction_interval, reduction_window, reduction_threshold, reduction_metric, minimize_loss, disable_progress_bar, print_params, clear_session, save_weights)\u001b[0m\n\u001b[0;32m    194\u001b[0m         \u001b[1;31m# start runtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mscan_run\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mscan_run\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m         \u001b[0mscan_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\anaconda\\envs\\tf_ks\\lib\\site-packages\\talos\\scan\\scan_run.py\u001b[0m in \u001b[0;36mscan_run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;31m# otherwise proceed with next permutation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mscan_round\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mscan_round\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[0mself\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscan_round\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\tf_ks\\lib\\site-packages\\talos\\scan\\scan_round.py\u001b[0m in \u001b[0;36mscan_round\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;31m# fit the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mingest_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mingest_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_history\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mround_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mingest_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mround_history\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_history\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\tf_ks\\lib\\site-packages\\talos\\model\\ingest_model.py\u001b[0m in \u001b[0;36mingest_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m      8\u001b[0m                       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m                       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m                       self.round_params)\n\u001b[0m",
      "\u001b[1;32m<ipython-input-9-de941e9789a9>\u001b[0m in \u001b[0;36mgen_net\u001b[1;34m(x_train, y_train, x_val, y_val, params)\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtg_steps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[0mvalidation_steps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvg_validation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m         \u001b[0mworkers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m     )\n\u001b[0;32m     38\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Time taken:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstartTime\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\tf_ks\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mD:\\anaconda\\envs\\tf_ks\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    393\u001b[0m                       \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTEST\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    394\u001b[0m                       \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meval_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 395\u001b[1;33m                       total_epochs=1)\n\u001b[0m\u001b[0;32m    396\u001b[0m                   cbks.make_logs(model, epoch_logs, eval_result, ModeKeys.TEST,\n\u001b[0;32m    397\u001b[0m                                  prefix='val_')\n",
      "\u001b[1;32mD:\\anaconda\\envs\\tf_ks\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    127\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\tf_ks\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 98\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\tf_ks\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\tf_ks\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    604\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    605\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 606\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    607\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    608\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32mD:\\anaconda\\envs\\tf_ks\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2361\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2363\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2365\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\tf_ks\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1611\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1613\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\tf_ks\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\tf_ks\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mD:\\anaconda\\envs\\tf_ks\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m     \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
      "\u001b[1;32mD:\\anaconda\\envs\\tf_ks\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: 2 root error(s) found.\n  (0) Resource exhausted:  MemoryError: Unable to allocate 36.8 MiB for an array with shape (64, 224, 224, 3) and data type float32\nTraceback (most recent call last):\n\n  File \"D:\\anaconda\\envs\\tf_ks\\lib\\site-packages\\tensorflow_core\\python\\ops\\script_ops.py\", line 236, in __call__\n    ret = func(*args)\n\n  File \"D:\\anaconda\\envs\\tf_ks\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\dataset_ops.py\", line 789, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"D:\\anaconda\\envs\\tf_ks\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\data_adapter.py\", line 975, in generator_fn\n    yield x[i]\n\n  File \"D:\\anaconda\\envs\\tf_ks\\lib\\site-packages\\keras_preprocessing\\image\\iterator.py\", line 65, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n\n  File \"D:\\anaconda\\envs\\tf_ks\\lib\\site-packages\\keras_preprocessing\\image\\iterator.py\", line 222, in _get_batches_of_transformed_samples\n    batch_x = np.zeros((len(index_array),) + self.image_shape, dtype=self.dtype)\n\nMemoryError: Unable to allocate 36.8 MiB for an array with shape (64, 224, 224, 3) and data type float32\n\n\n\t [[{{node PyFunc}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[IteratorGetNext]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[IteratorGetNext/_4]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n  (1) Resource exhausted:  MemoryError: Unable to allocate 36.8 MiB for an array with shape (64, 224, 224, 3) and data type float32\nTraceback (most recent call last):\n\n  File \"D:\\anaconda\\envs\\tf_ks\\lib\\site-packages\\tensorflow_core\\python\\ops\\script_ops.py\", line 236, in __call__\n    ret = func(*args)\n\n  File \"D:\\anaconda\\envs\\tf_ks\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\dataset_ops.py\", line 789, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"D:\\anaconda\\envs\\tf_ks\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\data_adapter.py\", line 975, in generator_fn\n    yield x[i]\n\n  File \"D:\\anaconda\\envs\\tf_ks\\lib\\site-packages\\keras_preprocessing\\image\\iterator.py\", line 65, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n\n  File \"D:\\anaconda\\envs\\tf_ks\\lib\\site-packages\\keras_preprocessing\\image\\iterator.py\", line 222, in _get_batches_of_transformed_samples\n    batch_x = np.zeros((len(index_array),) + self.image_shape, dtype=self.dtype)\n\nMemoryError: Unable to allocate 36.8 MiB for an array with shape (64, 224, 224, 3) and data type float32\n\n\n\t [[{{node PyFunc}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[IteratorGetNext]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n0 successful operations.\n0 derived errors ignored. [Op:__inference_distributed_function_163163]\n\nFunction call stack:\ndistributed_function -> distributed_function\n"
     ]
    }
   ],
   "source": [
    "dummy_x = np.empty((1, 2, 3, 224, 224))\n",
    "dummy_y = np.empty((1, 2))\n",
    "\n",
    "with tf.device('/device:GPU:0'):\n",
    "    with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "    \n",
    "            t = ta.Scan(\n",
    "                x = dummy_x,\n",
    "                y = dummy_y,\n",
    "                model = gen_net,\n",
    "                params = hyper_parameter,\n",
    "                experiment_name = '{}'.format(Global.dataset),\n",
    "                #shuffle=False,\n",
    "                reduction_metric = Global.reduction_metric,\n",
    "                disable_progress_bar = False,\n",
    "                print_params = True,\n",
    "                clear_session = True,\n",
    "                save_weights = False\n",
    "            )\n",
    "        \n",
    "\n",
    "#t.data.to_csv(Global.target_dir + Global.results, index = True)\n",
    "t.data.to_csv(Global.target_dir + Global.results, index = True, mode='a', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf_ks]",
   "language": "python",
   "name": "conda-env-tf_ks-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
