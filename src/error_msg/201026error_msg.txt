Epoch 117/400
2499/2500 [============================>.] - ETA: 0s - loss: 471.0735 - custom_mae: 8.3339
Epoch 00117: val_custom_mae did not improve from 8.82652
2500/2500 [==============================] - 262s 105ms/step - loss: 471.1204 - custom_mae: 8.3342 - val_loss: 615.6928 - val_custom_mae: 8.9675
Epoch 118/400
2499/2500 [============================>.] - ETA: 0s - loss: 460.3077 - custom_mae: 8.2641WARNING:tensorflow:Can save best model only with val_custom_mae available, skipping.

---------------------------------------------------------------------------
ResourceExhaustedError                    Traceback (most recent call last)
D:\anaconda\envs\tf_ks\lib\site-packages\tensorflow_core\python\keras\engine\training_v2.py in on_epoch(self, epoch, mode)
    766     try:
--> 767       yield epoch_logs
    768     finally:

D:\anaconda\envs\tf_ks\lib\site-packages\tensorflow_core\python\keras\engine\training_v2.py in fit(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)
    394                       training_context=eval_context,
--> 395                       total_epochs=1)
    396                   cbks.make_logs(model, epoch_logs, eval_result, ModeKeys.TEST,

D:\anaconda\envs\tf_ks\lib\site-packages\tensorflow_core\python\keras\engine\training_v2.py in run_one_epoch(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)
    127       try:
--> 128         batch_outs = execution_function(iterator)
    129       except (StopIteration, errors.OutOfRangeError):

D:\anaconda\envs\tf_ks\lib\site-packages\tensorflow_core\python\keras\engine\training_v2_utils.py in execution_function(input_fn)
     97     return nest.map_structure(_non_none_constant_value,
---> 98                               distributed_function(input_fn))
     99 

D:\anaconda\envs\tf_ks\lib\site-packages\tensorflow_core\python\eager\def_function.py in __call__(self, *args, **kwds)
    567     else:
--> 568       result = self._call(*args, **kwds)
    569 

D:\anaconda\envs\tf_ks\lib\site-packages\tensorflow_core\python\eager\def_function.py in _call(self, *args, **kwds)
    605       # run the first trace but we should fail if variables are created.
--> 606       results = self._stateful_fn(*args, **kwds)
    607       if self._created_variables:

D:\anaconda\envs\tf_ks\lib\site-packages\tensorflow_core\python\eager\function.py in __call__(self, *args, **kwargs)
   2362       graph_function, args, kwargs = self._maybe_define_function(args, kwargs)
-> 2363     return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
   2364 

D:\anaconda\envs\tf_ks\lib\site-packages\tensorflow_core\python\eager\function.py in _filtered_call(self, args, kwargs)
   1610                            resource_variable_ops.BaseResourceVariable))),
-> 1611         self.captured_inputs)
   1612 

D:\anaconda\envs\tf_ks\lib\site-packages\tensorflow_core\python\eager\function.py in _call_flat(self, args, captured_inputs, cancellation_manager)
   1691       return self._build_call_outputs(self._inference_function.call(
-> 1692           ctx, args, cancellation_manager=cancellation_manager))
   1693     forward_backward = self._select_forward_and_backward_functions(

D:\anaconda\envs\tf_ks\lib\site-packages\tensorflow_core\python\eager\function.py in call(self, ctx, args, cancellation_manager)
    544               attrs=("executor_type", executor_type, "config_proto", config),
--> 545               ctx=ctx)
    546         else:

D:\anaconda\envs\tf_ks\lib\site-packages\tensorflow_core\python\eager\execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)
     66       message = e.message
---> 67     six.raise_from(core._status_to_exception(e.code, message), None)
     68   except TypeError as e:

D:\anaconda\envs\tf_ks\lib\site-packages\six.py in raise_from(value, from_value)

ResourceExhaustedError: 2 root error(s) found.
  (0) Resource exhausted:  MemoryError: Unable to allocate 18.4 MiB for an array with shape (32, 224, 224, 3) and data type float32
Traceback (most recent call last):

  File "D:\anaconda\envs\tf_ks\lib\site-packages\tensorflow_core\python\ops\script_ops.py", line 236, in __call__
    ret = func(*args)

  File "D:\anaconda\envs\tf_ks\lib\site-packages\tensorflow_core\python\data\ops\dataset_ops.py", line 789, in generator_py_func
    values = next(generator_state.get_iterator(iterator_id))

  File "D:\anaconda\envs\tf_ks\lib\site-packages\tensorflow_core\python\keras\engine\data_adapter.py", line 975, in generator_fn
    yield x[i]

  File "D:\anaconda\envs\tf_ks\lib\site-packages\keras_preprocessing\image\iterator.py", line 65, in __getitem__
    return self._get_batches_of_transformed_samples(index_array)

  File "D:\anaconda\envs\tf_ks\lib\site-packages\keras_preprocessing\image\iterator.py", line 222, in _get_batches_of_transformed_samples
    batch_x = np.zeros((len(index_array),) + self.image_shape, dtype=self.dtype)

MemoryError: Unable to allocate 18.4 MiB for an array with shape (32, 224, 224, 3) and data type float32


	 [[{{node PyFunc}}]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.

	 [[IteratorGetNext]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.

	 [[Shape/_6]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.

  (1) Resource exhausted:  MemoryError: Unable to allocate 18.4 MiB for an array with shape (32, 224, 224, 3) and data type float32
Traceback (most recent call last):

  File "D:\anaconda\envs\tf_ks\lib\site-packages\tensorflow_core\python\ops\script_ops.py", line 236, in __call__
    ret = func(*args)

  File "D:\anaconda\envs\tf_ks\lib\site-packages\tensorflow_core\python\data\ops\dataset_ops.py", line 789, in generator_py_func
    values = next(generator_state.get_iterator(iterator_id))

  File "D:\anaconda\envs\tf_ks\lib\site-packages\tensorflow_core\python\keras\engine\data_adapter.py", line 975, in generator_fn
    yield x[i]

  File "D:\anaconda\envs\tf_ks\lib\site-packages\keras_preprocessing\image\iterator.py", line 65, in __getitem__
    return self._get_batches_of_transformed_samples(index_array)

  File "D:\anaconda\envs\tf_ks\lib\site-packages\keras_preprocessing\image\iterator.py", line 222, in _get_batches_of_transformed_samples
    batch_x = np.zeros((len(index_array),) + self.image_shape, dtype=self.dtype)

MemoryError: Unable to allocate 18.4 MiB for an array with shape (32, 224, 224, 3) and data type float32


	 [[{{node PyFunc}}]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.

	 [[IteratorGetNext]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.

0 successful operations.
0 derived errors ignored. [Op:__inference_distributed_function_9397]

Function call stack:
distributed_function -> distributed_function


During handling of the above exception, another exception occurred:

KeyError                                  Traceback (most recent call last)
<ipython-input-18-5a0825006cfa> in <module>
     26             disable_progress_bar = False,
     27             print_params = True,
---> 28             clear_session = True
     29         )
     30 

D:\anaconda\envs\tf_ks\lib\site-packages\talos\scan\Scan.py in __init__(self, x, y, params, model, experiment_name, x_val, y_val, val_split, random_method, seed, performance_target, fraction_limit, round_limit, time_limit, boolean_limit, reduction_method, reduction_interval, reduction_window, reduction_threshold, reduction_metric, minimize_loss, disable_progress_bar, print_params, clear_session, save_weights)
    194         # start runtime
    195         from .scan_run import scan_run
--> 196         scan_run(self)

D:\anaconda\envs\tf_ks\lib\site-packages\talos\scan\scan_run.py in scan_run(self)
     24         # otherwise proceed with next permutation
     25         from .scan_round import scan_round
---> 26         self = scan_round(self)
     27         self.pbar.update(1)
     28 

D:\anaconda\envs\tf_ks\lib\site-packages\talos\scan\scan_round.py in scan_round(self)
     17     # fit the model
     18     from ..model.ingest_model import ingest_model
---> 19     self.model_history, self.round_model = ingest_model(self)
     20     self.round_history.append(self.model_history.history)
     21 

D:\anaconda\envs\tf_ks\lib\site-packages\talos\model\ingest_model.py in ingest_model(self)
      8                       self.x_val,
      9                       self.y_val,
---> 10                       self.round_params)

<ipython-input-11-f963f301abeb> in grid_model_fine(x, y, x_val, y_val, params)
    116         callbacks = [checkpointer, csv_logger, lr_reducer, early_stopper],
    117         epochs = params['epochs'],
--> 118         workers = 8
    119     )
    120 

D:\anaconda\envs\tf_ks\lib\site-packages\tensorflow_core\python\keras\engine\training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)
    817         max_queue_size=max_queue_size,
    818         workers=workers,
--> 819         use_multiprocessing=use_multiprocessing)
    820 
    821   def evaluate(self,

D:\anaconda\envs\tf_ks\lib\site-packages\tensorflow_core\python\keras\engine\training_v2.py in fit(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)
    395                       total_epochs=1)
    396                   cbks.make_logs(model, epoch_logs, eval_result, ModeKeys.TEST,
--> 397                                  prefix='val_')
    398 
    399     return model.history

D:\anaconda\envs\tf_ks\lib\contextlib.py in __exit__(self, type, value, traceback)
    128                 value = type()
    129             try:
--> 130                 self.gen.throw(type, value, traceback)
    131             except StopIteration as exc:
    132                 # Suppress StopIteration *unless* it's the same exception that

D:\anaconda\envs\tf_ks\lib\site-packages\tensorflow_core\python\keras\engine\training_v2.py in on_epoch(self, epoch, mode)
    769       if mode == ModeKeys.TRAIN:
    770         # Epochs only apply to `fit`.
--> 771         self.callbacks.on_epoch_end(epoch, epoch_logs)
    772       self.progbar.on_epoch_end(epoch, epoch_logs)
    773 

D:\anaconda\envs\tf_ks\lib\site-packages\tensorflow_core\python\keras\callbacks.py in on_epoch_end(self, epoch, logs)
    300     logs = logs or {}
    301     for callback in self.callbacks:
--> 302       callback.on_epoch_end(epoch, logs)
    303 
    304   def on_train_batch_begin(self, batch, logs=None):

D:\anaconda\envs\tf_ks\lib\site-packages\tensorflow_core\python\keras\callbacks.py in on_epoch_end(self, epoch, logs)
   2044 
   2045     row_dict = collections.OrderedDict({'epoch': epoch})
-> 2046     row_dict.update((key, handle_value(logs[key])) for key in self.keys)
   2047     self.writer.writerow(row_dict)
   2048     self.csv_file.flush()

D:\anaconda\envs\tf_ks\lib\site-packages\tensorflow_core\python\keras\callbacks.py in <genexpr>(.0)
   2044 
   2045     row_dict = collections.OrderedDict({'epoch': epoch})
-> 2046     row_dict.update((key, handle_value(logs[key])) for key in self.keys)
   2047     self.writer.writerow(row_dict)
   2048     self.csv_file.flush()

KeyError: 'val_custom_mae'

