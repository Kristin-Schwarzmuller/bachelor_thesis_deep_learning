{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kristins Alex "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The installed version of TensorFlow 2.1.0 includes GPU support.\n",
      "\n",
      "Num GPUs Available:  2 \n",
      "\n",
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 10240550769039494501\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 9105744200\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 6347138127791968951\n",
      "physical_device_desc: \"device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:17:00.0, compute capability: 7.5\"\n",
      ", name: \"/device:GPU:1\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 9104897474\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 12093766622541448315\n",
      "physical_device_desc: \"device: 1, name: GeForce RTX 2080 Ti, pci bus id: 0000:65:00.0, compute capability: 7.5\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import talos as ta\n",
    "from talos.model import lr_normalizer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.compat.v1.keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import ReLU, LeakyReLU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "#from tensorflow.keras.initializers import glorot_uniform\n",
    "\n",
    "available_gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "built_with_cuda = tf.test.is_built_with_cuda()\n",
    "\n",
    "if not (not available_gpus) & built_with_cuda:\n",
    "    print(\"The installed version of TensorFlow {} includes GPU support.\\n\".format(tf.__version__))\n",
    "    print(\"Num GPUs Available: \", len(available_gpus), \"\\n\")\n",
    "else:\n",
    "    print(\"The installed version of TensorFlow {} does not include GPU support.\\n\".format(tf.__version__))\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "tf.random.set_seed(1)\n",
    "\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.99\n",
    "sess = tf.compat.v1.Session(config = config)\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alexnet(activation, leaky_alpha):\n",
    "        \n",
    "    if activation == 'leakyrelu':\n",
    "        activation_layer = LeakyReLU(alpha = leaky_alpha)\n",
    "    elif activation == 'relu':\n",
    "        activation_layer = ReLU()\n",
    "    \n",
    "    model = Sequential([\n",
    "        Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=(224,224,Global.num_image_channels)),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(3,3), strides=(2,2)),\n",
    "        Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(3,3), strides=(2,2)),\n",
    "        Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(filters=384, kernel_size=(1,1), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(filters=256, kernel_size=(1,1), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(3,3), strides=(2,2)),\n",
    "        Flatten(),\n",
    "        Dense(4096, activation=activation_layer),\n",
    "        Dropout(0.5),#todo\n",
    "        Dense(4096, activation=activation_layer),\n",
    "        Dropout(0.5),#todo\n",
    "        Dense(units = 2, activation=activation_layer)\n",
    "        #Dense(10, activation='softmax')\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generierung Modell (Angepasst f√ºr Talos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_model(x_train, y_train, x_val, y_val, params):\n",
    "    \n",
    "    K.clear_session()\n",
    "\n",
    "    model = alexnet(params['activation'], params['leaky_alpha'])\n",
    "        \n",
    "    model.compile(\n",
    "        optimizer = params['optimizer'](lr = lr_normalizer(params['lr'], params['optimizer'])), \n",
    "        loss = Global.loss_funktion, \n",
    "        metrics = get_reduction_metric(Global.reduction_metric)\n",
    "    )\n",
    "    train_generator, valid_generator = create_data_pipline(params['batch_size'], params['samples'])\n",
    "    tg_steps_per_epoch = train_generator.n // train_generator.batch_size\n",
    "    vg_validation_steps = valid_generator.n // valid_generator.batch_size\n",
    "    print('Steps per Epoch: {}, Validation Steps: {}'.format(tg_steps_per_epoch, vg_validation_steps))\n",
    "    \n",
    "    startTime = datetime.now()\n",
    "    out = model.fit(\n",
    "        x = train_generator,\n",
    "        epochs = params['epochs'],\n",
    "        validation_data = valid_generator,\n",
    "        steps_per_epoch = tg_steps_per_epoch,\n",
    "        validation_steps = vg_validation_steps,\n",
    "        #callbacks = [checkpointer]\n",
    "        workers = 8\n",
    "    )\n",
    "    print(\"Time taken:\", datetime.now() - startTime)\n",
    "    sess.close()\n",
    "    return out, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Process(Process-1, initial)>\n",
      "7\n",
      "None\n",
      "None\n",
      "None\n",
      "[0, 1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "from multiprocessing import Process\n",
    "from multiprocessing import Value\n",
    "\n",
    "def a_function(ret_value):\n",
    "    print(7)\n",
    "    ret_value = 3.145678\n",
    "    return ret_value\n",
    "\n",
    "\n",
    "ret_value = [0, 1, 2, 3]\n",
    "\n",
    "reader_process = multiprocessing.Process(target=a_function, args=[ret_value])\n",
    "print(reader_process)\n",
    "print(reader_process.run())\n",
    "print(reader_process.start())\n",
    "print(reader_process.join())\n",
    "\n",
    "\n",
    "print(ret_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benutzerdefinierte Kostenfunktion & Metrik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolut_error(y_true, y_pred):\n",
    "    return K.mean(K.abs(y_pred - y_true), axis = -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hilfsfunktion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reduction_metric(metric):\n",
    "    \n",
    "    if metric == 'mean_absolut_error':\n",
    "        return [mean_absolut_error]\n",
    "    else:\n",
    "        assert(False, 'Metric yet unknown - Please modify get_Reduction_Metric to meet your requirements')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Struct for global parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rgba\n",
      "4\n",
      "..\\..\\data_generation\\dataset\\201019_2253_final\\labels_ks_RGBD.csv\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class global_parameter:\n",
    "    loss_funktion: str = 'mean_squared_error'\n",
    "    reduction_metric: str = 'mean_absolut_error'\n",
    "    monitor_value: str = 'val_mean_absolut_error'\n",
    "    \n",
    "    dataset: str = '201019_2253_final'\n",
    "    device: str = 'RTX_2080_Ti'\n",
    "    data_augmentation: bool = True\n",
    "    image_channels: str = 'rgba' # 'rgb' OR 'rgba' # jsut change this, everything else will automaticlly adjusted\n",
    "    num_image_channels: int = 3\n",
    "    image_dir: str = '..\\\\..\\\\data_generation\\\\dataset\\\\{}\\\\'.format(dataset)\n",
    "    \n",
    "    csv_file_name: str = 'labels_ks_RGB.csv'\n",
    "    csv_file: str = image_dir + csv_file_name\n",
    "    target_dir: str = '..\\\\output\\\\{}_{}\\\\'.format(dataset, image_channels)\n",
    "    results: str = '\\\\..\\\\{}_{}_Results.csv'.format(dataset, image_channels)\n",
    "        \n",
    "Global = global_parameter\n",
    "\n",
    "if(Global.image_channels == 'rgba'):\n",
    "    Global.num_image_channels = 4\n",
    "    Global.csv_file_name: str = 'labels_ks_RGBD.csv'\n",
    "    Global.csv_file: str = Global.image_dir + Global.csv_file_name\n",
    "        \n",
    "print(Global.image_channels)\n",
    "print(Global.num_image_channels)\n",
    "print(Global.csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  Filename  Azimuth  Elevation\n",
      "0   buddha\\rgbd\\buddha00000000-0-5-0-5.png        0          5\n",
      "1  buddha\\rgbd\\buddha00000001-0-5-0-10.png        0         10\n",
      "2  buddha\\rgbd\\buddha00000002-0-5-0-15.png        0         15\n",
      "3  buddha\\rgbd\\buddha00000003-0-5-0-20.png        0         20\n",
      "4  buddha\\rgbd\\buddha00000004-0-5-0-25.png        0         25\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "df2 = pd.read_csv(Global.csv_file)\n",
    "print(df2.head(5))\n",
    "fst_image = df2.iloc[0]['Filename']\n",
    "Image(Global.image_dir + fst_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generierung Datenpipeline (Angepasst f√ºr Talos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_pipline(batch_size, num_samples):\n",
    "    \n",
    "    \n",
    "    df = pd.read_csv(Global.csv_file)\n",
    "    df_shuffled = df.sample(frac = 1, random_state = 1)\n",
    "    df_train = df_shuffled[0 : int(num_samples * 0.8 // batch_size * batch_size)]\n",
    "    df_valid = df_shuffled.drop(df_shuffled.index[0 : df_train.shape[0]])[0 : int(num_samples * 0.2 // batch_size * batch_size)]\n",
    "    #print(df_valid)\n",
    "    \n",
    "    if Global.data_augmentation:\n",
    "        train_data_generator = ImageDataGenerator(\n",
    "            rescale = 1./255,\n",
    "            width_shift_range = 0.1,\n",
    "            height_shift_range = 0.1,\n",
    "            zoom_range = 0.1,\n",
    "            brightness_range = (0.5, 1.0), \n",
    "            fill_mode = 'nearest'\n",
    "        )\n",
    "    else:\n",
    "        train_data_generator = ImageDataGenerator(\n",
    "            rescale = 1./255\n",
    "        )\n",
    "        \n",
    "    train_generator = train_data_generator.flow_from_dataframe(\n",
    "        dataframe = df_train,\n",
    "        directory = Global.image_dir,\n",
    "        x_col = 'Filename',\n",
    "        y_col = ['Elevation', 'Azimuth'],\n",
    "        class_mode = 'raw',\n",
    "        target_size = (224, 224),\n",
    "        color_mode = Global.image_channels,\n",
    "        shuffle = True,\n",
    "        seed = 77,\n",
    "        batch_size = batch_size\n",
    "    )\n",
    "    #print(df_train)\n",
    "        \n",
    "    valid_data_generator = ImageDataGenerator(\n",
    "        rescale = 1./255\n",
    "    )\n",
    "    \n",
    "    valid_generator = valid_data_generator.flow_from_dataframe(\n",
    "        dataframe = df_valid,\n",
    "        directory = Global.image_dir,\n",
    "        x_col = 'Filename',\n",
    "        y_col = ['Elevation', 'Azimuth'],\n",
    "        class_mode = 'raw',\n",
    "        target_size = (224, 224),\n",
    "        color_mode = Global.image_channels,\n",
    "        shuffle = False,\n",
    "        seed = 77,\n",
    "        batch_size = batch_size\n",
    "    )\n",
    "    #print(df_train)\n",
    "    \n",
    "    return train_generator, valid_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory >>| ..\\output\\201019_2253_final_rgba\\ |<< existiert bereits. Fortsetzen auf eigene Gefahr! (Weiter mit Enter)\n"
     ]
    }
   ],
   "source": [
    "if(not os.path.exists(Global.target_dir)):\n",
    "    os.makedirs(Global.target_dir)\n",
    "else:\n",
    "    input('Directory >>| {} |<< existiert bereits. Fortsetzen auf eigene Gefahr! (Weiter mit Enter)'.format(Global.target_dir))\n",
    "\n",
    "device_file = open(Global.target_dir + '{}.txt'.format(Global.device), \"a+\")\n",
    "device_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSerach Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     Adam = RMSprop + Momentum (lr=0.001)\n",
    "#     Nadam = Adam RMSprop + Nesterov-Momentum (lr=0.002)\n",
    "#     RMSprop = (lr=0.001)\n",
    "#     SGD = (lr=0.01)\n",
    "#     Adagrad\n",
    "\n",
    "hyper_parameter = {\n",
    "    'samples': [20000],\n",
    "    'epochs': [1],\n",
    "    'batch_size': [32, 64],\n",
    "    'optimizer': [Adam],\n",
    "    'lr': [1, 2, 3, 5],\n",
    "    'first_neuron': [1024, 2048, 4096],\n",
    "    'dropout': [0.25, 0.50],\n",
    "    'activation': ['leakyrelu', 'relu'],\n",
    "    'hidden_layers': [0, 1, 2, 3, 4],\n",
    "    'leaky_alpha': [0.1] #Default bei LeakyReLU, sonst PReLU\n",
    "}\n",
    "\n",
    "hyper_parameter = {\n",
    "    'samples': [20000],\n",
    "    'epochs': [1],\n",
    "    'batch_size': [32, 64],\n",
    "    'optimizer': [Adam],\n",
    "    'lr': [1, 2],\n",
    "    'first_neuron': [1024, 2048, 4096],\n",
    "    'dropout': [0.25, 0.50],\n",
    "    'activation': ['leakyrelu', 'relu'],\n",
    "    'hidden_layers': [0, 1, 2, 3, 4],\n",
    "    'leaky_alpha': [0.1] #Default bei LeakyReLU, sonst PReLU\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_model_process(x_train, y_train, x_val, y_val, params):\n",
    "    from multiprocessing import Process\n",
    "    \n",
    "    ret_value = multiprocessing.Value(x_train, y_train, x_val, y_val, params)\n",
    "\n",
    "    reader_process = multiprocessing.Process(target=gen_model2, args=[ret_value])\n",
    "\n",
    "    reader_process.start()\n",
    "\n",
    "    reader_process.join()\n",
    "    return ret_value.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Talos Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                          | 0/240 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'leakyrelu', 'batch_size': 32, 'dropout': 0.25, 'epochs': 1, 'first_neuron': 1024, 'hidden_layers': 0, 'leaky_alpha': 0.1, 'lr': 1, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>, 'samples': 20000}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'numpy.ndarray'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-b6dd6ea229eb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[0mprint_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[0mclear_session\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m             \u001b[0msave_weights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         )\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\tf_ks\\lib\\site-packages\\talos\\scan\\Scan.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, params, model, experiment_name, x_val, y_val, val_split, random_method, seed, performance_target, fraction_limit, round_limit, time_limit, boolean_limit, reduction_method, reduction_interval, reduction_window, reduction_threshold, reduction_metric, minimize_loss, disable_progress_bar, print_params, clear_session, save_weights)\u001b[0m\n\u001b[0;32m    194\u001b[0m         \u001b[1;31m# start runtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mscan_run\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mscan_run\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m         \u001b[0mscan_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\anaconda\\envs\\tf_ks\\lib\\site-packages\\talos\\scan\\scan_run.py\u001b[0m in \u001b[0;36mscan_run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;31m# otherwise proceed with next permutation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mscan_round\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mscan_round\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[0mself\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscan_round\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\tf_ks\\lib\\site-packages\\talos\\scan\\scan_round.py\u001b[0m in \u001b[0;36mscan_round\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;31m# fit the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mingest_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mingest_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_history\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mround_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mingest_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mround_history\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_history\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\tf_ks\\lib\\site-packages\\talos\\model\\ingest_model.py\u001b[0m in \u001b[0;36mingest_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m      8\u001b[0m                       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m                       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m                       self.round_params)\n\u001b[0m",
      "\u001b[1;32m<ipython-input-12-f2df5a5ba1d9>\u001b[0m in \u001b[0;36mgen_model_thread\u001b[1;34m(x_train, y_train, x_val, y_val, params)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0mmultiprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mProcess\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mret_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmultiprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mValue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mreader_process\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmultiprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mProcess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgen_model2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mret_value\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\tf_ks\\lib\\multiprocessing\\context.py\u001b[0m in \u001b[0;36mValue\u001b[1;34m(self, typecode_or_type, lock, *args)\u001b[0m\n\u001b[0;32m    133\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0msharedctypes\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mValue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m         return Value(typecode_or_type, *args, lock=lock,\n\u001b[1;32m--> 135\u001b[1;33m                      ctx=self.get_context())\n\u001b[0m\u001b[0;32m    136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mArray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtypecode_or_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize_or_initializer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlock\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\tf_ks\\lib\\multiprocessing\\sharedctypes.py\u001b[0m in \u001b[0;36mValue\u001b[1;34m(typecode_or_type, lock, ctx, *args)\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[0mReturn\u001b[0m \u001b[0ma\u001b[0m \u001b[0msynchronization\u001b[0m \u001b[0mwrapper\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0mValue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m     '''\n\u001b[1;32m---> 74\u001b[1;33m     \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRawValue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtypecode_or_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\tf_ks\\lib\\multiprocessing\\sharedctypes.py\u001b[0m in \u001b[0;36mRawValue\u001b[1;34m(typecode_or_type, *args)\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[0mReturns\u001b[0m \u001b[0ma\u001b[0m \u001b[0mctypes\u001b[0m \u001b[0mobject\u001b[0m \u001b[0mallocated\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mshared\u001b[0m \u001b[0mmemory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m     '''\n\u001b[1;32m---> 48\u001b[1;33m     \u001b[0mtype_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtypecode_to_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtypecode_or_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtypecode_or_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m     \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_new_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmemset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddressof\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msizeof\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'numpy.ndarray'"
     ]
    }
   ],
   "source": [
    "dummy_x = np.empty((1, 2, 3, 224, 224))\n",
    "dummy_y = np.empty((1, 2))\n",
    "\n",
    "with tf.device('/device:GPU:0'):\n",
    "    \n",
    "        t = ta.Scan(\n",
    "            x = dummy_x,\n",
    "            y = dummy_y,\n",
    "            model = gen_model_process,\n",
    "            params = hyper_parameter,\n",
    "            experiment_name = '{}'.format(Global.dataset),\n",
    "            #shuffle=False,\n",
    "            reduction_metric = Global.reduction_metric,\n",
    "            disable_progress_bar = False,\n",
    "            print_params = True,\n",
    "            clear_session = True,\n",
    "            save_weights = False\n",
    "        )\n",
    "        \n",
    "\n",
    "t.data.to_csv(Global.target_dir + Global.results, index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dummy_x = np.empty((1, 2, 3, 224, 224))\n",
    "#dummy_y = np.empty((1, 2))\n",
    "#\n",
    "#from multiprocessing.pool import ThreadPool\n",
    "#pool = ThreadPool(processes=1)\n",
    "#\n",
    "#\n",
    "#with tf.device('/device:GPU:0'):\n",
    "#    \n",
    "#        t = ta.Scan(\n",
    "#            x = dummy_x,\n",
    "#            y = dummy_y,\n",
    "#            model = gen_model_thread,\n",
    "#            params = hyper_parameter,\n",
    "#            experiment_name = '{}'.format(Global.dataset),\n",
    "#            #shuffle=False,\n",
    "#            reduction_metric = Global.reduction_metric,\n",
    "#            disable_progress_bar = False,\n",
    "#            print_params = True,\n",
    "#            clear_session = True,\n",
    "#            save_weights = False\n",
    "#        )\n",
    "#        \n",
    "#\n",
    "#t.data.to_csv(Global.target_dir + Global.results, index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top Ergebnisse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf_ks]",
   "language": "python",
   "name": "conda-env-tf_ks-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
